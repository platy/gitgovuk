<main class="html-publication" lang="en" role="main">
      

  <div class="publication-external">
    <ul class="organisation-logos">
        <li class="organisation-logos__logo">
          
<div class="gem-c-organisation-logo brand--department-for-culture-media-sport">
    <a class="gem-c-organisation-logo__container gem-c-organisation-logo__link gem-c-organisation-logo__crest gem-c-organisation-logo__crest--single-identity brand__border-color" href="/government/organisations/department-for-digital-culture-media-sport">
      <span class="gem-c-organisation-logo__name">Department for<br>Digital, Culture,<br>Media &amp; Sport</span>
</a>
</div>
        </li>
    </ul>
  </div>

  <header class="gem-c-inverse-header  gem-c-inverse-header--padding-top ">
    
  

<div class="gem-c-title gem-c-title--inverse govuk-!-margin-top-8 govuk-!-margin-bottom-0">
      <span class="govuk-caption-xl gem-c-title__context">
    Policy paper
  </span>


  <h1 class="gem-c-title__text govuk-heading-xl">
    Online Safety Bill: European Convention on Human Rights Memorandum 
  </h1>
</div>
  <p class="publication-header__last-changed">Updated 19 April 2022</p>

  </header>



<div class="govuk-grid-row sidebar-with-body" data-module="sticky-element-container">
    <div class="govuk-grid-column-one-quarter-from-desktop contents-list-container">
        <nav aria-label="Contents" class="gem-c-contents-list" data-module="gem-track-click" role="navigation">
    <h2 class="gem-c-contents-list__title">
      Contents
</h2>
    <ol class="gem-c-contents-list__list">
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 1" data-track-category="contentsClicked" data-track-label="#introduction" data-track-options="{&quot;dimension29&quot;:&quot;Introduction&quot;}" href="#introduction">Introduction</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 2" data-track-category="contentsClicked" data-track-label="#part-3--providers-of-regulated-services-duties-of-care" data-track-options="{&quot;dimension29&quot;:&quot;Part 3 — Providers of regulated services: Duties of care&quot;}" href="#part-3--providers-of-regulated-services-duties-of-care">Part 3 — Providers of regulated services: Duties of care</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 3" data-track-category="contentsClicked" data-track-label="#part-5--duties-of-providers-of-regulated-services-certain-pornographic-content-background" data-track-options="{&quot;dimension29&quot;:&quot;Part 5 — Duties of providers of regulated services: certain pornographic content: Background&quot;}" href="#part-5--duties-of-providers-of-regulated-services-certain-pornographic-content-background">Part 5 — Duties of providers of regulated services: certain pornographic content: Background</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 4" data-track-category="contentsClicked" data-track-label="#notices-in-relation-to-terrorism-content-and-child-sexual-exploitation-and-abuse-content--part-7-chapter-5" data-track-options="{&quot;dimension29&quot;:&quot;Notices in relation to terrorism content and child sexual exploitation and abuse content — Part 7, Chapter 5&quot;}" href="#notices-in-relation-to-terrorism-content-and-child-sexual-exploitation-and-abuse-content--part-7-chapter-5">Notices in relation to terrorism content and child sexual exploitation and abuse content — Part 7, Chapter 5</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 5" data-track-category="contentsClicked" data-track-label="#enforcement-powers--part-7-chapter-6" data-track-options="{&quot;dimension29&quot;:&quot;Enforcement powers — Part 7, Chapter 6&quot;}" href="#enforcement-powers--part-7-chapter-6">Enforcement powers — Part 7, Chapter 6</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 6" data-track-category="contentsClicked" data-track-label="#part-10--communications-offences" data-track-options="{&quot;dimension29&quot;:&quot;Part 10 — Communications Offences&quot;}" href="#part-10--communications-offences">Part 10 — Communications Offences</a>

        </li>
    </ol>
</nav>
      
<div class="gem-c-print-link govuk-!-display-none-print govuk-!-margin-top-0 govuk-!-margin-bottom-6">
    <button class="govuk-link govuk-body-s gem-c-print-link__button" data-module="print-link">Print this page</button>
</div>
    </div>

  <div class="print-wrapper">
    <div class="print-meta-data">
      <p>
  <img class="print-meta-data-licence" src="/assets/government-frontend/open-government-licence-min-93b6a51b518ff99714a1aa2a7d2162735c155ec3cb073c75fb88b2a332fa83d3.png">
</p>
<p>
  © Crown copyright 2022
</p>
<p>
  This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated. To view this licence, visit <a href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3">nationalarchives.gov.uk/doc/open-government-licence/version/3</a> or write to the Information Policy Team, The National Archives, Kew, London TW9 4DU, or email: <a href="mailto:psi@nationalarchives.gov.uk">psi@nationalarchives.gov.uk</a>.
</p>
<p>
  Where we have identified any third party copyright information you will need to obtain permission from the copyright holders concerned.
</p>
<p>
  This publication is available at https://www.gov.uk/government/publications/online-safety-bill-supporting-documents/online-safety-bill-european-convention-on-human-rights-memorandum
</p>


    </div>
  </div>

  <div class="main-content-container">
    <div class="gem-c-govspeak-html-publication">
  
<div class="gem-c-govspeak govuk-govspeak " data-module="govspeak">
    
    
      <div class="govspeak">
<h2>Introduction</h2>

<p>1. This memorandum addresses issues arising under the European Convention on Human Rights (“ECHR”) in relation to the draft Online Safety Bill. It has been prepared by the Department for Digital, Culture, Media and Sport and the Home Office.</p>

<p>2. The Bill imposes obligations on providers of internet services which allow users to upload or share user-generated content or otherwise to interact (‘user-to-user services’) and on providers of services which allow users to search all or some parts of the internet (‘search services’). It also imposes obligations on providers of internet services which publish or otherwise make accessible pornographic content. These obligations apply to providers of in scope services (“regulated services”), including those based outside the UK.</p>

<p>3. The Bill also includes 3 new communications offences (replacing former offences) recommended by the Law Commission. The Bill also creates a new “cyberflashing” offence.</p>

<p>4. In May, the government published the Bill in draft, for pre-legislative scrutiny by the draft Online Safety Bill Joint Committee. The government has considered the Committee’s recommendations and has now prepared an updated Bill for introduction to Parliament.</p>

<p>5. Section 19 of the Human Rights Act 1998 requires the Minister in charge of a Bill in either House of Parliament to make a statement before Second Reading about the compatibility of the provisions of the Bill with the Convention rights (as defined by section 1 of that Act).  The Secretary of State for Digital, Culture, Media and Sport proposes to make a statement under section 19(1)(a) of the Human Rights Act 1998 that, in her view, the provisions of the Bill are compatible with the ECHR rights, on introduction of the Bill.</p>

<h2>Part 3 — Providers of regulated services: Duties of care</h2>

<h3>Background:</h3>

<p>6. <strong>Illegal content:</strong> All providers of in-scope user-to-user services will be subject to safety duties which require them to put in place systems and processes to mitigate and effectively manage the risk of harm to individuals as identified in the service providers’ illegal content risk assessment (clause 9). All providers of in-scope search services will similarly be subject to safety duties which require them to put in place systems and processes that minimise the risk of individuals encountering priority content and other illegal content in search results (clause 24).</p>

<p>7. <strong>Harmful to children:</strong> All providers of in scope user-to-user services which are ‘likely to be accessed by children’ will be subject to safety duties which require them to put in place systems and processes to ensure that children are prevented or protected from encountering content which is harmful to children on their services (clause 11). All providers of in-scope search services which are ‘likely to be accessed by children’ will similarly be subject to safety duties which require them to minimise the risk of children encountering harmful content in search results (clause 26).</p>

<p>8. <strong>Harmful to adults:</strong> Providers of regulated user-to-user services which meet thresholds set by the Secretary of State in regulations (‘Category 1 services’) are required to comply with additional duties. Such providers must consider the nature and severity of the risks of harm to adults identified and specify in their terms of service how such content is treated (clause 13).</p>

<p>9. <strong>Risk assessments:</strong> In order to be in a position to comply with these safety duties, service providers will have to carry out detailed risk assessments of the risks posed by the relevant types of content on their services (clauses 8, 10, 12, 23, 25).</p>

<p>10. <strong>Freedom of expression/privacy</strong>: All providers of regulated user-to-user services and search services will be required to have regard to the importance of protecting users’ rights to freedom of expression and protecting users from breaches of privacy when deciding on, and implementing, safety policies and procedures to discharge their safety duties (clauses 19 and 29).</p>

<p>11. <strong>Content of democratic importance:</strong> Providers of Category 1 services must operate their services using systems and processes to take account of the special importance of the free expression of content of democratic importance (clause 15). The terms of service of Category 1 services must specify how content of democratic importance will be treated, particularly in relation to decisions about whether to take down content or restrict access to it, or decisions to take action against a user. These terms and conditions must be clear and accessible and must be applied consistently.</p>

<p>12. <strong>News publishers/journalism:</strong> Content published by ‘recognised news publishers’ (established newspapers and broadcasters) will be exempt from the scope of the safety duties. Providers of Category 1 services will be required to use systems and processes designed to ensure that the special importance of the free expression of journalistic content is taken into account when making decisions about how to treat such content, particularly in relation to decisions about whether to take down content or restrict access to it, or decisions to take action against a user (clause 16) .</p>

<p>13. <strong>Fraudulent advertisements:</strong> Part 3, Chapter 5 includes provisions which will place a duty on providers of a subsection of in-scope services to put in place appropriate measures to minimise any paid-for fraudulent advertisements being displayed on their service. Clauses 34 and 35 place the duty on providers of Category 1 and 2A services, which are the largest user to user and search services.</p>

<p>14. <strong>Complaints:</strong> Providers of user-to-user services and search services will be under a duty to have systems in place which allow individuals to make a complaint if the individual considers that the provider is not complying with certain duties imposed by the Bill (see clauses 18 and 28). The complaints procedure must be easy to access, easy to use and transparent. Providers must take appropriate action in response to complaints.</p>

<p>15. <strong>Codes of practice:</strong> Following consultation with the Secretary of State and other relevant persons specified in the legislation, OFCOM must prepare codes of practice containing steps which a provider may follow in order to comply with the safety duties (see clause 37). A provider does not have to follow the steps in the code of practice in order to comply with the safety duties -  providers  can choose to comply in other ways. Where appropriate, OFCOM may recommend in the codes of practice the use of technology, including proactive technology  (defined in clause 184), for compliance with the illegal content, children’s online safety duties and fraudulent advertising duties. (Schedule 4 paragraph 12).  In doing so, OFCOM must  be satisfied that the use of technology by a service would be proportionate to the risk of harm that the technology is designed to safeguard against. OFCOM must have regard to the  accuracy, effectiveness and lack of bias when deciding whether to include a proactive technology measure in a code of practice.</p>

<p>16. In preparing a code of practice containing recommendations on compliance with their safety duties, OFCOM must consult persons whom OFCOM considers have relevant expertise in equality and human rights, in particular  the right to freedom of expression, and  the right to privacy (clause 37(6)(f)). All codes of practice that OFCOM prepares must be designed to reflect the importance of protecting rights to freedom of expression and protecting  from breaches of privacy (Schedule 4, paragraph 10). When complying with the safety duties, service providers must have regard to the importance of protecting  rights to freedom of expression and protecting users from breaches of privacy (see clauses 19 and 29).</p>

<h3>Article 10 (freedom of expression)</h3>

<p>17. Article 10 provides that everyone has the right to freedom of expression. The right includes freedom to hold opinions and to receive and impart information and ideas without interference. Selected interference with this right is permitted by article 10(2) where that is prescribed by law and necessary in a democratic society.</p>

<p>18. The safety duties in the Bill engage Article 10 ECHR to the extent that the duties will affect the ability of users to receive and impart certain types of information online.</p>

<p>19. An appreciable amount of the content affected by the application of the safety duties will be of a nature which does not attract the protection of Article 10. The caselaw of the European Court of Human Rights indicates that, under Article 17 of the Convention (prohibition of abuse of rights), applicants are prevented from relying on Article 10 in order to perform acts characterised by factors such as hatred, violence, xenophobia and racial discrimination (see, for example, Norwood v United Kingdom, case no. 23131/03). Thus the Court has held that content expressing support for terrorism does not, by virtue of Article 17, attract the protection afforded by Article 10 (Roj TV A/S v Denmark, case no. 24683/14).</p>

<p>20. The Bill does not impose any restrictions on content produced and published by service providers on their own services, or require service providers to carry any specific pieces of user-generated content on their services in breach of their terms and conditions, and therefore is not considered to affect the Article 10 rights of service providers.</p>

<p>21. Services which give rise to a low risk of harm to individuals in the UK are exempted (clause 49(2) and Schedule 1).</p>

<p>22. The Bill will not apply to news publishers’ websites. Full articles and recordings published by “recognised news publishers” are also exempted from the scope of the safety duties which apply to user-to-user services and search services (see clause 49(2), (8)-(10), and clause 50.</p>

<h3>Justification for interference with Article 10 rights of users</h3>

<p>23. Article 10 is a qualified right. Any interference with the Article 10 rights of internet service providers and users by Part 3 can be justified. The interference is prescribed by law, pursues the legitimate aims of the protection of health and morals as prescribed in Article 10(2), and is necessary in a democratic society.</p>

<p>24. <strong>Prescribed by law:</strong> The Bill establishes an overarching regulatory framework governing the treatment of content online. In addition to the detailed provisions contained in the primary legislation, its application in specific cases will be given a higher degree of legal certainty through the exercise of delegated powers by the Secretary of State and the issuing of codes of practice by OFCOM.</p>

<p>25. <strong>Pursuit of a legitimate aim:</strong> The purpose of the obligations imposed on service providers in relation to the safety duties is to reduce the risk of illegal and harmful content online causing harm to individuals, particularly children. This is a legitimate aim for the interference with the Article 10 rights of users.</p>

<p>26. To the extent that they relate to terrorism content, the obligations imposed on service providers under the illegal content safety duties can be justified as being necessary in the interests of national security (see, for example, Zana v Turkey, case no. 18954/91).</p>

<p>27. The effect of the safety duties in reducing the prevalence of CSEA content and other illegal content online can also be justified as being necessary for the protection of health and morals as well as for the prevention of crime (Mouvement Raëlien Suisse v. Switzerland, case no. 16354/06).</p>

<p>28. In addition, the safety duties for content which is harmful to children will protect the health and morals of children by requiring service providers to reduce the exposure of children to content such as pornography and material encouraging suicide and self-harm. In its case law the European Court of Human Rights has emphasised the margin of appreciation Contracting States enjoy in relation to measures designed to protect children from potentially harmful material (see, for example, Handyside v United Kingdom, case no. 5493/72).</p>

<p>29. <strong>Necessary in a democratic society:</strong> The European Court of Human Rights (ECtHR) has recognised the importance of the internet for freedom of expression but also its potential for abuse (Delfi AS v Estonia, case no. 64659/09, at paragraph 110).  As indicated above, the government is concerned about the prevalence of illegal and harmful content online and the harm it can cause to individuals, particularly children.</p>

<p>30. <strong>Additional mitigating factors:</strong> The safety duties require providers to take proportionate steps to mitigate risks to users and to operate their services with proportionate systems and processes (see, for example, clause 9(2) and (3)). Under clause 19, all in-scope service providers are required to have regard to the importance of protecting freedom of expression when deciding on and implementing their safety policies and procedures. Providers’ compliance with the safety duties will also be informed by the Codes of Practice issued by OFCOM (and approved by the Secretary of State).  Paragraph 10 of Schedule 4 requires OFCOM to ensure that the measures recommended in the codes of practice for the purpose of compliance with the duties  are designed in the light of protecting the right of users to freedom of expression, and must incorporate safeguards for the freedom of expression, as appropriate.</p>

<p>31. In the exercise of their powers and functions OFCOM and the Secretary of State are required, under section 6 of the Human Rights Act 1998, to act in a way which is compatible with ECHR rights.</p>

<p>32. Enhanced user complaints and redress mechanisms will also enable users to challenge decisions made by service providers about the treatment of content. Clause 18 imposes duties on providers of user-to-user services to put in place complaint procedures which allow users to complain to the provider in relation to a decision to take down or restrict access to content on the basis that it is illegal content or (where appropriate) harmful to children or adults, and which provide for effective redress if a complaint is upheld. Existing rights for users to bring an action in the courts for breach of contract will continue to exist (for instance if user material is taken down in breach of the provider’s terms of service).</p>

<p>33. The Bill imposes a duty on Category 1 service providers to take measures to protect journalistic content (clause 16). The definition of “journalistic content” includes content “generated for the purposes of journalism” and will therefore capture content produced by citizen journalists as well as content published by recognised news publishers. These measures will afford all creators of UK-linked journalistic content (including citizen journalists) with substantive additional safeguards and protections against the removal of journalistic content, including an expedited complaints procedure, on user-to-user services with the largest numbers of users and highest risk features.</p>

<p>34. The Bill is expected to have a positive effect on the freedom of expression of some users, by reducing the prevalence of bullying and abuse online and so creating a safer environment in which users (particularly those in vulnerable groups) feel more able to express their views.</p>

<p>35. For these reasons any interference with users’ rights to free expression resulting from the imposition of safety duties in relation to illegal and harmful content is compatible with Article 10.</p>

<h3>Recognised news publisher exemption: Combined effect of Article 10 and Article 14</h3>

<p>36. The “recognised news publisher” content exemption applies only to content published by established national, local and online newspapers and broadcasters, not to journalistic content produced by citizen journalists.</p>

<p>37. Article 14 of the ECHR provides that the rights and freedoms set out therein shall be secured without discrimination on any ground. It therefore needs to be read in relation to the other substantive Convention rights.</p>

<p>38. Article 14 ECHR (read with Article 10) may be engaged because a citizen journalist could seek to argue that they are being discriminated against in the enjoyment of their Article 10 rights because their content does not benefit from the additional protections offered by the Bill to content published by a recognised news publisher.</p>

<p>39. Article 14 applies to discrimination on the grounds such as specific personal characteristics or ‘other status’. To the extent that being a citizen journalist would amount to an appropriate ‘other status’ on which to base an Article 14 discrimination claim, there are strong grounds for treating the two groups differently, since the conditions which apply to recognised news publishers (e.g. editorial control, standards code, complaints procedure - see clause 50(2)) mean that content they produce gives rise to a lower risk of harm. In addition, citizen journalists will benefit from strong protections under clause 16 of the Bill.</p>

<p>40. In relation to journalistic content, the Bill is therefore compliant with Article 14 (read with Article 10).</p>

<h2>Part 5 — Duties of providers of regulated services: certain pornographic content: Background</h2>

<p>41. Part 3 of the Digital Economy Act 2017 (“DEA 2017”) contains provisions which would require persons who make pornography available on the internet to prevent children from accessing that content. This duty would not apply to internet services which will be user-to-user services under this Bill. In October 2019, DCMS announced that Part 3 DEA 2017 would not be brought into force. Clause 170 will repeal Part 3 DEA 2017.</p>

<p>42. In place of Part 3 DEA 2017, Part 5 of this Bill will introduce a requirement for providers of internet services which publish pornography on their services to ensure that children are not able to encounter that pornography. The intention is that Part 5 will dovetail with the duty in Part 3 of the Bill to prevent children from encountering primary priority content that is harmful to children (clause 11). Part 3 will apply to pornography which is uploaded by users, while Part 5 will apply to pornography which is uploaded by the provider of the service. Part 5 will apply to all internet services, unless they are otherwise exempt or excepted, including those which are neither regulated user-to-user services nor regulated search services.</p>

<p>43. Clause 68 also includes duties intended to protect the privacy of users of services in scope of Part 5 and to maintain a written record of how the service has done this. OFCOM will be required by clause 69 to produce guidance to assist services in complying with the duties described in this paragraph and the one above.</p>

<h3>Article 10 ECHR</h3>

<p>44. Part 5 engages Article 10 ECHR to the extent that it will affect the ability of providers of internet services to impart information and users to receive information. Part 5 imposes restrictions on internet service providers publishing pornographic content on their own services. It also restricts children’s access to that content. As a consequence of that restriction, it will also be more difficult for adult users to access online pornography as they will need to demonstrate they are over 18.</p>

<p>45. Article 10 is a qualified right. Any interference with the Article 10 rights of internet service providers and users by Part 5 can be justified. The interference is prescribed by law, pursues the legitimate aims of the protection of health and morals as prescribed in Article 10(2), and is necessary in a democratic society.</p>

<p>46. <strong>Prescribed by law:</strong> The interference with the Article 10 rights of providers of internet services and users will be set out in the primary legislation. The duties which internet services must comply with if they publish regulated provider pornographic content on their service are set out in clause 68. The duties are clear and precise enough to enable internet service providers to be able to foresee the consequences of their decisions on which content to publish on their services and the steps that they must take to prevent children from accessing any regulated provider pornographic content. The definition of what is pornographic is clear. The definition is based on existing definitions in primary legislation which have been used in the context of trying pornography-related criminal offences for more than a decade. Ofcom will be required by clause 69 to produce guidance in relation to these duties to assist internet services providers with complying with their duties and to provide transparency on how OFCOM will use the enforcement powers granted to them in Part 7.</p>

<p>47. <strong>Pursuit of a legitimate aim:</strong> The purpose of the obligations imposed on internet service providers in Part 5 is to protect children from suffering harm resulting from exposure to pornography during childhood. This is a legitimate aim.</p>

<p>48. <strong>Necessary in a democratic society:</strong> The ECtHR has recognised that contracting states have a wide margin of appreciation when assessing the necessity of restrictions on freedom of expression for the sake of protecting health and morality (Mouvement Raëlien Suisse). The ECtHR has held that wide margin of appreciation applies in the case of restrictions on the publication of sexually explicit content in publicly accessible places (Müller v Switzerland case no. 10737/84).</p>

<p>49. Part 5 has been drafted to achieve its legitimate aim in a manner which interferes with the Article 10 rights of users no more than is necessary. The restriction on users accessing regulated provider pornographic content only prevents children from receiving the content. While adults will need to complete an age verification step to be able to access the content, their ability to receive the content is otherwise not interfered with. As Part 5 does not prescribe how the age verification step must be done, internet services will have flexibility to introduce age verification in a way which is least burdensome for their adult users (as long as it still restricts children’s access).</p>

<p>50. The interference with the Article 10 rights of internet service providers is similarly limited to no more than is necessary to achieve Part 5’s legitimate aim. Internet service providers will not be banned from publishing regulated provider pornographic content on their service. They will be free to continue to do so as long as it is done in a manner which children are unable to access that pornographic content.</p>

<p>51. In order to minimise the burden on internet service providers, Schedule 1 and Schedule 9 contain a number of exemptions and exceptions to the duty for circumstances where it is felt that the risk of harm to children is low and that applying the duties  would therefore be disproportionate.</p>

<p>52. When assessing the proportionality of measures intended to protect health and morality, the ECtHR has held that the audience of the speech and the impact on that audience has to be taken into consideration (Ponson v. France, case no. 26935/05). In Ponson, the ECtHR held that content being capable of inciting young people to act in unhealthy ways was a relevant and sufficient reason to justify the interference with the publisher’s Article 10 rights.</p>

<h2>Notices in relation to terrorism content and child sexual exploitation and abuse content — Part 7, Chapter 5:</h2>

<h3>Background:</h3>

<p>53. A Notice issued under Clause 103 would require a service provider to use specified technology to identify and remove illegal CSEA content and terrorist content from their user-to-user services. The Bill lists in Schedule 5 the offences that constitute ‘terrorism offences’; these offences are capable of being committed online. The offences which constitute “CSEA offences’’ are listed in Schedule 6 to the Bill; again these offences are capable of being committed online.</p>

<p>54. OFCOM will be able to issue a Notice irrespective of whether a service provider has complied with the safety duty. This is because it is possible for a service provider to comply with all of the steps in the codes of practice but none-the-less still have significant amounts of CSEA and / or terrorism content on their platform. A Notice is therefore a means by which OFCOM can require the provider to utilise specific technology to identify and remove the material. A Notice may be issued in relation to CSEA content present on any part of the service (public or private) but  only in relation to public terrorism content.</p>

<p>55. Before issuing a notice under Clause 103, OFCOM must  issue a warning notice (see clause 103(7)) containing details including the technology that OFCOM are considering requiring, whether the technology is to be required in relation to terrorism or CSEA content (or both), and explaining that the provider may make representations during a specified period. OFCOM may only issue a Notice after the period for issuing representations has expired, and only if satisfied that it is necessary and proportionate in the particular case, taking into account a non-exhaustive list of factors (see clause 104). These factors include the prevalence of the content, the risk of harm to individuals in the UK, and the severity of that harm, any interference with freedom of expression, risks in relation to privacy and that no less intrusive step is available.</p>

<p>56. In addition to the safeguards in subsection clause 104(2), the Bill imposes a duty on OFCOM to produce guidance as to how it proposes to exercise its functions under this Chapter (clause 107).</p>

<p>57. The Bill specifies that OFCOM must only require the use of accredited technology (see clause 103(2)). Technology can be accredited by OFCOM or a person appointed by OFCOM, which can only accredit technology that meets minimum standards of accuracy (approved and published by the Secretary of State) (see clause 105(9-10)).</p>

<p>58. The Bill will confer a right on service providers to appeal a Notice to the Upper Tribunal (see clause 139).</p>

<h3>Article 8 (right to privacy), Article 10 (freedom of expression).</h3>

<p>59. Content analysis occurring pursuant to a Notice engages the right to privacy protected by Article 8(1) ECHR. OFCOM will have the power to require the analysis or scanning of private communications for the purposes of identifying and removing CSEA content.</p>

<p>60. The provisions are also likely to engage Article 10 ECHR because they allow OFCOM to require service providers to analyse or scan private and public content for the purposes of identifying and removing CSEA content, and public content for the purposes of identifying and removing terrorism content. While an individual’s right to freedom of expression will not be engaged in relation to terrorism content or CSEA content, requiring a user-to-user service to use such automated tools may constitute a restriction on the Article 10 rights of user-to-user service users, because it will involve the removal of content, and there is a very small possibility that it  leads to the inadvertent removal of legal content.</p>

<h3>Justification for interference with Article 8 and Article 10 rights</h3>

<p>61. <strong>Prescribed by law:</strong> The interference is  ‘in accordance with the law’  because it is sufficiently foreseeable in its terms to give individuals an adequate indication as to the circumstances in which their rights under Article 8 and 10 may be affected: in addition to the safeguards in  clause 104(2),  guidance from OFCOM will make clear to individuals the circumstances in which OFCOM may issue a use of technology notice.</p>

<p>62. <strong>Legitimate aim:</strong> The measures pursue a legitimate aim. To the extent that the measures relate to CSEA  content, the measures can be justified as necessary for the protection of health and morals as well as for the prevention of crime (Mouvement Raëlien Suisse).</p>

<p>63. To the extent that they relate to terrorism content, the obligations imposed on service providers under the illegal content safety duties can be justified as being necessary in the interests of national security (see, for example, Zana).</p>

<p>64. <strong>Necessary in a democratic society:</strong> The issue of a Notice by OFCOM is a proportionate means of achieving the legitimate aim of identifying and removing illegal CSEA and terrorist content. The tools that OFCOM will be able to require a company to use will be accredited based on standards published by the Secretary of State to ensure that only the most accurate tools are required.  OFCOM must consider a  number of matters before it issues  each notice, including whether the use of  less intrusive means would be likely to achieve a significant reduction in the amount of relevant content, the severity of the harm and the widespread nature of the problem. These factors will ensure that OFCOM only issues a Notice where it is proportionate to do so. For these reasons, the provisions relating to Clause 13 Notices are compatible with article 8 and article 10 rights.</p>

<h3>Interference with Article 1 of Protocol 1:</h3>

<p>65. The provisions requiring businesses to  use technologies in particular circumstances will constitute some interference with the way in which affected providers run their businesses. As such these provisions may engage the protections conferred by Article 1 of Protocol 1 against deprivation of possessions, save in the public interest and subject to the conditions provided for by law and by the general principles of international law.</p>

<h3>Justification for interference with Article 1, Protocol 1 rights</h3>

<p>66. The measures will not  amount to deprivation of property but a restriction of its use or enjoyment. Any restriction can be justified as part of the measures necessary to enforce laws in the general interest as set out in the Bill. OFCOM may only impose the requirements where it is proportionate and necessary, and we expect that the measures will normally only be used in scenarios where the risk of harm to users is sufficiently high in order to justify the intrusion and where such steps are the only effective measure to protect from harm the users of online services, especially more vulnerable users such as children.</p>

<h2>Enforcement powers — Part 7, Chapter 6:</h2>

<p>67. <strong>Background:</strong> A range of enforcement powers will be conferred on OFCOM, enabling it to use a spectrum of measures in order to tackle infringements in a proportionate manner. Clause 110 enables OFCOM to issue a provisional notice of contravention where it considers there are reasonable grounds that the provider has failed or is failing in respect of the Bill’s enforceable requirements. This notice must specify a period during which the provider can make representations, after which OFCOM may then issue a confirmation decision (see clause 112) if it considers, following the representations, that the person is failing or has failed to comply with the notified requirement.  This notice will either set out steps the provider must take to comply, or impose a penalty, or both. There are also provisions allowing penalties to be imposed for the non-payment of fees (see clauses 120) and for non-compliance with a Notice to deal with terrorism or CSEA content (see clause 119). Maximum penalties of £18 million or 10% of qualifying worldwide revenue, whichever is greater, are available to provide a suitable deterrent. Confirmation decisions and penalty notices can be appealed in the Upper Tribunal (see clause 139).</p>

<p>68. More stringent enforcement tools known as business disruption measures (BDMs) are also available to OFCOM. BDMs can be either service restriction measures (SROs) or access restriction measures (AROs) (see clauses 123 - 127). BDMs are intended to have a deterrent or persuasive effect, encouraging the service provider to bring their processes into alignment with the requirements of the Bill. Following an application to an appropriate court, OFCOM can, through the use of SROs, require third party providers to withdraw access to certain services (such as the processing of payments). Through the use of AROs, OFCOM can restrict access to the non-compliant service for UK users.  Any application by OFCOM for a SRO or ARO must be supported by detailed grounds and evidence. The court must take into account the rights and obligations of all relevant parties. These safeguards also apply to interim SROs and AROs.</p>

<h3>Article 6 (right to a fair trial)</h3>

<p>69. Article 6 ECHR provides that everyone is entitled to a fair trial, that is a fair and public hearing within a reasonable time by an independent and impartial tribunal established by law.</p>

<p>70. In relation to the general enforcement powers (clauses 110 - 121), the power to fine arguably engages the protections of Article 6(1) as it involves the imposition of an obligation to pay the relevant penalty. Given the potential severity of the penalties, it is possible that a court would find that the penalties are criminal in nature and so impose stricter requirements in order to comply with Article 6.  The protections of Article 6(1) may also be engaged by OFCOM’s powers to impose BDMs. These decisions arguably involve the determination of a ‘civil right or obligation’ - primarily they affect the rights of persons to carry out a business (Tre Traktorer AB v Sweden, case no. 10873/84 (para 43)). The Bill provides that such action may, in all cases, only be taken following the issue of a Court order made on an application filed by OFCOM.</p>

<h3>Justification for interference with Article 6 rights</h3>

<p>71. <strong>Penalties:</strong> Whether the penalties are criminal in nature or not, we consider that any potential interference with this right can be justified as there are relevant safeguards built into the Bill, including an explicit statutory requirement for OFCOM to give reasons for issuing a penalty (see clause 117(5)(a)), a right to make representations and provide evidence to the regulator (see clause 110(8)) and a right of appeal to the Upper Tribunal where the decision to issue the penalty notice and the decision to impose a penalty of a particular amount may be challenged (see clause 139).</p>

<p>72. <strong>Business disruption measures:</strong> Whilst part of the enforcement framework, BDMs are not primarily designed to be punitive (there is no formal finding of guilt or handing down of penalties); instead they will act to lower the risks and reduce the potential harm of the breach by reducing the availability of the infringing online service.</p>

<p>73. In light of the above we do not consider BDMs to amount to criminal penalties. However, in the event that they do, their exercise would not give rise to undue interference with the Article 6 rights given the procedural safeguards built into the BDM framework within the Bill.</p>

<p>74. The initial application to the Court for any BDM will be open to challenge by both the proposed recipient of the order as well as the non-compliant provider, save where a ‘without notice’ application has been filed (which itself will have to be justified to the Court’s satisfaction). Any order made by the Court will be susceptible to an appeal through the usual channels.</p>

<p>75. Taken together, this will provide ‘sufficiency of review’ for the purposes of Article 6(1) (Bryan v United Kingdom, case no. 19178/91). Finally, all decisions made in relation to BDMs - whether to apply for an order or to issue one — will be based on a clear and predictable legal basis as set out on the face of the Bill, with clear and exacting requirements for both the application to the Court and any order made, as well as in relation to the factors for the Court to consider and the thresholds that must be met before an application can succeed.</p>

<p>76. We therefore consider that the enforcement provisions in the Bill are compatible with Article 6.</p>

<h3>Article 1 of Protocol 1 (Protection of property)</h3>

<p>77. Article 1 of Protocol 1 entitles everyone to the peaceful enjoyment of their possessions. Noone is to be deprived of their possessions except in the public interest and subject to the conditions provided for by law and by the general principles of international law.</p>

<h4>Interference with Article 1 of Protocol 1</h4>

<p>78. The business disruption enforcement provisions (clauses 122 - 126) engage the protections conferred by Article 1 of Protocol 1 against deprivation of possessions, save in the public interest and subject to the conditions provided for by law and by the general principles of international law.</p>

<h4>Justification for interference with Article 1, Protocol 1 rights</h4>

<p>79. The measures will not  amount to deprivation of property but a restriction of its use or enjoyment. Any restriction can be justified as part of the measures necessary to enforce laws in the general interest as set out in the Bill. Moreover they are proportionate and necessary measures that will normally only be used as the culmination of the enforcement process and/or when addressing the most egregious breaches of the duties set out in the Bill where such steps will be required to protect from harm the users of online services, especially more vulnerable users such as children.</p>

<p>80. BDMs will only be imposed after a detailed application including grounds and evidence has been considered by a court. The court can only make an order if it is satisfied that the making of the order is appropriate for the purposes of preventing harm to individuals, and is proportionate to the risk of such harm (see e.g. clause 123(6)(c) and (d)). The court is expressly required to consider the rights and obligations of all relevant parties, including the persons on whom the court is considering imposing the requirements. The court will therefore be able to ensure that any interference with the Article 1 Protocol 1 rights of third parties is in the public interest and strikes a fair balance between the general interest and the protection of the rights of third parties to whom an order is directed.</p>

<p>81. These provisions could have retrospective effect in that they may affect contracts entered into before the relevant provisions in the Bill come into force. There is no presumption that legislation is not intended to interfere with existing rights, nor does the ECHR create an absolute prohibition on retrospective application of legislation (cf. A v United Kingdom, case no. 8531/79).</p>

<p>82. We therefore consider that the measures in Part 7, Chapter 6 are compatible with Article 1, Protocol 1.</p>

<h2>Part 10 — Communications Offences</h2>

<p>83. The Bill will repeal the offences in the Malicious Communications Act 1988, and subsection 127(1) and subsection 2(a) and (b) of the Communications Act 2003 so far as they apply to England &amp; Wales.</p>

<p>84. Part 10 contains three new offences which are intended to replace the repealed offences: (i) a harmful communications offence (clause 150); (ii) a false communications offence (clause 151); (iii) a threatening communications offence (clause 152), (together the “communications offences”).</p>

<h3>Article 10 (freedom of expression) and Article 8 (respect for private life and correspondence)</h3>

<p>85. Any offence criminalising speech will constitute an interference in the qualified right to freedom of expression, and could, depending on circumstance, constitute an interference in the qualified right to respect for private life and correspondence.</p>

<p>86. The Law Commission in part recommended the replacement of the existing communications offences due to concerns that a prosecution under the <em>existing</em> offences could, in certain circumstances, be susceptible to challenge under Article 10 (and, again, potentially Article 8), on the basis that the interference: (i) is not sufficiently prescribed by law (“grossly offensive” is ill-defined and prone to subjective definition); and (ii) does not pursue a legitimate aim (where a communication carries no potential for harm, either personal or societal, it is not clear which of the legitimate aims would be engaged).</p>

<p>87. Part of the rationale for the new offences was to address these shortcomings in the existing law. We consider that the communications offences within the Bill are adequately prescribed by law, pursue a legitimate aim within Articles 8(2) and 10(2), and are necessary in a democratic society.</p>

<h3>Prescribed by law</h3>

<p>88. We consider that the offences are formulated in such a way as to enable people to foresee with a reasonable degree of certainty the consequences of their conduct.</p>

<h3>Legitimate aim</h3>
<p>89. The offences in various ways focus on the potential harm to those likely to see the communication. The rationale for interfering in the defendant’s Article 10 (and, where relevant, Article 8) rights is thus primarily to protect the health and rights of others (ie those likely to or intended to encounter the communication).</p>

<h3>Necessary in a democratic society</h3>

<p>90. It is clear from the range of harms that attend to abusive communications (especially though not uniquely online) that there is a pressing social need for some kind of interference in order to prevent such harms. The criminal law is not the least restrictive form of interference, and that is why the offences are targeted at particularly harmful and culpable forms of behaviour.</p>

<p>91. For these reasons, we consider that any interference in a person’s Article 8 or 10 rights that might result from the communications offences in this Bill would be compatible with the ECHR.<br> <br> <br></p>

<p><strong>Department for Digital, Culture, Media and Sport and the Home Office</strong><br><br><br>
<strong>17 March 2022</strong></p>

</div>


</div>
</div>
  </div>

  <div class="sticky-element" data-sticky-element="">
    <a class="govuk-link app-c-back-to-top dont-print" href="#contents">
    <svg class="app-c-back-to-top__icon" focusable="false" height="17" viewBox="0 0 13 17" width="13" xmlns="http://www.w3.org/2000/svg">
      <path d="M6.5 0L0 6.5 1.4 8l4-4v12.7h2V4l4.3 4L13 6.4z" fill="currentColor"></path>
    </svg>
    Contents
</a>

    <div class="sticky-element__print-link">
      
<div class="gem-c-print-link govuk-!-display-none-print govuk-!-margin-top-0 govuk-!-margin-bottom-6">
    <button class="govuk-link govuk-body-s gem-c-print-link__button" data-module="print-link">Print this page</button>
</div>
    </div>
  </div>
</div>

    </main>