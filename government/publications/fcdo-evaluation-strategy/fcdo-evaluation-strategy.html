<main class="html-publication" lang="en" role="main">
      

  <div class="publication-external">
    <ul class="organisation-logos">
        <li class="organisation-logos__logo">
          
<div class="gem-c-organisation-logo brand--foreign-commonwealth-development-office">
    <a class="gem-c-organisation-logo__container gem-c-organisation-logo__link gem-c-organisation-logo__crest gem-c-organisation-logo__crest--single-identity brand__border-color" href="/government/organisations/foreign-commonwealth-development-office">
      <span class="gem-c-organisation-logo__name">Foreign, Commonwealth<br>&amp; Development Office</span>
</a>
</div>
        </li>
    </ul>
  </div>

  <header class="gem-c-inverse-header  gem-c-inverse-header--padding-top ">
    
  

<div class="gem-c-title gem-c-title--inverse govuk-!-margin-top-8 govuk-!-margin-bottom-0">
      <span class="govuk-caption-xl gem-c-title__context">
    Policy paper
  </span>


  <h1 class="gem-c-title__text govuk-heading-xl">
    FCDO evaluation strategy
  </h1>
</div>
  <p class="publication-header__last-changed">Published 4 July 2022</p>

  </header>






<div class="govuk-grid-row sidebar-with-body" data-module="sticky-element-container">
    <div class="govuk-grid-column-one-quarter-from-desktop contents-list-container">
        <nav aria-label="Contents" class="gem-c-contents-list" data-module="gem-track-click" role="navigation">
    <h2 class="gem-c-contents-list__title">
      Contents
</h2>
    <ol class="gem-c-contents-list__list">
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 1" data-track-category="contentsClicked" data-track-label="#foreword" data-track-options="{&quot;dimension29&quot;:&quot;Foreword&quot;}" href="#foreword">Foreword</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 2" data-track-category="contentsClicked" data-track-label="#executive-summary" data-track-options="{&quot;dimension29&quot;:&quot;Executive summary&quot;}" href="#executive-summary">Executive summary</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 3" data-track-category="contentsClicked" data-track-label="#introduction-1" data-track-options="{&quot;dimension29&quot;:&quot;\n1.   Introduction&quot;}" href="#introduction-1"><span class="gem-c-contents-list__number">1. </span><span class="gem-c-contents-list__numbered-text">Introduction</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 4" data-track-category="contentsClicked" data-track-label="#the-ambition-1" data-track-options="{&quot;dimension29&quot;:&quot;\n2.  The ambition&quot;}" href="#the-ambition-1"><span class="gem-c-contents-list__number">2. </span><span class="gem-c-contents-list__numbered-text">The ambition</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 5" data-track-category="contentsClicked" data-track-label="#implementation-of-the-strategy" data-track-options="{&quot;dimension29&quot;:&quot;\n3.  Implementation of the strategy&quot;}" href="#implementation-of-the-strategy"><span class="gem-c-contents-list__number">3. </span><span class="gem-c-contents-list__numbered-text">Implementation of the strategy</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 6" data-track-category="contentsClicked" data-track-label="#annex-1-map-of-workstreams-and-outcomes" data-track-options="{&quot;dimension29&quot;:&quot;Annex 1: Map of workstreams and outcomes&quot;}" href="#annex-1-map-of-workstreams-and-outcomes">Annex 1: Map of workstreams and outcomes</a>

        </li>
    </ol>
</nav>
      
<div class="gem-c-print-link govuk-!-display-none-print govuk-!-margin-top-0 govuk-!-margin-bottom-6">
    <button class="govuk-link govuk-body-s gem-c-print-link__button" data-module="print-link">Print this page</button>
</div>
    </div>

  <div class="print-wrapper">
    <div class="print-meta-data">
      <p>
  <img class="print-meta-data-licence" src="/assets/government-frontend/open-government-licence-min-93b6a51b518ff99714a1aa2a7d2162735c155ec3cb073c75fb88b2a332fa83d3.png">
</p>
<p>
  © Crown copyright 2022
</p>
<p>
  This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated. To view this licence, visit <a href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3">nationalarchives.gov.uk/doc/open-government-licence/version/3</a> or write to the Information Policy Team, The National Archives, Kew, London TW9 4DU, or email: <a href="mailto:psi@nationalarchives.gov.uk">psi@nationalarchives.gov.uk</a>.
</p>
<p>
  Where we have identified any third party copyright information you will need to obtain permission from the copyright holders concerned.
</p>
<p>
  This publication is available at https://www.gov.uk/government/publications/fcdo-evaluation-strategy/fcdo-evaluation-strategy
</p>


    </div>
  </div>

  <div class="main-content-container">
    <div class="gem-c-govspeak-html-publication">
  
<div class="gem-c-govspeak govuk-govspeak " data-module="govspeak">
    
    
      <div class="govspeak">
<h2>Foreword</h2>
<p>This is the Foreign, Commonwealth and Development Office’s first Evaluation Strategy.</p>

<p>We are in a time of unprecedented global challenges. Our impact as a department relies on the generation and use of good quality evidence, including evaluation. Be it tackling the most complex international policy issues or working in fragile and testing environments around the world, evaluation identifies good practice, improves our performance and identifies what works.</p>

<p>As a leader on the global stage, good evaluation enables us to respond to new priorities and changing contexts, contributing evidence that helps us to deliver the Foreign Secretary’s vision of “a new era for peace, security and prosperity.” This strategy builds on the good practice of our legacy organisations. It will guide decisions about evaluations across our diplomatic and development activities as we implement the UK’s international priorities set out in the 2021 Integrated Review and the International Development Strategy.</p>

<p>The strategy will help us to deliver our commitment to evidence, accountability and learning, and to establish the mechanisms we need to develop a robust evaluation system. This is a critical part of building an FCDO culture that is driven by evidence and makes the most of the wealth of expertise across the Department.</p>

<p>Permanent Under-Secretary, Sir Philip Barton, KCMG OBE</p>

<h2>Executive summary</h2>

<h3>Introduction</h3>

<p>We know how well things work because of evaluation. Evaluation is the tool that tells us what works, how and why, so as to maximise the value of taxpayers’ money and better achieve our objectives. It identifies good practice, improves our performance and helps to target resources on activities that will have the most impact on the ground.</p>

<p>As a new organisation, the Foreign, Commonwealth and Development Office (FCDO) must develop an evaluation system which informs decision-making for policy, programming and strategy across a diverse, global portfolio. The Evaluation Strategy outlines our ambition to support, ensure quality and maximise learning of decentralised evaluation, as well as improving mechanisms for identifying, prioritising and implementing central evaluation in critical areas.</p>

<p>There is a strong evidence&nbsp;ecosystem in FCDO, in which evaluation is an important part. This&nbsp;includes evidence generated through situation analysis, programme management, results monitoring, financial and risk management, data analysis, evidence synthesis and research and development.&nbsp;Within this spectrum of evidence tools, evaluation complements other evidence sources as&nbsp;part of a culture of continual improvement and offers a unique contribution in generating robust evidence of what works and why.</p>

<p>Evaluation may be undertaken for learning or accountability, and often these 2 purposes overlap. Evaluation, and the learning generated from it, can be applied to programmes, strategies, policies, portfolios or cross-cutting themes. FCDO draws on a wide range of evaluation tools to meet different information needs and purposes, and&nbsp;this strategy supports appropriate and proportionate application of the full spectrum of evaluation approaches in FCDO.</p>

<p>The UK government has a strong commitment to evaluation, as demonstrated by the establishment of the Evaluation Task Force, the recent National Audit Office review on evaluation and updates to the Government Social Research protocols. In addition, FCDO has scrutiny and accountability obligations as an Official Development Assistance (ODA) spending department, including regular review by the <a class="govuk-link" href="https://icai.independent.gov.uk/wp-content/uploads/ICAI-follow-up-2019-20-reviews.pdf" rel="external">Independent Commission for Aid Impact</a> (ICAI) and adherence to the 2015 International Development Act.</p>

<h3>The ambition</h3>

<p>The FCDO Evaluation Strategy sets the ambition for evaluation over the next 3 years (2022-2025). Its overarching goal is to advance and strengthen the practice, quality and use of evaluation so that FCDO’s strategy, policy and programming are more coherent, relevant, efficient, effective, and have greater impact.</p>

<p>In order to achieve this ambition, we will work towards 4 key outcomes. We have outlined the outcomes and their corresponding actions and workstreams in the table below. Annual milestones have been identified against each workstream to ensure we monitor our progress.</p>

<table>
  <thead>
    <tr>
      <th scope="col">Outcome</th>
      <th scope="col">Key actions and workstreams</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Strategic evaluation evidence is produced and used in strategy, policy and programming: Relevant, timely, high-quality evaluation evidence is produced and used in areas of strategic importance for FCDO, HMG and international partners.</td>
      <td>* Enhance oversight of evaluation investments<br> * Identify potential central evaluations through Evaluation Portfolio Assessments<br> * Co-design portfolios of evaluated interventions to address evidence gaps on priority themes<br> * Deliver demand-responsive thematic evaluation<br> * Support rigorous, experimental impact evaluation for high priority interventions</td>
    </tr>
    <tr>
      <td>Evaluation evidence is systematic and objective: Users have confidence in the findings generated from evaluations of FCDO interventions, policies and strategies.</td>
      <td>* Implement the FCDO Evaluation Policy<br> * Quality assure evaluation design and outputs<br> * Provide efficient access to good quality suppliers<br> * Develop and share guidance, templates and best practice</td>
    </tr>
    <tr>
      <td>Learning from evaluations is shared and used in decision-making: Evaluation findings are accessible and actively communicated in a timely and useful way to inform future strategy, programme and policy design.</td>
      <td>* Improve management information of evaluations<br> * Generate Evaluation Insights – learning documents synthesising evaluative evidence<br> * Improve communication and visibility about evaluation support, methods and findings<br> * Share learning across HMG and with international partners</td>
    </tr>
    <tr>
      <td>FCDO has an evaluative culture, the right evaluation expertise and capability: FCDO is sufficiently resourced with skilled advisers possessing up-to-date knowledge of evaluation, and minimum standards of evaluation literacy are mainstreamed across the organisation.</td>
      <td>* Develop organisational capability through individual skills and training<br> * Lead the Evaluation and Government Social Research Cadre<br> * Advise on deployment of evaluation staff<br> * Develop and test innovative methods for evaluation and evidence synthesis<br> * Advance thinking on evidence-based influencing approaches</td>
    </tr>
  </tbody>
</table>

<p>The actions and milestones outlined in the strategy will be reviewed annually to ensure they reflect ongoing learning and adapt to organisational changes.</p>

<h3>Roles and responsibilities</h3>

<p>Operationalising this strategy is the responsibility of the Head of the Evaluation Unit and the Head of the Evaluation and Government Social Research Profession. They are accountable for its delivery, supported by Evaluation Advisers and Programme Managers within the Evaluation Unit and by advisers working on research, monitoring, evaluation and learning across FCDO. In addition, the strategy depends on engagement and co-working with the following groups:</p>

<ul>
  <li>staff across the business, especially senior officials</li>
  <li>research and Evidence Directorate and the Tech and Analysis Directorate</li>
  <li>the Investment Committee</li>
  <li>other government departments, especially the Joint Funds Unit and those spending ODA</li>
</ul>

<h2>
<span class="number">1. </span>  Introduction</h2>

<p>We know how well things work because of evaluation: evaluation is the tool that tells us what works and why, so as to maximise the value of taxpayers’ money and better achieve our objectives. It identifies good practice, improves our performance and helps to target resources on activities that will have the most impact on the ground.</p>

<p>As a new organisation, the Foreign, Commonwealth and Development Office (FCDO) must develop an evaluation system which informs decision-making across a diverse, global portfolio. This strategy outlines the ambition for evaluation in FCDO, and the steps required over the next 3 years to support the journey towards that ambition. It outlines specific actions that will enhance the practice, quality and use of evaluation across the business. It seeks to expand the proportionate use of evaluation across our development and diplomacy work, enabling assessment of both programme and non-programme areas.</p>

<p>This strategy builds on learning from evaluation approaches in the 2 legacy departments (Department for International Development and Foreign and Commonwealth Office) and a review of evaluation policies and strategies in peer government and donor organisations. The strategy seeks to support, ensure quality and maximise learning of decentralised evaluation - recognising the need for teams spread across the globe to respond to their own context and evidence needs - while improving mechanisms for identifying, prioritising and implementing central evaluations in critical areas. The strategy recognises the different challenges, expertise and experience in evaluating diplomacy and development, and seeks to build on these to apply learning and evaluative approaches across disciplines.</p>

<p>This document is complemented by the FCDO Evaluation Policy, which ensures a common understanding of core evaluation principles and standards. The Evaluation Strategy includes details of how we will promote, monitor and enforce the minimum standards on ethics and quality in evaluation as outlined in the Evaluation Policy.</p>

<p>This is an FCDO-wide strategy. The Head of the Evaluation Unit and the Head of Profession for Evaluation and Government Social Research are accountable for its implementation and will report annually on its progress. Further details are outlined in Section 3.</p>

<p>This strategy covers the period from April 2022 - March 2025, in line with the current Spending Review period. Progress against the indicators outlined in this document will be reviewed annually, and targets revised as appropriate.</p>

<p>In this introduction, we outline the context and evidence system for evaluation in FCDO. In section 2, we specify our goal and 4 outcomes, and detail the activities and milestones against each of those outcomes. The final section of the document outlines the roles and responsibilities for implementing the strategy.</p>

<h3>The need for evaluation in FCDO</h3>

<p>The FCDO is committed to generating and using evidence. There is a strong evidence&nbsp;ecosystem in FCDO, in which evaluation is an important part. This&nbsp;includes tools such as rigorous evidence reviews, research and development programmes, research analyst reports, economic appraisals, country diagnostics and situation/context analysis to inform how we design strategies, policies and programmes. Annual reviews and regular monitoring of results and risk help us track how we are delivering. Programme Completion Reports, After Action&nbsp;Reviews and evaluation help us assess&nbsp;how well we delivered and whether it made a difference.&nbsp;Within this spectrum of evidence tools, evaluation<sup role="doc-noteref"><a class="govuk-link" href="#fn:1" rel="footnote">[footnote 1]</a></sup> complements other evidence sources as&nbsp;part of a culture of continual improvement&nbsp;and offers a unique contribution in generating robust evidence of what works and why.</p>

<p>Cross government initiatives, such as the establishment of the Evaluation Task Force,<sup role="doc-noteref"><a class="govuk-link" href="#fn:2" rel="footnote">[footnote 2]</a></sup> are promoting standards and expectations on evaluation across government departments, working closely with Her Majesty’s Treasury. These initiatives sit alongside FCDO’s scrutiny and accountability obligations as an Official Development Assistance (ODA) spending department, including regular review by the <a class="govuk-link" href="https://icai.independent.gov.uk/wp-content/uploads/ICAI-follow-up-2019-20-reviews.pdf" rel="external">Independent Commission for Aid Impact</a> (ICAI) and adherence to the 2015 International Development Act,<sup role="doc-noteref"><a class="govuk-link" href="#fn:3" rel="footnote">[footnote 3]</a></sup> which mandates that ‘the Secretary of State must make arrangements for the independent evaluation of the extent to which ODA provided by the United Kingdom represents value’.</p>

<h3>Using evaluation evidence</h3>

<p>Evaluation may be undertaken for learning and/or accountability purposes, and often these 2 purposes overlap. Evaluation for learning can help to: manage risk and uncertainty; improve current strategies, policies or programmes by providing evidence to make better decisions; gain an understanding of what works, for whom and when, as evidence to inform future decisions. Evaluation for accountability can help to generate evidence of how an intervention or policy has worked, for example its efficiency, effectiveness or impact, and supports a commitment to openness, scrutiny and challenge. Ultimately, evaluation seeks to understand and improve our work and our impact on the ground, and therefore increase the value of our work and our spend.&nbsp;Evaluation can be used to evidence and strengthen our business and country plans, measure key areas under our outcome delivery plans, and contribute to the global public good.</p>

<p>Evaluation, and the learning generated from it, can be applied to programmes, strategies, policies, portfolios or cross-cutting themes. FCDO draws on a wide range of evaluation tools to meet different information needs and purposes.&nbsp;These include:</p>

<ol>
  <li>Programme level monitoring and evaluation, with FCDO requiring all programmes to have their progress monitored and for teams to consider whether they are suitable for evaluation.</li>
  <li>Portfolio monitoring and evaluation, drawing together data and learning on strategy, policy and programming across a directorate or country post.</li>
  <li>Strategic and thematic evaluations, managed centrally, which can assess policy, programming or strategy and draw out broader learning.</li>
  <li>Fully external and independent reviews, with a focus on accountability and conducted by the Independent Commission on Aid Impact.</li>
</ol>

<p>Evaluation should not be applied to every policy or programme, but rather where there is an explicit learning need. Consideration of whether evaluation is required should take into account whether policies or programmes are high profile, levels of uncertainty or risk, cost, and learning potential<sup role="doc-noteref"><a class="govuk-link" href="#fn:4" rel="footnote">[footnote 4]</a></sup>. There is a wide range of evaluation approaches available, from the most rigorous experimental impact evaluations to light-touch internal learning. Deciding the right evaluation approach must consider:</p>

<ul>
  <li>the information needs</li>
  <li>the feasibility of different approaches</li>
  <li>the available resources / proportionality</li>
</ul>

<p>We promote experimental evaluation approaches where they are feasible and where the findings will promote useful learning. However, we recognise that in some instances they are not feasible or appropriate, and other methods may be more effective in producing the required results. This strategy supports appropriate and proportionate application of the full spectrum of evaluation approaches in FCDO.</p>

<div class="call-to-action">
<h4>Box 1: Lexicon</h4>

<p>For this document and in line with the Her Majesty’s Treasury’s Central Government guidance on evaluation (<a class="govuk-link" href="https://www.gov.uk/government/publications/the-magenta-book">Magenta Book</a>) and OECD Development Assistance Committee (DAC) definitions, we define evaluation as the systematic and objective assessment of an on-going or completed FCDO project, programme, strategy or policy, its design, implementation, and results. In FCDO, we use a range of different tools to measure our progress and results, including:</p>

<ul>
  <li>monitoring: systematic collection of data to measure progress against intended results</li>
  <li>process evaluation: independent assessment of how delivery is implemented</li>
  <li>impact evaluation: independent assessment of what difference the intervention has made, with impacts attributable to the intervention. This includes experimental/quasi-experimental and theory-based approaches</li>
  <li>portfolio evaluation: evaluation of a group or portfolio of projects with similar aims or collectively contributing towards Directorate General/directorate/post outcome(s)</li>
  <li>thematic evaluation: evaluation focusing on 1 or more themes that are relevant beyond a particular project or outcome and cut across countries, regions, and sectors</li>
</ul>
</div>

<h2>
<span class="number">2. </span> The ambition</h2>

<p>The overarching goal of the Evaluation Strategy is to advance and strengthen the practice, quality and use of evaluation so that FCDO’s strategy, policy and programming are more coherent, relevant, efficient, effective, and have greater impact.</p>

<p>In order to achieve this ambition, we will work towards 4 key outcomes:</p>

<h3>Outcome 1</h3>
<p>Strategic evaluation evidence is produced and used in strategy, policy and programming: Relevant, timely, high-quality evaluation evidence is produced and used in areas of strategic importance for FCDO, Her Majesty’s Government (HMG) and international partners.</p>

<h3>Outcome 2</h3>
<p>Evaluation evidence is systematic and objective: Users have confidence in the findings generated from evaluation of FCDO interventions, policies and strategies.</p>

<h3>Outcome 3</h3>
<p>Learning from evaluations is shared and used in decision-making: Evaluation findings are accessible and actively communicated in a timely and useful way to inform future strategy, programme and policy design.</p>

<h3>Outcome 4</h3>
<p>FCDO has an evaluative culture, the right evaluation expertise and capability: FCDO is sufficiently resourced with skilled advisers possessing up-to-date knowledge of evaluation, and minimum standards of evaluation literacy are mainstreamed across the organisation.</p>

<p>This requires an effective, coordinated evaluation system which combines approaches from both legacy departments to enable evaluative thinking and learning across the range of diplomatic and development requirements in FCDO. We will adopt a blended centralised and decentralised approach whereby the majority of evaluation activity and spend is decentralised across FCDO, complemented by centrally managed evaluations.</p>

<h3>Outcome 1: Strategic evaluation evidence is produced and used in strategy, policy and programming</h3>

<p>This outcome focuses on producing relevant, timely, high-quality evaluation evidence that is used in areas of strategic importance for FCDO, HMG and international partners. We seek to ensure evaluation investments are proportionate and focused on generating new evidence that supports impactful and value for money programming and effective policy. This includes strengthening our ability to draw lessons and demonstrate the impact of our strategies, policies and programming within or across divisions, departments, geographies or themes. We will undertake an exercise to identify the strength of evidence supporting the 20 highest cost policy areas and programmes, which will inform our priority topics for evaluation<sup role="doc-noteref"><a class="govuk-link" href="#fn:5" rel="footnote">[footnote 5]</a></sup>.</p>

<p>To achieve this outcome, we will focus on:</p>

<ul>
  <li>
    <p>enhancing oversight of evaluations commissioned by FCDO</p>
  </li>
  <li>
    <p>strengthening the use of rigorous impact evaluation methods for FCDO activities</p>
  </li>
  <li>
    <p>prioritising evaluation investments to meet needs across the range of FCDO development and diplomatic activities. Identifying and prioritising centrally managed evaluations will be done through both top-down and bottom-up mechanisms, with the Evaluation Portfolio Assessments playing a critical role in identifying under-evaluated areas and topics. We will work in close collaboration with the Research and Evidence Directorate to ensure that our activities complement the portfolio of research and development activity that generates research and evaluation evidence on global evidence gaps. We will ensure gender and inclusion is considered in the selection and design of these evaluations</p>
  </li>
</ul>

<div class="call-to-action">
<h3>Box 2: Central, coordinated impact evaluations on community policing</h3>

<p>The Metaketa Initiative tested community policing interventions in 6 developing countries, reaching an estimated 9 million people, and measuring impacts on: community attitudes toward police; community cooperation with the police; police attitudes and behaviours; crime. Randomised controlled trials were conducted in and coordinated across 6 sites, Brazil, Colombia, Liberia, Pakistan, the Philippines, and Uganda, measuring interventions that were implemented by local police agencies and with common elements across all sites. The evaluation found that crime was not reduced, citizen’s attitudes did not improve, and interventions were often implemented unevenly and incompletely. This study concluded that national governments should proceed with caution if adopting the community policing model, unless structural constraints or operational practices within the police are also addressed.</p>

<p>The coordinated evaluations produced stronger, more robust evidence than an evidence synthesis from a similar number of uncoordinated evaluations might have. The evaluation helped FCDO better understand where and why such interventions work, and can be used to decide where and how to invest in community policing in the future. The results will be used to inform international evidence-driven policy guidelines.</p>

<p>This evaluation was 1 of 2 included in the Evaluation Taskforce’s Top 10 Evaluations: read more about them here: <a class="govuk-link" href="https://www.gov.uk/government/collections/top-evaluations-government#improving-land-rights-in-democratic-republic-of-congo-(2017-2019)">Top Evaluations: Government - GOV.UK</a>.</p>
</div>

<h4>Key actions and workstreams</h4>

<p>Progress towards this outcome is dependent on a collaborative effort by FCDO’s central Evaluation Unit and advisers working on monitoring, evaluation, research and learning across the organisation. It will include 5 workstreams:</p>

<h4>1.1 Enhance oversight of evaluation investments:</h4>

<p>The Evaluation Unit, working with advisers across the FCDO, will develop improved mechanisms for scrutiny of monitoring, evaluation and learning (MEL) plans in high resource business cases, as part of the existing Quality Assurance Unit processes. Such a mechanism will aim to:</p>

<ul>
  <li>
    <p>improve the quality and consistency of approach to MEL in programme proposals</p>
  </li>
  <li>
    <p>make evaluation plans more strategic, with potential to generate and apply new learning, as well as being technically feasible</p>
  </li>
  <li>
    <p>trigger additional support for impact evaluations that are deemed feasible, to maximise quality, value for money and learning. This will enable us to hold back or improve evaluations which are not feasible or not in FCDO’s strategic interest, as well as ensure that evaluations have sufficient technical support throughout their lifecycle</p>
  </li>
</ul>

<h4>1.2 Identify potential central evaluations through Evaluation Portfolio Assessments:</h4>

<p>The Evaluation Unit will conduct an analysis of Directorate General (DG) portfolios and generate recommendations on areas where evaluations should and could be conducted. These Evaluation Portfolio Assessments will identify where evaluation could generate insights for high-level decision-making, particularly in areas that might otherwise have been missed. For example, the Evaluation Portfolio Assessment might include recommendations for evaluations on thematic or geographic policy outcomes, cross-cutting objectives, ways of delivering, or specific, innovative programmes. They will enable the identification of opportunities to evaluate non-programmatic activity (e.g., the effectiveness of diplomatic influencing or the implementation of foreign policy) or identify opportunities for rigorous impact evaluation of programmes, including within areas identified as the 20 highest cost policy/programmes which may have limited evidence or identified as an area with low evidence in the FCDO’s assessment of the ‘Best Buys’ within specific sectors. Embedded advisers working on monitoring, evaluation and learning will provide expert support to this process, including shaping the final recommendations and supporting their uptake and implementation. The process will include consultation with relevant teams, including from FCDO’s Research and Evidence Directorate, to ensure coherence and value add of proposed evaluations. Recommendations will be put to relevant Directors to action as appropriate and with Evaluation Unit support. The full list of recommendations and agreed actions will be submitted to the Investment Committee as part of the annual update on the Evaluation Strategy.</p>

<h4>1.3 Co-design portfolios of evaluated interventions to address evidence gaps on priority themes:</h4>

<p>Over recent years, a number of programmes have addressed evidence gaps in areas of Ministerial and international priority by matching (1) a component supporting a portfolio of innovative interventions, designed and managed by a policy team, with (2) a component supporting a portfolio of corresponding evaluations (impact and process evaluations) and research (e.g. on prevalence and drivers of the issue in question), designed and managed by a team in Research and Evidence Directorate. Such collaborations will cover a range of thematic priorities including what works to prevent violence against women and girls, what works to prevent violence at scale and the Disability Inclusive Development programme. Programmes of this nature will continue to generate robust research and evaluation evidence to inform decision making within the FCDO and beyond.</p>

<h4>1.4 Deliver demand-responsive thematic evaluation:</h4>

<p>The Evaluation Unit will manage a flexible resource, via the Evidence Fund, to support strategic and thematic evaluations. These evaluations will be identified via the Evaluation Portfolio Assessments but will also be accessible via bidding windows where staff across FCDO can bid for funds and technical support to enhance portfolio and thematic evaluation evidence generation. The Evidence Fund is a dynamic platform, led within the Research and Evidence Directorate, providing demand-responsive evidence and support for dissemination and uptake. We will work closely with ICAI to ensure FCDO-led evaluation adds value and avoids duplication with ICAI’s work.</p>

<h4>1.5 Support rigorous, experimental impact evaluation for high priority interventions:</h4>

<p>Subject to necessary approvals, the Evaluation Unit aims to develop a new programme to support experimental evaluations of strategic, innovative interventions, assessing what works on key evidence gaps, thereby increasing the impact of FCDO investments. Given the technical complexity and levels of investment required to do good experimental and quasi-experimental evaluations,&nbsp;the programme will maximise value for money by focussing on areas with the most potential for learning, identified in part through Evaluation Portfolio Assessments, our assessment of the evidence underpinning the 20 highest-cost policy/programme areas, and consultation with relevant experts. This will include innovative approaches to robust impact evaluation, such as that which measures diplomacy and influencing or works in insecure and fragile contexts.</p>

<p>The programme will&nbsp;aim to provide 3 key services:</p>

<ul>
  <li>design, conduct and analyse impact evaluations</li>
  <li>undertake follow-up studies of existing impact evaluations to assess longer-term impact</li>
  <li>provide technical support to ensure quality and develop FCDO capability on impact evaluations</li>
</ul>

<p>We will monitor our progress against each of these activities on an annual basis - Table 1 outlines the key milestones.</p>

<h4>Table 1: Key milestones for workstreams under Outcome 1</h4>

<table>
  <thead>
    <tr>
      <td></td>
      <th scope="col">By April 2023 (+1 year)</th>
      <th scope="col">By April 2024 (+2 years)</th>
      <th scope="col">By April 2025 (+3 years)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">1.1 Enhance oversight of evaluation investments</th>
      <td>Criteria for assessing new evaluation investments developed and new mechanism fully tested.</td>
      <td>Approach for review operating smoothly and drawing on consistent input from across the evaluation advisory network.</td>
      <td>System working, MEL reviews complete on all QAU eligible business cases. Formal feedback process in place.</td>
    </tr>
    <tr>
      <th scope="row">1.2 Identify potential central evaluations through Evaluation Portfolio Assessments</th>
      <td>Evaluation Portfolio Assessment (EPA) pilot complete and selected evaluations progressed.<br>  Evaluation Unit resource restructured to scale the approach to other parts of FCDO. Guidance and support documents produced for embedded Evaluation Advisers applying to country portfolios as appropriate.</td>
      <td>EPAs completed in all Director General areas. Good practice identified and shared across FCDO. Selected evaluations progressed.</td>
      <td>Review lessons from the approach and develop proposal for appropriate central funding for strategic and thematic evaluations in advance of the next Spending Review.</td>
    </tr>
    <tr>
      <th scope="row">1.3 Co-design portfolios of evaluated interventions to address evidence gaps on priority themes</th>
      <td>Follow up VAWG programme (What works to prevent violence at scale) contracted; first call for proposals for Humanitarian Protection impact evaluations (BEPAC)</td>
      <td>First round of What works…at scale and BEPAC impact evaluations identified and under design.</td>
      <td>Impact evaluations being implemented, additional studies under design.</td>
    </tr>
    <tr>
      <th scope="row">1.4 Deliver demand-responsive thematic evaluation</th>
      <td>Completion of 3 thematic evaluations, 2-3 additional evaluations under design.</td>
      <td>Target figures to be confirmed in Evidence Fund logframe.</td>
      <td>Target figures to be confirmed in Evidence Fund logframe.</td>
    </tr>
    <tr>
      <th scope="row">1.5 Support rigorous, experimental impact evaluation for high priority interventions</th>
      <td>Concept note and business case approved; supplier recruited.</td>
      <td>Impact evaluations and follow up studies identified and under design; capacity development plan formulated.</td>
      <td>Impact evaluations being implemented, additional studies under design as appropriate.</td>
    </tr>
  </tbody>
</table>

<h3>Outcome 2: Evaluation evidence is systematic and objective</h3>

<p>We aim to ensure confidence in the findings generated from evaluation of FCDO interventions, policies and strategies. This is essential for our evaluations to be credible, trusted and used, and to maximise the impact of our findings in design and delivery of policies and programmes. Under this outcome, we aim for: (i) an organisation-wide agreement of minimum principles and standards for evaluation and when they should be used; (ii) an increase in evaluations that meet expected quality standards in design and outputs; and (iii) the use of pre-qualified suppliers in external evaluations to maximise quality and credibility.</p>

<p>The Evaluation Policy defines evaluation as systematic (it uses recognised robust and replicable methodology which is appropriate to the evaluation question) and objective (it includes a level of independence from the strategy, policy or programme in question)<sup role="doc-noteref"><a class="govuk-link" href="#fn:6" rel="footnote">[footnote 6]</a></sup>. All evaluative activities should aim to meet core principles of being useful, credible, robust, proportionate and safe and ethical, including consideration of gender and inclusion in their design, implementation and analysis.</p>

<p>For programme spend, the&nbsp;Programme Operating Framework (PrOF) provides&nbsp;a clear set of rules to ensure we use evidence throughout design and implementation. The rules are supplemented by the Evaluation PrOF guide which includes criteria for staff to consider when deciding whether to evaluate. This includes consideration of strategic value and the broader evidence base to ensure that evaluation investments are targeted on evidence gaps within priority issues. However, deciding whether an evaluation is required and appropriate requires technical input from evaluation experts. Without such expertise there are risks that potential evaluations in key areas are missed, or that evaluations are conducted on areas or using approaches which do not generate useful learning.</p>

<p>In refining how we ensure the quality of evaluations, FCDO takes into account recent updates to cross-government approaches to evaluation, including the updated Magenta Book (2020), the Government Social Research (GSR) publication protocol (2021) and the findings of the National Audit Office review on evaluation in government (2021)<sup role="doc-noteref"><a class="govuk-link" href="#fn:7" rel="footnote">[footnote 7]</a></sup>. Evaluations are aligned to FCDO data commitments, including the Inclusive Data Charter and policies on open access.</p>

<div class="call-to-action">
<h3>Box 3: Credibility is vital for evaluations to influence change</h3>

<p>The OECD specifies that “aid agencies should have an evaluation policy with clearly established guidelines and methods and with a clear definition of its role and responsibilities and its place in institutional aid structure”. Research conducted by DFID found quality and rigour is essential: the credibility of an evaluation (including the evaluation quality) is a key component to the evaluations use and uptake, and that the intrinsic quality of an evaluation is a key modifier of its potential value. Evaluation quality factors include: clarity about the evaluation purpose and objectives, the selection of a team with the right mix of skills and expertise, the appropriateness and ‘right rigour’ of the methodology, the robustness of the data and the analytical frameworks, ensuring possibility of verifiable findings, the extent to which plural views are represented in the evaluation findings, and the use of the evaluation findings to draw useful conclusions and recommendations.</p>

<p>Sources: OECD (1991) <a class="govuk-link" href="https://www.oecd.org/dac/evaluation/2755284.pdf" rel="external">Principles for Evaluation of Development Assistance</a>
Review to measure the influence of DFID’s Published Evaluations (2017, internal) ITAD (2016) <a class="govuk-link" href="https://assets.publishing.service.gov.uk/media/57a312d8e5274a31e0001b5a/Value_of_Evaluation_Discussion_Paper_-__Final_Version_for_Publication_03082016_clean.pdf" rel="external">The Value of Evaluation</a></p>
</div>

<h4>Key actions and workstreams</h4>

<p>The main workstreams by which we will promote, support and ensure quality and credibility are:</p>

<h4>2.1 Implement the FCDO Evaluation Policy:</h4>

<p>The FCDO Evaluation Policy seeks to ensure a common understanding of evaluation principles and standards. It provides a mechanism to promote, monitor and enforce minimum standards on evaluation as well as demonstrating our ongoing commitment to high quality, objective and transparent evaluation.&nbsp;It outlines standards required in evaluations, including those which assess activities outside of programme spend.&nbsp;The Evaluation Unit will promote the use of the policy for all evaluative activities, track adherence to the standards and follow-up with teams requiring support.</p>

<h4>2.2 Quality assure evaluation design and outputs:</h4>

<p>Independent quality assurance helps to protect objectivity and credibility. It demonstrates to internal and external audiences that we have processes to ensure objectivity, thereby increasing trust in our evaluation outputs. Without quality assurance, there are risks of weak, misleading or even inaccurate evidence informing decision-making and impacting value for money. The Evaluation Quality Assurance and Learning Service (EQUALS) 2, is an essential mechanism for ensuring evaluations meet minimum standards of quality throughout their lifecycle. Through use of an expert panel, it conducts quality assurance of evaluation terms of reference, inception, baseline and final reports<sup role="doc-noteref"><a class="govuk-link" href="#fn:8" rel="footnote">[footnote 8]</a></sup>. The standards are set by FCDO and continually updated in line with the latest cross government and international guidance.</p>

<h4>2.3 Provide efficient access to good quality suppliers:</h4>

<p>A new Global Evaluation Monitoring Framework Agreement (GEMFA) will ensure the provision of efficient and effective expert services for the delivery of monitoring, evaluation and learning of FCDO diplomacy and development (as well as support other ODA-spending government departments). It will give access to pre-approved suppliers that provide high quality and internationally recognised evaluation and monitoring knowledge and skills, and can deliver MEL across the organisation’s strategies, policy areas and programmes across the globe. This also enables more control over the timing of evaluations – which is critical to uptake and use – by reducing the procurement timelines without compromising on quality.</p>

<h4>2.4 Develop and share guidance, templates and best practice:</h4>

<p>The Evaluation Unit will be responsible for sourcing, promoting and developing guidance and templates on evaluation. This will include updates to the Evaluation PrOF guide, as well as guidance notes on specific methodological or evaluation management issues. It will include surfacing best practice within FCDO on new or challenging approaches, such as developing and managing country level portfolio MEL, in line with priority activities set out in Outcome 1 and learning products developed under Outcome 3.</p>

<p>We will monitor our progress against each of these activities on an annual basis - Table 2 outlines the key milestones.</p>

<h4>Table 2: Key milestones for workstreams under Outcome 2</h4>

<table>
  <thead>
    <tr>
      <td></td>
      <th scope="col">By April 2023 (+1 year)</th>
      <th scope="col">By April 2024 (+2 years)</th>
      <th scope="col">By April 2025 (+3 years)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">2.1 Implement the FCDO Evaluation Policy</th>
      <td>Policy agreed and published, accessible and actively promoted across FCDO.</td>
      <td>Policy reviewed to ensure relevance in line with any changes in the organisation.</td>
      <td>Policy reviewed and updated to ensure relevance in line with any changes in the organisation; redrafted for next SR period as required.</td>
    </tr>
    <tr>
      <th scope="row">2.2 Quality assure evaluation design and outputs</th>
      <td>EQUALS 2 fully operational and used across the organisation.</td>
      <td>Demand for and user satisfaction with EQUALS 2 remains high [target figures to be confirmed with EQUALS 2 logframe].</td>
      <td>Demand for and user satisfaction with EQUALS 2 remains high [target figures to be confirmed with EQUALS 2 logframe]. Model reviewed to ensure approach is appropriate and sustainable.</td>
    </tr>
    <tr>
      <th scope="row">2.3 Provide efficient access to good quality suppliers</th>
      <td>GEMFA launched, monitored and promoted amongst Evaluation Advisers and staff working on programmes or evaluations.</td>
      <td>Framework actively managed over SR period (inc. corrective action taken if suppliers not performing). Suppliers informed of their performance in comparison to other suppliers.</td>
      <td>Framework actively managed over SR period. Suppliers informed of their performance in comparison to other suppliers.</td>
    </tr>
    <tr>
      <th scope="row">2.4 Develop and share guidance, templates<sup role="doc-noteref"><a class="govuk-link" href="#fn:9" rel="footnote">[footnote 9]</a></sup> and best practice</th>
      <td>PrOF guide updated. Key guidance documents developed and shared. Mechanism for responding to learning from EQUALS/ GEMFA. Best practice examples on portfolio MEL developed.</td>
      <td>PrOF guide updated. Key guidance documents developed and shared, in response to learning from EQUALS/GEMFA and wider demand.</td>
      <td>PrOF guide updated. Key guidance documents developed and shared, in response to learning from EQUALS/GEMFA and wider demand.</td>
    </tr>
  </tbody>
</table>

<h3>Outcome 3: Learning from evaluations is shared and used in decision making</h3>

<p>As a learning organisation, drawing out and sharing lessons from our evaluations is essential. Using evaluation findings and other evidence enhances our impact on the ground, efficiency in how we work, and the value for money of our investments. To support this, we must improve access to and knowledge about evaluations across the organisation. We will seek to:</p>

<ul>
  <li>
    <p>improve supply of and access to evaluations for all FCDO staff</p>
  </li>
  <li>
    <p>promote and track the use of evaluation findings</p>
  </li>
  <li>
    <p>encourage a learning environment, where evaluations can support reflection on both success and failure. Improving our repositories of evaluation findings, signposting teams to evaluations with similar themes or methods, and generating overviews and syntheses of existing evaluative evidence can help us understand what has or has not worked in multiple instances and contexts and will mitigate the risk that learning from an evaluation starts and ends with the team that commission it</p>
  </li>
</ul>

<h4>Key actions and workstreams</h4>

<p>A combination of actions working coherently together will enable FCDO to promote learning from evaluation. This includes:</p>

<h4>3.1 Improve management information of evaluations:</h4>

<p>We aim to have management information (MI) systems that provide a picture of all evaluations in FCDO, and allow us to track each evaluation across its lifespan. This means enhancing interoperability and consistency across multiple data sources. Doing so will increase opportunities for knowledge sharing and collaboration across teams, enabling staff to easily access evaluations on particular topics or using particular methods. The data will inform central insights and visibility work, support recommendations for strategic evaluation (see Outcome 1) and provide a tool for tracking the implementation of, and compliance to, the FCDO Evaluation Policy (see Outcome 2). It will enable us to provide accurate updates to accountability and scrutiny bodies on existing and pipeline evaluations and help us to provide the right support to teams to ensure high-quality and transparent evaluations.</p>

<h4>3.2 Generate Evaluation Insights:</h4>

<p>Evaluation Insights are learning documents which synthesise evaluative evidence. Evaluation Insights could cover areas such as: ethical processes within evaluations; evaluation supplier performance; thematic syntheses of existing evaluation studies; or, improvement of evaluation methods. Insight reports will support the production of evaluation guidance and practical learning, including through related training and events. This work will be aligned with other sources of learning, such as ICAI reviews and internal evidence work.</p>

<h4>3.3 Improve communication and visibility:</h4>

<p>We will provide and promote accessible information on evaluations to the wider organisation, including those less familiar with evaluation evidence. A communications and visibility plan will be developed and will include: keeping internal and external repositories of evaluations up to date; developing accessible summaries through an occasional newsletter/spotlight communication; convening and promoting evaluation seminars and events with specialist and wider FCDO audiences; and engaging with stakeholders across the FCDO to promote uptake of evaluation findings by linking to existing knowledge management and evidence communications processes. It will outline specific activities to engage senior leaders, and advocate for the proportionate application of evaluative tools in all directorates and posts. We will develop plans for generating and sharing case studies on how evaluations have had impact, as well as monitoring the uptake of evaluation findings in programme design and wider decision making. We will make use of internal communications channels (e.g., Teams, Yammer, the intranet) to highlight key findings of published evaluations to create and contribute to a culture of sharing and collaboration. This will be closely aligned to the work undertaken under Outcome 4.</p>

<h4>3.4 Share learning across HMG and with international partners:</h4>

<p>FCDO has much to share and much to learn from others working across government and across the development and diplomacy sectors. We will mobilise opportunities to disseminate results and learning from evaluations in these external forums, as well as promoting external learning events to FCDO staff. In particular, the Evaluation Unit and broader cadre will connect with those managing similar challenges, such as those working on international influencing activities or ODA-spending departments. Improved management information and knowledge management systems will also support sharing with external audiences. We will continue our engagement with key external networks such as the OECD Development Assistance Committee EvalNet, the C19 Global Evaluation Coalition and Multilateral Organisation Performance Assessment Network (MOPAN).</p>

<p>We will monitor our progress against each of these activities on an annual basis - Table 3 outlines the key milestones.</p>

<h4>Table 3: Key milestones for workstreams under Outcome 3</h4>

<table>
  <thead>
    <tr>
      <td></td>
      <th scope="col">By April 2023 (+1 year)</th>
      <th scope="col">By April 2024 (+2 years)</th>
      <th scope="col">By April 2025 (+3 years)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">3.1 Improve management information of evaluations</th>
      <td>Improved MI system developed and piloted.  External evaluation repository up to date on Gov.uk and relevant internal libraries.</td>
      <td>Comprehensive, up-to-date evaluation database accessible to FCDO staff and being used by Evaluation Unit and Evaluation Advisers. External evaluation repository regularly updated on Gov.uk and relevant internal libraries.</td>
      <td>Continuation of external evaluation repository, regularly updated on Gov.uk and relevant internal libraries, linked to MI system to ensure its searchable by geography and sector.</td>
    </tr>
    <tr>
      <th scope="row">3.2 Generate Evaluation Insights</th>
      <td>Plan for insights work established and insights work underway.</td>
      <td>2-3 evaluation insights products complete.</td>
      <td>4-6 evaluation insights products complete (cumulative).</td>
    </tr>
    <tr>
      <th scope="row">3.3 Improve communication and visibility</th>
      <td>Communication plan developed. Development of communication products including spotlight newsletters, evaluation impact case studies. 1-2 evaluation learning events. Annual uptake survey designed and implemented.</td>
      <td>Regular dissemination of communication products including spotlight newsletters, evaluation impact case studies. 3-4 evaluation learning events (cumulative). Annual uptake survey implemented.</td>
      <td>Regular communication products including spotlight newsletters, evaluation impact case studies. 5-6 learning events (cumulative). Annual uptake survey implemented.</td>
    </tr>
    <tr>
      <th scope="row">3.4 Share learning across HMG and international partners</th>
      <td>1-2 evaluation learning events open to external participants and/or including external speakers. Presentation of evaluation findings at 1-2 externally hosted events.</td>
      <td>3-4 evaluation learning events open to external participants and/or including external speakers (cumulative). Presentation of evaluation findings at 3-4 externally hosted events (cumulative).</td>
      <td>5-6 evaluation learning events open to external participants and/or including external speakers (cumulative). Presentation of evaluation findings at 5-6 externally hosted events (cumulative).</td>
    </tr>
  </tbody>
</table>

<h3>Outcome 4: FCDO has an evaluative culture, the right expertise and capability</h3>

<p>To ensure that high-quality, timely, relevant evidence is generated and used, FCDO needs to ensure that: (i) appropriate expertise is in place to produce and use evaluation evidence; (ii) FCDO decision making processes include consideration of evaluation and its evidence, and (iii) FCDO’s culture and incentives encourage production, sourcing and use of evaluation evidence. Expertise is essential to assessing where evaluation is needed, identifying the appropriate evaluation approach and design, implementing evaluations to a high quality, and sharing the results and learning effectively.</p>

<p>We will work towards having sufficient evaluation skills across the diplomatic, policy, programme delivery and analytical professions to conduct and commission good quality monitoring and evaluation at FCDO. Across FCDO, distributed across the network of country posts and within central teams, there are accredited Evaluation Advisers and others fully or partly working in monitoring, evaluation and learning, with skills on the planning, generation and use of evaluation evidence. This pool of specialists needs to be sufficient in number to meet needs, include an element of flexibility to respond to emerging priorities and scope to contribute to the wider evaluation system, and advisers’ skills must be maintained and updated. We must continue to generate innovative methodologies for hard to measure topics, complex contexts and adaptive approaches, generating evidence to fill critical gaps and improving our capability to use new methodologies going forward.</p>

<p>There is potential to build capability for all FCDO staff to find, appraise and use evaluation evidence, to ensure a minimum evaluation literacy across the organisation. This capability is particularly important to build in non-programming areas, where the production and use of evaluation is less institutionalised, and in areas which are more challenging to evaluate. We will provide a structured continuing professional development offer for both mainstreaming minimum evaluation standards as well as specialised training for experts.</p>

<p>To build demand for evaluation we will work to promote its value through demonstration: the Evaluation Portfolio Assessments and thematic evaluations under the Evidence Fund (Outcome 1) provide opportunities to profile how and why evaluation adds value. In addition, targeted deployment of adviser resource to emerging priorities can support the use of evaluation capability where it is needed most. Increasing the communications and visibility of evaluation evidence (Outcome 3) will contribute to putting a spotlight on evaluation’s usefulness and examples of the impact of evaluation evidence. These actions will promote the benefit of evaluation to FCDO staff, including senior leaders.</p>

<h4>Key actions and workstreams</h4>

<h4>4.1 Develop organisational capability, individual skills and training:</h4>

<p>The Evaluation and Government Social Research (GSR) Head of Profession (HoP) will lead work to develop an organisational evaluation capability offer, which is aligned with both the Data Driven Diplomacy and Development (4D) and the cross-government Analysis Function capability offers. This organisational and individual capacity building will serve to mainstream minimum evaluation literacy across FCDO (a level 1 and level 2 offer), using primarily the International Academy and considering the right balance across different grades including senior leaders. It will also build, maintain and extend knowledge and experience for capability level 3 (Proficient), and level 4 (Expert). This will enable FCDO to develop a pipeline of relevant deployable expertise plus ensure FCDO expert skills are up-to-date with latest best practice and innovations. EQUALS 2 will provide short-term technical assistance as a backstop, ensuring technical coverage and high-quality evaluation in a broad range of specialisms across policies, geographies and methodologies.</p>

<h4>4.2 Lead the Evaluation and Government Social Research (GSR) Cadre:</h4>

<p>The GSR Technical Competency Framework, developed by Her Majesty’s Treasury in conjunction with individual departments, sets the minimum standards needed to accredit to the Government Social Research profession. The aligned FCDO framework will form the basis for assessing our monitoring, evaluation and learning expertise through accreditation. Facilitated by the Evaluation and GSR HoP, FCDO advisers will be able to take advantage of the GSR Continuing Professional Development and cross-HMG networking opportunities on offer. The HoP will represent FCDO in cross-HMG GSR Board and Standing Meetings, ensuring FCDO is able to take full advantage of the resources on offer, including access to a larger pool of skilled personnel to fill staffing gaps.</p>

<h4>4.3 Advise on deployment of evaluation staff:</h4>

<p>Decisions about the mix of skills and expertise in staffing is devolved to senior leadership within directorates and posts across the FCDO. A regular review of deployment of evaluation expertise across the business will be conducted, to identify gaps and advocate for appropriate coverage. FCDO will look at cross-government pipeline options such as the GSR mainstream campaign.</p>

<h4>4.4 Develop and test innovative methods for evaluation and evidence synthesis through the Centre of Excellence for Development Impact and Learning (CEDIL):</h4>

<p>FCDO has funded CEDIL since 2017 to develop and test innovative methods for evaluation and evidence synthesis in international development contexts, and to build the evidence base on research uptake and use in decision-making. It does this through evaluating complex interventions, enhancing evidence transferability, and producing learning on improving research uptake. CEDIL is pushing what is possible in evaluation, through developing methods and sharing learning on methods with FCDO, developing our capacities and abilities to measure more complex areas.</p>

<h4>4.5 Advance thinking on evidence-based influencing approaches:</h4>

<p>The Evaluation Unit is leading a workstream on evidence-based influencing, working with teams and posts across the organisation. The aims are to build on existing expertise and capabilities, including diplomatic tradecraft, to develop and professionalise FCDO influencing, which will contribute to achieving FCDO short-term outcomes and longer-term strategic goals. Key work strands include: clarifying and communicating the definitions and measures of influencing; developing staff capabilities on influencing; measuring influencing results and impact; and using the evidence base to inform decision making. Outputs and learning will be shared across FCDO including through internal and external cross HMG working groups, the Evaluation Cadre and other specialist cadres. Technical assistance is being provided to a range of Foreign Secretary high priority work. The Evaluation Unit is working with International Academy to develop a suite of training for staff at all levels on diplomatic influencing including how to monitor, evaluate and learn from influencing. Additional workstreams will be developed to continue to improve how we measure influencing results and impact and better use the evidence base to influence strategy, policy and programming in the short- and long-term.</p>

<p>We will monitor our progress against each of these activities on an annual basis - Table 4 outlines the key milestones.</p>

<h4>Table 4: Key milestones for workstreams under Outcome 4</h4>

<table>
  <thead>
    <tr>
      <td></td>
      <th scope="col">By April 2023 (+1 year)</th>
      <th scope="col">By April 2024 (+2 years)</th>
      <th scope="col">By April 2025 (+3 years)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">4.1 Develop organisational capability, individual skills and training</th>
      <td>4D &amp; Analytical Function aligned FCDO evaluation capability offer developed (Levels 1–4).</td>
      <td>50% FCDO staff successfully completed Level 1 Evaluation trainings.</td>
      <td>Evaluation capability offer reviewed &amp; revised.</td>
    </tr>
    <tr>
      <th scope="row">4.2 Lead the Evaluation and Government Social Research Cadre</th>
      <td>FCDO GSR Accreditation round complete.</td>
      <td>Professional Development Conference held.</td>
      <td>FCDO GSR Accreditation round complete for FY24-25.  Professional Development Conference held for FY24-25.</td>
    </tr>
    <tr>
      <th scope="row">4.3 Advise on deployment of evaluation staff</th>
      <td>Mapping exercise of coverage across priority areas complete.</td>
      <td>Target to be determined by March 2023, depending on organisational design and structures.</td>
      <td>Target to be determined by March 2023, depending on organisational design and structures.</td>
    </tr>
    <tr>
      <th scope="row">4.4 Develop and test innovative methods for evaluation and evidence synthesis</th>
      <td>16 user-oriented summary products produced and published. 9 FCDO or public facing learning events.</td>
      <td>NA - programme ends April 2023.</td>
      <td>NA - programme ends April 2023.</td>
    </tr>
    <tr>
      <th scope="row">4.5 Advance thinking on evidence-based influencing approaches</th>
      <td>Evidence-base developed to inform design and roll out of diplomatic influencing training. Technical advice to FS priority areas delivered.</td>
      <td>Target to be determined by March 2023, depending on priorities.</td>
      <td>Target to be determined by March 2023, depending on priorities.</td>
    </tr>
  </tbody>
</table>

<h2>
<span class="number">3. </span> Implementation of the strategy</h2>

<h3>Roles and responsibilities</h3>

<p>Operationalising this strategy is the responsibility of the Head of the Evaluation Unit and the Head of the Evaluation and Government Social Research Profession. They are accountable for its delivery, supported directly by Evaluation Advisers and Programme Managers within the Evaluation Unit and by advisers working on monitoring, evaluation and learning across FCDO.</p>

<p>An efficient evaluation system is reliant upon two-way communication between the centre and the decentralised teams situated across the FCDO global footprint. Embedded advisers are key to promoting and implementing evaluation activities which contribute towards the outcomes in this strategy. Advisers should be aware of and make use of the services and support offered by the Evaluation Unit and the Evaluation Head of Profession; the centre should provide strategic direction, guidance, backstopping and advocacy to support embedded advisers. As a minimum requirement, advisers will stay informed of central developments and engage in opportunities to advance their own capabilities. In line with other FCDO cadres, Evaluation Advisers are expected to use their professional expertise and contribute up to 10% of their time annually to meet key business objectives. They should also provide updates from their own area of work, including contributing to central MI, sharing case studies and evaluation impact, and contributing to learning and dissemination activities.</p>

<p>The strategy depends on effective engagement and co-working with the following groups:</p>

<ul>
  <li>staff across the business, especially senior officials: We recognise the importance of buy-in from all parts of the office, especially senior leaders. Our workstreams will be designed to target senior leaders as necessary, advocating for appropriate use of evaluative tools to support decision-making and supporting development of evaluation capacity and capability within teams</li>
  <li>Research and Evidence Directorate and the Tech and Analysis Directorate: The Evaluation Unit will engage key research and data specialists on relevant workstreams to ensure learning and knowledge management activities are complementary. Ensuring a shared agenda with the Chief Scientific Adviser is essential to supporting evidence use; we will continue to collaborate with the Research and Evidence Directorate on a range of activities including implementation of the Evidence Fund, evidence mapping and synthesis activities, and generation of experimental and quasi-experimental evaluation evidence. The Heads of Profession for Statistics and Evaluation will continue a close working relationship to ensure support for advisers is coherent. The Evaluation Unit will also engage the FCDO Centre for Delivery to maximise join up and opportunities to collaborate on the continual review and refinement of the PrOF and other delivery initiatives</li>
  <li>Investment Committee: We will seek steers and approval for our approach, ensuring it remains relevant and appropriate to organisational priorities. Endorsement from the Investment Committee also communicates to others the importance FCDO places on evaluation and evidence</li>
  <li>other government departments, especially the Joint Funds Unit and those spending ODA: We will engage with evaluation teams in other government departments, to share learning about approaches, methods and themes, and ensure coherence across shared interests. This is particularly relevant for departments with an international angle to their work, or where we have partnerships such as through the Joint Funds Unit. Given the additional accountability requirements on ODA, and the need for coherence across government, we will continue to ensure open communication channels, share good practice, and provide evaluation support services to departments with ODA-spend through EQUALS 2</li>
</ul>

<h3>Tracking progress</h3>

<p>A written update on progress against the strategy will be provided to the Investment Committee on an annual basis.</p>

<p>This strategy is valid from 2022 to 2025. A new strategy will be developed and finalised in advance of the next Spending Review period, which takes into account progress on this strategy and any changes to the organisational design and priorities.</p>

<h2>Annex 1: Map of workstreams and outcomes</h2>

<figure class="image embedded"><div class="img"><img alt="" src="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/image_data/file/154387/Evaluation-strategy-annex1-GOVUK.png"></div></figure>

<table>
  <thead>
    <tr>
      <td></td>
      <th scope="col">Strategic Evaluation Evidence</th>
      <th scope="col">Evaluation evidence is systematic and objective</th>
      <th scope="col">Learning is shared and used in decision making</th>
      <th scope="col">Evaluative culture, evaluation expertise and capability</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th scope="row">Outcomes</th>
      <td>Relevant, timely, high-quality evaluation evidence is produced and used in areas of strategic importance for FCDO, HMG and international partners</td>
      <td>users have confidence in the finding generated from evaluation of FCDO interventions, policies and strategies</td>
      <td>Evaluation finding are accessible and actively communicated in a timely and useful way to inform future strategy, programme and policy design</td>
      <td>FCDO is sufficiently resourced with skilled advisers possessing up to date knowledge of evaluation; minimum standards of evaluation literacy are mainstreamed across the organisation</td>
    </tr>
    <tr>
      <th scope="row">Internal outcomes</th>
      <td>Drawing lessons and inform strategy at portfolio/sector level, <br> more rigorous evaluation evidence to improve use in FCDO decision making, <br> evaluation budgets used to generate the most learning</td>
      <td>Minimum principles and standards for evaluation and when to use,<br> Evaluations meet expected quality standards in design and outputs, <br> pre-qualified suppliers used to maximise quality</td>
      <td>Improved access to knowledge about evaluations, <br> evaluations inform future programme/policy design in FCDO, <br> uphold reputation on evaluation across HMG and international sector</td>
      <td>Innovative methodologies for evidence on hard to measure topics and contexts, <br> evaluation skills throughout the organisation to conduct, commission and use good quality evaluations</td>
    </tr>
    <tr>
      <th scope="row">Workstreams</th>
      <td>M&amp;E assessment in business cases. <br> Evaluation portfolio assessments. <br> R&amp;D central evaluations. <br> Thematic evaluations. <br> Programme on Impact Evaluations</td>
      <td>Evaluation policy. <br> Quality assurance service. <br> Evaluation procurement framework. <br> Guidance, templates and best practice</td>
      <td>Improved evaluation MI. <br> Evaluation insights. <br> Communication and visibility. <br> International and xHMG learning. <br>
</td>
      <td>Organisational capacity, individual skills and training. <br> Evaluation and GSR cadre leadership. <br> Deployment of evaluation staff. <br> Innovative methods development. <br> Evidence based influencing</td>
    </tr>
  </tbody>
</table>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li role="doc-endnote">
  <p>
    For this document and in line with HM Treasury’s Central Government guidance on evaluation (<a class="govuk-link" href="https://www.gov.uk/government/publications/the-magenta-book">Magenta Book</a>) and OECD-DAC definitions, we define evaluation as the systematic and objective assessment of an on-going or completed FCDO project, programme, strategy or policy, its design, implementation, and results.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:1" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    The Evaluation Taskforce is a joint Cabinet Office-HMT unit providing specialist support to ensure evidence and evaluation sits at the heart of spending decisions. https://www.gov.uk/government/organisations/evaluation-task-force<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:2" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    <a class="govuk-link" href="https://www.legislation.gov.uk/ukpga/2015/12/pdfs/ukpga_20150012_en.pdf" rel="external">https://www.legislation.gov.uk/ukpga/2015/12/pdfs/ukpga_20150012_en.pdf</a><a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:3" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    The Evaluation Programme Operating Framework Guide, available internally for FCDO staff, offers further details on deciding whether to evaluate.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:4" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    A condition of the 2021 Spending Review settlement requires the FCDO to provide HM Treasury and the Evaluation Task Force with an assessment with an assessment of how much evidence supports the 20 highest cost policy areas/programmes, using the Nesta Standards of Evidence.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:5" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Based on the HMG Magenta book definition of evaluation and the OECD Development Assistance Committee (DAC) Network on Development Evaluation, we define evaluation as:&nbsp;a systematic and objective assessment of the design, implementation and outcomes of an intervention, programme or policy, or a portfolio of interventions, programmes or policies in a particular area or theme. It involves understanding the process behind implementation, and the effects or outcomes, for whom and why. It identifies what can be improved, and where appropriate, can estimate the overall impacts and cost-effectiveness.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:6" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Magenta Book 2020: <a class="govuk-link" href="https://www.gov.uk/government/publications/the-magenta-book">https://www.gov.uk/government/publications/the-magenta-book</a>; Government Social Research: Publication protocol updated 2021: <a class="govuk-link" href="https://www.gov.uk/government/publications/government-social-research-publication-protocols">https://www.gov.uk/government/publications/government-social-research-publication-protocols</a>; National Audit Office review on evaluation in government 2021 <a class="govuk-link" href="https://www.nao.org.uk/report/evaluating-government-spending/" rel="external">https://www.nao.org.uk/report/evaluating-government-spending/</a><a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:7" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This service is also available to other government departments for their ODA spend. EQUALS 2 is not always appropriate (e.g. where partners have their own QA systems, or for highly sensitive material); alternative mechanisms for independent QA are outlined in the policy.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:8" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Templates for encouraging best practice on evaluation products, which might include templates for terms of reference, management responses, evaluation reports etc.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:9" role="doc-backlink">↩</a>
  </p>
</li>
  </ol>
</div>

</div>


</div>
</div>
  </div>

  <div class="sticky-element" data-sticky-element="">
    <a class="govuk-link app-c-back-to-top dont-print" href="#contents">
    <svg class="app-c-back-to-top__icon" focusable="false" height="17" viewBox="0 0 13 17" width="13" xmlns="http://www.w3.org/2000/svg">
      <path d="M6.5 0L0 6.5 1.4 8l4-4v12.7h2V4l4.3 4L13 6.4z" fill="currentColor"></path>
    </svg>
    Contents
</a>

    <div class="sticky-element__print-link">
      
<div class="gem-c-print-link govuk-!-display-none-print govuk-!-margin-top-0 govuk-!-margin-bottom-6">
    <button class="govuk-link govuk-body-s gem-c-print-link__button" data-module="print-link">Print this page</button>
</div>
    </div>
  </div>
</div>

    </main>