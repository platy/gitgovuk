<main class="html-publication" lang="en" role="main">
      

  <div class="publication-external">
    <ul class="organisation-logos">
        <li class="organisation-logos__logo">
          
<div class="gem-c-organisation-logo brand--cabinet-office">
    <a class="gem-c-organisation-logo__container gem-c-organisation-logo__link brand__border-color" href="/government/organisations/centre-for-data-ethics-and-innovation">
      <span class="gem-c-organisation-logo__name">Centre for<br>Data Ethics<br>and Innovation</span>
</a>
</div>
        </li>
    </ul>
  </div>

  <header class="gem-c-inverse-header  gem-c-inverse-header--padding-top ">
    
  

<div class="gem-c-title gem-c-title--inverse govuk-!-margin-top-8 govuk-!-margin-bottom-0">
      <span class="govuk-caption-xl gem-c-title__context">
    Policy paper
  </span>


  <h1 class="gem-c-title__text govuk-heading-xl">
    Responsible Innovation in Self-Driving Vehicles
  </h1>
</div>
  <p class="publication-header__last-changed">Published 19 August 2022</p>

  </header>






<div class="sidebar-with-body">
  <div class="govuk-grid-row">
      <div class="govuk-grid-column-one-quarter-from-desktop contents-list-container">
          <nav aria-label="Contents" class="gem-c-contents-list" data-module="gem-track-click" role="navigation">
    <h2 class="gem-c-contents-list__title">
      Contents
</h2>
    <ol class="gem-c-contents-list__list">
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 1" data-track-category="contentsClicked" data-track-label="#introduction" data-track-options="{&quot;dimension29&quot;:&quot;Introduction&quot;}" href="#introduction">Introduction</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 2" data-track-category="contentsClicked" data-track-label="#glossary" data-track-options="{&quot;dimension29&quot;:&quot;Glossary&quot;}" href="#glossary">Glossary</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 3" data-track-category="contentsClicked" data-track-label="#regulatory-lifecycle" data-track-options="{&quot;dimension29&quot;:&quot;Regulatory lifecycle&quot;}" href="#regulatory-lifecycle">Regulatory lifecycle</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 4" data-track-category="contentsClicked" data-track-label="#context" data-track-options="{&quot;dimension29&quot;:&quot;Context&quot;}" href="#context">Context</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 5" data-track-category="contentsClicked" data-track-label="#summary-of-recommendations" data-track-options="{&quot;dimension29&quot;:&quot;Summary of recommendations&quot;}" href="#summary-of-recommendations">Summary of recommendations</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 6" data-track-category="contentsClicked" data-track-label="#road-safety" data-track-options="{&quot;dimension29&quot;:&quot;\n1.  Road safety&quot;}" href="#road-safety"><span class="gem-c-contents-list__number">1. </span><span class="gem-c-contents-list__numbered-text">Road safety</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 7" data-track-category="contentsClicked" data-track-label="#data-privacy" data-track-options="{&quot;dimension29&quot;:&quot;\n2.  Data privacy&quot;}" href="#data-privacy"><span class="gem-c-contents-list__number">2. </span><span class="gem-c-contents-list__numbered-text">Data privacy</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 8" data-track-category="contentsClicked" data-track-label="#fairness" data-track-options="{&quot;dimension29&quot;:&quot;\n3.  Fairness&quot;}" href="#fairness"><span class="gem-c-contents-list__number">3. </span><span class="gem-c-contents-list__numbered-text">Fairness</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 9" data-track-category="contentsClicked" data-track-label="#explainability" data-track-options="{&quot;dimension29&quot;:&quot;\n4.  Explainability&quot;}" href="#explainability"><span class="gem-c-contents-list__number">4. </span><span class="gem-c-contents-list__numbered-text">Explainability</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 10" data-track-category="contentsClicked" data-track-label="#data-sharing" data-track-options="{&quot;dimension29&quot;:&quot;\n5.  Data sharing&quot;}" href="#data-sharing"><span class="gem-c-contents-list__number">5. </span><span class="gem-c-contents-list__numbered-text">Data sharing</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 11" data-track-category="contentsClicked" data-track-label="#public-trust" data-track-options="{&quot;dimension29&quot;:&quot;\n6.  Public trust&quot;}" href="#public-trust"><span class="gem-c-contents-list__number">6. </span><span class="gem-c-contents-list__numbered-text">Public trust</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 12" data-track-category="contentsClicked" data-track-label="#governance" data-track-options="{&quot;dimension29&quot;:&quot;\n7.  Governance&quot;}" href="#governance"><span class="gem-c-contents-list__number">7. </span><span class="gem-c-contents-list__numbered-text">Governance</span></a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 13" data-track-category="contentsClicked" data-track-label="#next-steps" data-track-options="{&quot;dimension29&quot;:&quot;Next steps&quot;}" href="#next-steps">Next steps</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 14" data-track-category="contentsClicked" data-track-label="#Annex-A" data-track-options="{&quot;dimension29&quot;:&quot;Annex A: Safe and Ethical Operational Concept and Safety Management Systems&quot;}" href="#Annex-A">Annex A: Safe and Ethical Operational Concept and Safety Management Systems</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 15" data-track-category="contentsClicked" data-track-label="#annex-b-list-of-recommendations" data-track-options="{&quot;dimension29&quot;:&quot;Annex B: List of recommendations&quot;}" href="#annex-b-list-of-recommendations">Annex B: List of recommendations</a>

        </li>
        <li class="gem-c-contents-list__list-item gem-c-contents-list__list-item--numbered">
          <a class="gem-c-contents-list__link govuk-link govuk-link--no-underline" data-track-action="content_item 16" data-track-category="contentsClicked" data-track-label="#list-of-abbreviations" data-track-options="{&quot;dimension29&quot;:&quot;List of Abbreviations&quot;}" href="#list-of-abbreviations">List of Abbreviations</a>

        </li>
    </ol>
</nav>
        
<div class="gem-c-print-link govuk-!-display-none-print govuk-!-margin-top-0 govuk-!-margin-bottom-6">
    <button class="govuk-link govuk-body-s gem-c-print-link__button" data-module="print-link">Print this page</button>
</div>
      </div>

    <div class="print-wrapper">
      <div class="print-meta-data">
        <p>
  <img class="print-meta-data-licence" src="/assets/government-frontend/open-government-licence-min-93b6a51b518ff99714a1aa2a7d2162735c155ec3cb073c75fb88b2a332fa83d3.png">
</p>
<p>
  © Crown copyright 2022
</p>
<p>
  This publication is licensed under the terms of the Open Government Licence v3.0 except where otherwise stated. To view this licence, visit <a href="https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3">nationalarchives.gov.uk/doc/open-government-licence/version/3</a> or write to the Information Policy Team, The National Archives, Kew, London TW9 4DU, or email: <a href="mailto:psi@nationalarchives.gov.uk">psi@nationalarchives.gov.uk</a>.
</p>
<p>
  Where we have identified any third party copyright information you will need to obtain permission from the copyright holders concerned.
</p>
<p>
  This publication is available at https://www.gov.uk/government/publications/responsible-innovation-in-self-driving-vehicles/responsible-innovation-in-self-driving-vehicles
</p>


      </div>
    </div>

    <div class="main-content-container">
      <div class="gem-c-govspeak-html-publication">
  
<div class="gem-c-govspeak govuk-govspeak " data-module="govspeak">
    
    
        <div class="govspeak">
<h2>Introduction</h2>

<p>Self-driving vehicles have the potential to radically transform the UK’s roads. They offer the opportunity to deliver significant improvements to road safety and efficiency by reducing driver error, can improve accessibility by enhancing mobility for people unable to drive, and have the potential to reduce emissions. There is also a significant economic opportunity: the automotive and digital sectors are already important contributors to the UK economy and self-driving vehicles could grow this considerably. Recent <a class="govuk-link" href="https://www.gov.uk/government/publications/connected-and-automated-vehicles-market-forecast-2020">research</a> commissioned by the Department for Transport has shown that by 2035, the UK connected and automated vehicles market could be worth £41.7 billion.</p>

<p>To enable these benefits and achieve the government’s ambition to <a class="govuk-link" href="https://www.gov.uk/government/news/uk-on-the-cusp-of-a-transport-revolution-as-self-driving-vehicles-set-to-be-worth-nearly-42-billion-by-2035">‘make the UK the best place in the world to deploy connected and automated vehicles’</a> manufacturers need clarity about the regulatory landscape they are operating in. The general public also needs to have confidence in the safety, fairness and trustworthiness of these vehicles.</p>

<p>To provide this clarity and confidence, the legal and regulatory frameworks that govern conventional vehicles and their drivers will need to be updated. Under our current legal and regulatory systems, we licence drivers as competent to drive and then hold them accountable for their actions. In the context of vehicles that are self-driving, we will need new mechanisms to ensure that the systems these vehicles use, and the organisations that develop and deploy them, are similarly held accountable for performing in a safe and ethical manner.</p>

<p>With the right design, regulation and governance can actively promote innovation. As the UK Government’s ‘Plan for Digital Regulation’ <a class="govuk-link" href="https://www.gov.uk/government/publications/digital-regulation-driving-growth-and-unlocking-innovation">puts this</a>, ‘well-designed regulation can have a powerful effect on driving growth and shaping a thriving digital economy and society, whereas poorly-designed or restrictive regulation can dampen innovation…the right rules can help people trust the products and services they’re using, which in turn can drive take-up and further consumption, investment and innovation’.</p>

<p>Building on the <a class="govuk-link" href="https://s3-eu-west-2.amazonaws.com/lawcom-prod-storage-11jsxou24uy7q/uploads/2022/01/Automated-vehicles-joint-report-cvr-03-02-22.pdf" rel="external">recent proposals</a> set out by the Law Commissions, this report provides a comprehensive view of how these proposals can be supported by a responsible and trustworthy regulatory and assurance framework. This report takes a broad view of the factors that are likely to deliver public trust: safety, data privacy, and fairness. We also look at the areas that will be important enablers to responsible innovation: facilitating sufficient explainability to ensure accountability, data sharing, promoting public trust, and effective governance.</p>

<p>The flexible, pro-innovation approach taken in this report furthers the government’s approach to the regulation of AI and its intent to establish <a class="govuk-link" href="https://www.gov.uk/government/publications/national-ai-strategy">‘the most trusted and pro-innovation system for AI governance in the world’</a>. It also supports the CDEI’s programme of work on AI Assurance, which seeks to achieve <a class="govuk-link" href="https://www.gov.uk/government/publications/the-roadmap-to-an-effective-ai-assurance-ecosystem">‘effective, pro-innovation governance of AI’</a>.</p>

<p>These recommendations aim to ensure a fair, trustworthy and proportionate approach to the regulation and governance of self-driving vehicles to build public trust and confidence in their use, which in turn will drive adoption and innovation. They have been shaped by the expert contributions of Professor John McDermid and Professor Jack Stilgoe and through engagement with key stakeholders, including the Centre for Connected and Autonomous Vehicles (<abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr>), the Law Commission of England and Wales and the Scottish Law Commission, the Information Commissioner’s Office, members of the Centre for Data Ethics and Innovation Advisory Board, Home Office, the Office of the Biometrics and Surveillance Camera Commissioner, the Driver and Vehicle Standards Agency, and the Vehicle Certification Agency.</p>

<p>The views expressed in this report are those of the Centre for Data Ethics and Innovation and will support the Department for Transport in delivering ‘Connected &amp; Automated Mobility 2025: realising the benefits of self-driving vehicles’, a roadmap which commits to developing a new legislative framework that builds trust in self-driving vehicles while enabling innovation. In particular, this report will inform the design of the new safety framework for self-driving vehicles, proposing detailed recommendations on what features and capabilities a new safety framework for self-driving vehicles will need to possess, and how to manage interdependencies between different parts of the regulatory ecosystem. Following consultation, the Department for Transport expects to publish further guidance on what constitutes a sufficient safety case by Authorised Self-Driving Entity (<abbr title="Authorised Self-Driving Entity">ASDE</abbr>) and No-User-in-Charge (<abbr title="No User-in-Charge">NUiC</abbr>) Operators, which will be shaped by the recommendations of this report. More broadly, this report will guide the Department for Transport in developing secondary legislation that will set out the details of the requirements and processes of the new legislative framework. This secondary legislation is due to be consulted on in 2023, marking the next stage of an ongoing public dialogue about how self-driving vehicles should be governed.</p>

<h2>Glossary</h2>

<p><strong>Authorisation authority</strong>: A new role recommended by the Law Commissions. ‘It will be the government agency responsible for the second stage (authorisation) of <abbr title="Automated Vehicle">AV</abbr> safety assurance in Great Britain. When authorising the vehicle, the authorisation authority will assess each of the vehicle’s <abbr title="Automated Driving System(s)">ADS</abbr> features and specify those which are ‘self-driving’. The authorisation authority will also assess whether the entity putting the vehicle forward for authorisation has the reputation and financial standing required to be an <abbr title="Authorised Self-Driving Entity">ASDE</abbr>’.<sup role="doc-noteref"><a class="govuk-link" href="#fn:1" rel="footnote">[footnote 1]</a></sup></p>

<p><strong>Authorised Self-Driving Entity (<abbr title="Authorised Self-Driving Entity">ASDE</abbr>)</strong>: A new legal actor proposed by the Law Commissions. ‘It is the entity that puts an <abbr title="Automated Vehicle">AV</abbr> forward for authorisation as having self-driving features. It may be the vehicle manufacturer, or a software designer, or a joint venture between the two’.<sup role="doc-noteref"><a class="govuk-link" href="#fn:2" rel="footnote">[footnote 2]</a></sup></p>

<p><strong>Automated Vehicle (<abbr title="Automated Vehicle">AV</abbr>)</strong>: ‘A general term used to describe vehicles which can drive themselves without being controlled or monitored by an individual for at least part of a journey’.</p>

<p><strong>Data minimisation</strong>: Under the data minimisation principle of UK <abbr title="General Data Protection Regulation">GDPR</abbr>, [Personal data shall be] ‘adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed’.<sup role="doc-noteref"><a class="govuk-link" href="#fn:4" rel="footnote">[footnote 4]</a></sup></p>

<p><strong>Data protection by default</strong>: As <a class="govuk-link" href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/accountability-and-governance/data-protection-by-design-and-default/#dpd3" rel="external">defined by the <abbr title="Information Commissioner’s Office">ICO</abbr></a>, ‘data protection by default requires you to ensure that you only process the data that is necessary to achieve your specific purpose. It links to the fundamental data protection principles of data minimisation and purpose limitation’.</p>

<p><strong>Data protection by design</strong>: As <a class="govuk-link" href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/accountability-and-governance/data-protection-by-design-and-default/#dpd3" rel="external">defined by the <abbr title="Information Commissioner’s Office">ICO</abbr></a>, ‘data protection by design is ultimately an approach that ensures you consider privacy and data protection issues at the design phase of any system, service, product or process and then throughout the lifecycle’.</p>

<p><strong>Dynamic driving task</strong>: A term used by the Law Commissions to describe ‘the real-time operational and tactical functions required to operate a vehicle in on-road traffic. It includes steering, accelerating and braking together with object and event detection and response’.<sup role="doc-noteref"><a class="govuk-link" href="#fn:5" rel="footnote">[footnote 5]</a></sup></p>

<p><strong>Explainability</strong>: This term <a class="govuk-link" href="https://www.gov.uk/government/publications/cdei-publishes-review-into-bias-in-algorithmic-decision-making">refers to</a> ‘the ability to understand and summarise the inner workings of a model, including the factors that have gone into the model’.</p>

<p><strong>Lidar</strong>: An acronym that stands for ‘light detecting and ranging’. Lidar is a remote sensing method for determining ranges.</p>

<p><strong><abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr></strong>: A new legal actor proposed by the Law Commissions. As <a class="govuk-link" href="https://s3-eu-west-2.amazonaws.com/lawcom-prod-storage-11jsxou24uy7q/uploads/2022/01/Automated-vehicles-joint-report-cvr-03-02-22.pdf" rel="external">explained</a> by the Law Commissions: ‘Some features will be authorised for use without a user-in-charge. We refer to these as “No User-In-Charge” (NUIC) features. We recommend that when a <abbr title="No User-in-Charge">NUiC</abbr> feature is engaged on a road or other public place, the vehicle is overseen by a licensed NUIC Operator’.</p>

<p><strong>Operational Design Domain (<abbr title="Operational Design Domain">ODD</abbr>)</strong>: As defined by the Law Commissions, the <abbr title="Operational Design Domain">ODD</abbr> is ‘(…) the domain within which an automated driving system can drive itself. It may be limited by geography, time, type of road, weather or by some other criteria’.<sup role="doc-noteref"><a class="govuk-link" href="#fn:6" rel="footnote">[footnote 6]</a></sup></p>

<p><strong>Personal data</strong>: As set out in UK <abbr title="General Data Protection Regulation">GDPR</abbr>, ‘personal data’ refers to ‘any information relating to an identified or identifiable natural person (…)’.<sup role="doc-noteref"><a class="govuk-link" href="#fn:7" rel="footnote">[footnote 7]</a></sup></p>

<p><strong>Safety by design</strong>: Guiding the design with information derived from hazard and safety analysis both to achieve safety more cost-effectively and to make it easier to assure safety.</p>

<p><strong>User-in-charge (<abbr title="User-in-Charge">UiC</abbr>)</strong>: As defined by the Law Commissions, the <abbr title="User-in-Charge">UiC</abbr> is, ‘An individual who is in the vehicle and in position to operate the driving controls while a self-driving <abbr title="Automated Driving System(s)">ADS</abbr> feature is engaged. The user-in-charge is not responsible for the dynamic driving but must be qualified and fit to drive. They might be required to take over following a transition demand. They would also have obligations relating to non-dynamic driving task requirements including duties to maintain and insure the vehicle, secure loads carried by the vehicle and report accidents. An automated vehicle would require a user-in-charge unless it is authorised to operate without one’.<sup role="doc-noteref"><a class="govuk-link" href="#fn:8" rel="footnote">[footnote 8]</a></sup></p>

<p><strong>Vulnerable road users</strong>: Road users requiring extra care. As set out in the Highway Code, this includes pedestrians, particularly children, older or disabled people, cyclists, motorcyclists and horse riders.<sup role="doc-noteref"><a class="govuk-link" href="#fn:9" rel="footnote">[footnote 9]</a></sup></p>

<h2>Regulatory lifecycle</h2>

<p>The table below describes the key responsibilities of different actors across the regulatory lifecycle of a self-driving vehicle under our recommendations, from trials to the ongoing response and change needed to ensure vehicles remain safe. It is supplemented by a regulatory lifecycle flowchart in an annex to this report, that more fully describes the interdependencies between different parts of the regulatory lifecycle, and situates our recommendations within them.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Phases</strong></td>
      <td><strong>Trials and pre-authorisation</strong></td>
      <td><strong>Authorisation</strong></td>
      <td><strong>Operator Licensing (where <abbr title="No User-in-Charge">NUiC</abbr>)</strong></td>
      <td><strong>Ongoing monitoring</strong></td>
      <td><strong>Response and change</strong></td>
    </tr>
    <tr>
      <td>Key assurance question</td>
      <td>How do we develop the evidence that a vehicle is safe enough to drive itself?</td>
      <td>Should the vehicle be permitted to drive itself?</td>
      <td>Where the vehicle needs no driver in the vehicle, is there a responsible operator behind it?</td>
      <td>Are vehicles safe when used on the roads?</td>
      <td>&nbsp; How can real world evidence be used to continuously improve the system?</td>
    </tr>
    <tr>
      <td>Policy and advice</td>
      <td>
<strong><abbr title="Department for Transport">DfT</abbr> (advised by <abbr title="Committee on AV Ethics and Safety">CAVES</abbr>)</strong> issues guidance to (prospective) ASDEs, interpreting primary legislation, <abbr title="United Nations Economic Commission for Europe">UNECE</abbr> regulations, and technical standards, equality and data protection/surveillance issues</td>
      <td>
<strong><abbr title="Department for Transport">DfT</abbr> and regulatory agencies (advised by <abbr title="Committee on AV Ethics and Safety">CAVES</abbr>)</strong> interpret and apply legislation, regulations and <abbr title="Department for Transport">DfT</abbr> policy, including:<br><br>* Road rules<br>* Equality impacts<br>* Privacy/surveillance impacts<br>* Human-machine interfaces for drivers (handover) and other road users (labelling)</td>
      <td>
<strong><abbr title="Department for Transport">DfT</abbr> and regulatory agencies (advised by <abbr title="Committee on AV Ethics and Safety">CAVES</abbr>)</strong> interpret and apply legislation, regulations and <abbr title="Department for Transport">DfT</abbr> policy, including:<br><br>* Road rules<br>* Equality impacts<br>* Privacy/surveillance impacts<br>* Human-machine interfaces for drivers (handover) and other road users (labelling)</td>
      <td>
<strong><abbr title="Department for Transport">DfT</abbr></strong> publishes <abbr title="Automated Vehicle">AV</abbr> Safety reports, reviews systematic outcomes and (<strong>advised by <abbr title="Committee on AV Ethics and Safety">CAVES</abbr></strong>) considers revisions to policy and regulation</td>
      <td>
<strong><abbr title="Department for Transport">DfT</abbr></strong> publishes <abbr title="Automated Vehicle">AV</abbr> Safety reports, reviews systematic outcomes and (<strong>advised by <abbr title="Committee on AV Ethics and Safety">CAVES</abbr></strong>) considers revisions to policy and regulation</td>
    </tr>
    <tr>
      <td>Regulator(s)</td>
      <td>
<strong>Authorisation body</strong> reviews Vehicle Safety Case Reports (VSCRs)s, audits safety management system, and relevant type approval certificates<br><br><strong>Authorisation body and <abbr title="Authorised Self-Driving Entity">ASDE</abbr></strong> agree basis for authorisation, based on the type approval granted, agreed <abbr title="Vehicle Safety Case Report">VSCR</abbr>, <abbr title="Operational Design Domain">ODD</abbr>
</td>
      <td>
<strong>Authorisation body</strong> assesses suitability for self driving, including consistency with road rules, collision risks, equality impacts, privacy/data protection and driver interfaces and labelling<br><br><strong>Authorisation body</strong> issues authorisation of <abbr title="Automated Vehicle">AV</abbr> as capable of driving itself</td>
      <td>(where <abbr title="No User-in-Charge">NUiC</abbr>)<br><strong>Licensing body (or delegate)</strong> tests the deployment domain, in particular the suitability of remote operation<br><br><strong>Licensing body</strong> issues licence to operate a <abbr title="No User-in-Charge">NUiC</abbr> service</td>
      <td>
<strong>In-use regulator</strong> reviews notifiable events, and systemwide performance on safety, fairness and other outcomes, and issues regulatory notices where new forms of notifiable incident are identified</td>
      <td>
<strong>In-use regulator and/or collision investigator</strong> issues change instructions where remediation is required, regulatory sanctions, including traffic infringements, and potentially de-authorisation (in severe cases)<br><br><strong>In-use regulator</strong> reviews revised vehicle safety case reports and re-authorises <abbr title="Automated Vehicle">AV</abbr> if suitable</td>
    </tr>
    <tr>
      <td><abbr title="Authorised Self-Driving Entity">ASDE</abbr></td>
      <td>
<strong>(Prospective) <abbr title="Authorised Self-Driving Entity">ASDE</abbr></strong> trials potential self-driving system with safety driver and labelling in place, in line with a Safety Management System<br><br><strong><abbr title="Authorised Self-Driving Entity">ASDE</abbr></strong> develops and submits Vehicle Safety Case Reports and Safety Management System for Authorisation, on the basis of the agreed <abbr title="Operational Design Domain">ODD</abbr>
</td>
      <td>
<strong><abbr title="Authorised Self-Driving Entity">ASDE</abbr></strong> publishes authorisation notice, and summary of authorised safety case report<br><br><strong><abbr title="Authorised Self-Driving Entity">ASDE</abbr></strong> shares more detailed safety information with prospective <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>(s)</td>
      <td>&nbsp;</td>
      <td>
<strong><abbr title="Authorised Self-Driving Entity">ASDE</abbr></strong> conducts ongoing monitoring and reporting of notifiable incidents, including consistency of deployment with <abbr title="Operational Design Domain">ODD</abbr><br><br><strong><abbr title="Authorised Self-Driving Entity">ASDE</abbr></strong> produces regular aggregate outcome reports to the in-use regulator including safety, fairness&nbsp; privacy</td>
      <td>
<strong><abbr title="Authorised Self-Driving Entity">ASDE</abbr></strong> identifies and implements changes instructed by regulators, and considers changes proposed by <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s<br><br>Where de-authorised, <strong><abbr title="Authorised Self-Driving Entity">ASDE</abbr></strong> revises and submits vehicle safety case reports for re-authorisation</td>
    </tr>
    <tr>
      <td><abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr></td>
      <td>(where <abbr title="No User-in-Charge">NUiC</abbr>)<br><strong>(Prospective) <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr></strong> develops Deployment Safety Case Report on the basis of a Vehicle Safety Case Report, and Operator Safety Management System</td>
      <td>(where <abbr title="No User-in-Charge">NUiC</abbr>)<br><strong><abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr></strong> submits Operational Safety Case Report and Operator Safety Management System for Licensing</td>
      <td>(where <abbr title="No User-in-Charge">NUiC</abbr>)<br><strong><abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr></strong> publishes licence to operate and makes available to any passengers</td>
      <td>(where <abbr title="No User-in-Charge">NUiC</abbr>)<br><strong><abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr></strong> conducts ongoing monitoring and reporting of notifiable incidents, including consistency of deployment with <abbr title="Operational Design Domain">ODD</abbr>
</td>
      <td>(where <abbr title="No User-in-Charge">NUiC</abbr>)<br>Where <strong><abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr></strong> identifies remediation/improvement to address a non-notifiable incident, issues operator change proposal to the <abbr title="Authorised Self-Driving Entity">ASDE</abbr>
</td>
    </tr>
  </tbody>
</table>

<h2>Context</h2>

<p>The Centre for Data Ethics and Innovation (CDEI) was commissioned by the Centre for Connected and Autonomous Vehicles (<abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr>) to provide expert advice to inform future regulation and policy on self-driving vehicles. We use the acronym ‘<abbr title="Automated Vehicle">AV</abbr>’ to refer to self-driving vehicles as this is the commonly-used shorthand.</p>

<h3>Methodology</h3>

<p>The recommendations have been developed by CDEI in consultation with subject matter experts. They have been informed by primary research and interviews with 32 experts from across industry, academia and the public sector. We have designed the recommendations to be as specific and practically focused as possible. For example, we highlight the intended ‘implementer’ for each recommendation. We have also set out a visual guide to the roles and responsibilities set out by our recommendations that situates them within the current regulatory ecosystem (see separate Annex).</p>

<h3>Relationship to proposals made by the Law Commissions</h3>

<p>The report’s recommendations are intended to be read alongside the regulatory proposals developed by the Law Commission of England and Wales and the Scottish Law Commission (the Commissions), as part of their joint review of the legal framework for AVs in Great Britain. These recommendations have been designed to complement (and avoid duplicating) the Law Commissions’ proposals. Our hope is that the recommendations below clearly bound the ethical problem for regulating AVs. We recognise that some requirements have already been set out by other projects, such as the need for AVs to comply with road rules. Where appropriate, we use the terminology coined by the Commissions, such as ‘in-use regulator’, without prejudice to how the government finally implements the Commissions’ recommendations.</p>

<h3>Scope</h3>

<p>This report examines the most pressing ethical and governance issues that relate to the regulation of AVs. For this reason, we made the decision not to cover the following issues which, while important, are not within the scope of this work:</p>

<ul>
  <li>
    <p>the impact of AVs on regional inequalities and the ‘levelling up’ agenda</p>
  </li>
  <li>
    <p>environmental impacts of AVs and the contribution to Net Zero targets</p>
  </li>
  <li>
    <p>wider societal implications of AVs (e.g. relating to land use policy, employment, public transport passenger safety or taxation).</p>
  </li>
</ul>

<h2>Summary of recommendations</h2>

<table>
  <tbody>
    <tr>
      <td>&nbsp;</td>
      <td><strong>Recommendations for policymakers</strong></td>
      <td><strong>Recommended requirements for Authorised Self Driving Entities (ASDEs), <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s, and trialling organisations</strong></td>
    </tr>
    <tr>
      <th scope="row">Road safety</th>
      <td>The authorisation authority, in concert with the in-use regulator, shall develop and publish guidance on Road Rules (<abbr title="Road Rules">RR</abbr>) in the context of self-driving vehicles.<br><br> The authorisation authority shall define a scheme for determining what changes to <abbr title="Automated Vehicle">AV</abbr> performance are significant enough to require re-authorisation prior to ASDEs supplying updates to deployed AVs.</td>
      <td>The Operational Design Domain (<abbr title="Operational Design Domain">ODD</abbr>) should be consistent with the relevant road rules and cover all classes of road users, including vulnerable road users that can reasonably be expected in the <abbr title="Operational Design Domain">ODD</abbr>.<br><br>The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> should define a ‘Safe and Ethical Operational Concept’ (<abbr title="Safe and Ethical Operational Concept">SEOC</abbr>) that sets out high-level principles that will govern the design and behaviour of the <abbr title="Automated Vehicle">AV</abbr>.</td>
    </tr>
    <tr>
      <th scope="row">Data privacy</th>
      <td>The <abbr title="Automated Vehicle">AV</abbr> regulator(s) should issue guidance for ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s clarifying how Data Protection <a class="govuk-link" href="https://www.gov.uk/government/consultations/data-a-new-direction">obligations</a> apply to AVs, in consultation with the Information Commissioner’s Office.<br><br>The Home Office should issue guidance clarifying how the Police and Criminal Evidence Act 1984 applies to <abbr title="Automated Vehicle">AV</abbr> data, and should issue guidance clarifying how the Investigatory Powers Act 2016 applies to ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s.</td>
      <td>In line with UK <abbr title="General Data Protection Regulation">GDPR</abbr>, ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s shall ensure that ‘data protection by design and by default’ measures are incorporated throughout the <abbr title="Automated Vehicle">AV</abbr> development process, for example, by anonymising facial image data that is unavoidably captured in video of the <abbr title="Automated Vehicle">AV</abbr>’s surroundings at the point it is collected and before further processing.</td>
    </tr>
    <tr>
      <th scope="row">Fairness</th>
      <td>The in-use regulator, advised by <abbr title="Committee on AV Ethics and Safety">CAVES</abbr>, should collect data on fairness and safety outcomes in order to allow feedback to operators and collective learning.<br><br>The authorisation authority and licensing authority should ensure that <abbr title="Automated Vehicle">AV</abbr> services are non-discriminatory in terms of access (e.g. who can be a passenger, who can access services) as part of authorisation and licensing decisions.</td>
      <td>ASDEs should report on the fit between their training data and their ODDs to minimise risk of algorithmic bias as part of the equality impact assessment and safety case reports submitted during the authorisation process.<br><br>ASDEs should facilitate independent scrutiny of risks and biases so that distribution of risks can be assessed.</td>
    </tr>
    <tr>
      <th scope="row">Explainability</th>
      <td>The Committee on <abbr title="Automated Vehicle">AV</abbr> Ethics and Safety (see below) should review the degree of explainability needed for regulatory oversight.</td>
      <td>The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> should design the <abbr title="Automated Vehicle">AV</abbr> so that it is possible to construct an explanation of key decisions made during the Dynamic Driving Task (<abbr title="Dynamic Driving Task">DDT</abbr>) for a bounded test scenario, and in the lead up to a notifiable event.<br><br>For collisions, near misses and other notifiable events, the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> should design the <abbr title="Automated Vehicle">AV</abbr> so that it is possible to construct an explanation of the key decisions made by the <abbr title="Automated Vehicle">AV</abbr> leading up to the event, however caused.</td>
    </tr>
    <tr>
      <th scope="row">Data sharing</th>
      <td>The disclosure of safety-relevant data should be standardised across ASDEs. The in-use regulator should define a consistent format for safety-relevant data to facilitate sharing between ASDEs, the authorisation authority and a collision investigation unit.</td>
      <td>In consultation with the authorisation authority, the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall publish a summary of the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, which will be made publicly and freely available upon authorisation of the vehicle to drive itself.<br><br>The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> should communicate safety-relevant data with other organisations in the <abbr title="Automated Vehicle">AV</abbr> ecosystem when requested, including other ASDEs, the in-use regulator, the authorisation authority and the collision investigation unit, using agreed data formats, where this contributes to road safety.</td>
    </tr>
    <tr>
      <th scope="row">Public trust</th>
      <td>
<abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr> should continue to commission public dialogue and social research to seek public views on: Balancing the tensions between achieving a ‘safety-first culture’ and ensuring sufficient accountability for the consequences of <abbr title="Automated Vehicle">AV</abbr> behaviour; The distribution of <abbr title="Automated Vehicle">AV</abbr> risks and benefits; Future changes to infrastructure and rules of the road and any associated costs; Explainability of decisions made by AVs; Labelling of vehicles.<br><br>If trials on public roads become de facto deployments - e.g. by removing a safety driver, substantially increasing numbers of vehicles or starting to transport customers, there should be increased scrutiny and renewed safety assessments.</td>
      <td>Prospective ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s should engage with local communities, including local authorities, when an <abbr title="Automated Vehicle">AV</abbr> trial is planned in a particular area.<sup role="doc-noteref"><a class="govuk-link" href="#fn:10" rel="footnote">[footnote 10]</a></sup> This engagement should inform testing or deployment (e.g. placing conditions on times, places, public information, maximum speeds etc).<br><br>AVs should be clearly labelled. Where vehicles have the capability to drive themselves and be driven conventionally at different times, signals should indicate the status of operation. This external labelling should be in addition to information inside the vehicle that clearly indicates mode of operation.</td>
    </tr>
    <tr>
      <th scope="row">Governance</th>
      <td>The authorisation authority and in-use regulator should establish a joint Committee on <abbr title="Automated Vehicle">AV</abbr> Ethics and Safety (<abbr title="Committee on AV Ethics and Safety">CAVES</abbr>) to provide contestable advice and recommendations on policy and ethical issues regarding the safety of AVs. <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should be composed of experts and lay members with a diverse range of perspectives.</td>
      <td>&nbsp;</td>
    </tr>
  </tbody>
</table>

<h2>
<span class="number">1. </span> Road safety</h2>

<h3>Introduction</h3>

<p>Road safety is a key consideration for AVs. If the technology&nbsp; is not seen as ‘safe enough’, it is unlikely to be accepted by the public. However, there is no empirically verifiable answer to the question of ‘how safe is safe enough?’ The hope is that AVs will offer dramatic improvements in overall road safety, but in changing the scale of risk, they will also affect the type and distribution of risks experienced by road users. Average improvements in road safety, even if they can be clearly demonstrated, will not engender public trust if crashes are seen as the fault of faceless technology companies or lax regulation rather than fallible human drivers. Evidence from past studies of risk perception shows that risks that are seen as new, uncontrolled, catastrophic and artificial are consistently amplified in the minds of the public.<sup role="doc-noteref"><a class="govuk-link" href="#fn:11" rel="footnote">[footnote 11]</a></sup> If AVs are seen by the public as equivalent to trains or aircraft, mobility technologies that users feel are not under their control, the public could expect a 100x improvement in average safety over manually-driven vehicles.<sup role="doc-noteref"><a class="govuk-link" href="#fn:12" rel="footnote">[footnote 12]</a></sup> Uncertainty about a socially tolerable risk threshold for AVs will remain until the technology is mature and deployed at scale. Our approach is intended to support the safe and ethical introduction of AVs, which will allow this risk threshold to be established over time, based on a carefully managed introduction of the technology.</p>

<p>AVs are road vehicles, and many of the normal regulatory processes for road vehicles will continue to apply, including type approval, which ensures that a vehicle (or component) is compliant with established regulatory standards. A significant part of the existing regulatory framework is to licence drivers as competent to drive, and hold drivers accountable for safe driving. This framework no longer serves its purpose in a situation where vehicles are ‘self-driving’ where there is no such driver in control of the vehicle, whether there is a ‘user-in-charge’ who is not required to monitor the situation, or no user-in-charge within the vehicle at all. This means that additions to the current regulatory framework are needed. Specifically, these additions will have to address the transfer of safety responsibility from drivers to vehicle manufacturers and operators. There will also be a need for sufficient regulatory oversight of how these vehicles behave, both during upfront approval, and monitoring while deployed. While this is in part addressed by the recommendations made by the Law Commissions, this report builds on that legal framework by recommending a regulatory approach which assures vehicles, rather than drivers, and provides a level of technical detail that is intended to enable vehicles to be designed, assessed and authorised.</p>

<h3>Safety by design</h3>

<p>Rather than attempting to define a level of acceptable risk, our approach is to outline a framework for the assurance of safe AVs as part of an emerging regime of standards, certification and inspection, with the further aim of continual safety improvements over time, to ensure that an acceptable level of risk is achieved before AVs become widespread. A safety assurance regime cannot guarantee safe outcomes in all cases, nor can it provide clear statistics on aggregate risk in advance of testing and deployment, particularly with new and complex technologies.<sup role="doc-noteref"><a class="govuk-link" href="#fn:13" rel="footnote">[footnote 13]</a></sup> Our focus instead is on encouraging safety by design.</p>

<p>Safety by design involves informing and guiding the design and development of a system with the results of safety analyses, rather than viewing safety assessment as a process carried out at the end of the development process. The benefits are twofold: first, it is much more likely that a safe system will result; second, it will be easier to assure safety, as the safety evidence needed for the safety case will arise naturally out of the development process. This concept is well-established for “conventional” systems and is often encoded in four principles, here presented with respect to software:</p>

<ol>
  <li>Software safety requirements shall be defined to address the software contribution to system hazards.</li>
  <li>The intent of the software safety requirements shall be maintained throughout requirements decomposition.</li>
  <li>Software safety requirements shall be satisfied.</li>
  <li>Hazardous behaviour of the software shall be identified and mitigated.</li>
</ol>

<p>The first three principles relate to managing safety ‘top down’; the fourth is ‘bottom up’, recognising that there will never be complete foresight, and the design process needs to address unanticipated, low-level, failure modes. These four principles are often supplemented with a fifth (referred to as 4+1) that the confidence established in addressing the software safety principles shall be commensurate to the contribution of the software to system risk.</p>

<p>These principles can be seen in assurance processes for machine learning based systems, see for example the <a class="govuk-link" href="https://www.assuringautonomy.com/" rel="external">Assurance of Machine Learning for Autonomous Systems (AMLAS) framework</a>.</p>

<p>The associated assurance framework is intended to seek sufficient evidence that safety by design principles have been followed and that developers and manufacturers have in place mechanisms to learn from experience, improve designs, and to achieve societally acceptable levels of risk over time. Thus, the safety framework is intended to seek meaningful data on who benefits, who is harmed, how they are harmed and who is responsible rather than just statistics on deaths and injuries per million miles. Recognising that this is a rapidly evolving technology, this framework does not aim to be prescriptive about technological approaches. Rather than examining the safety of AVs in isolation, the assurance of <abbr title="Automated Vehicle">AV</abbr> safety is possible only in the context of their deployment domains.</p>

<h3>Elements of a safety framework</h3>

<p>There are many important aspects of the proposed safety framework in terms of achieving safety, assuring safety, and in communicating to the public. We briefly outline the key elements of the framework.</p>

<h4>Operational Design Domain (<abbr title="Operational Design Domain">ODD</abbr>) and deployment domains</h4>

<p>It is conventional to specify an <abbr title="Operational Design Domain">ODD</abbr> for an <abbr title="Automated Vehicle">AV</abbr> - that is a definition of the types of road layout, road users, including their ethically relevant features, weather conditions and lighting conditions in which an <abbr title="Automated Vehicle">AV</abbr> is expected to operate. AVs will be assured for operation in a particular <abbr title="Operational Design Domain">ODD</abbr> noting that, for example, the <abbr title="Operational Design Domain">ODD</abbr> for a valet-parking capability will be distinct from the <abbr title="Operational Design Domain">ODD</abbr> for a ‘motorway pilot’. When AVs are deployed, e.g. to provide mobility as a service, a check will be needed that the deployment context, i.e. where, and in what conditions, the vehicles are used, matches the <abbr title="Operational Design Domain">ODD</abbr> - for example if there are level crossings in the deployment domain, then these need to be present in the <abbr title="Operational Design Domain">ODD</abbr> for it to be appropriate for the vehicle to be approved for deployment in that domain.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>1. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall define the <abbr title="Automated Vehicle">AV</abbr> <abbr title="Operational Design Domain">ODD</abbr> to be consistent with the relevant Road Rules (<abbr title="Road Rules">RR</abbr>) and to cover all classes of road users including vulnerable road users that can reasonably be expected in the <abbr title="Operational Design Domain">ODD</abbr>.<br><br>The <abbr title="Operational Design Domain">ODD</abbr> definition should include all relevant features defined to an appropriate level of detail. The definition should cover the parameter ranges for fixed scenery elements, attributes of dynamic elements and environmental elements. It should also include all ethically salient features relating to other road users.<br><br>Further guidance will be needed from <abbr title="Department for Transport">DfT</abbr> to define these ethically salient features.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>2. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall ensure that the deployment domain is compatible with the <abbr title="Operational Design Domain">ODD</abbr> prior to operational use of the <abbr title="Automated Vehicle">AV</abbr>.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> reporting to the In-use regulator</td>
    </tr>
  </tbody>
</table>

<h4>Road rules</h4>

<p>Road rules (<abbr title="Road Rules">RR</abbr>) are customs or rules governing the behaviour of road users. These include, but are not limited to, relevant aspects of the Highway Code. For example, the custom of ‘flashing lights’ or making a beckoning motion to indicate that an oncoming vehicle can proceed is not enshrined in the Highway Code but is widely (if perhaps inconsistently) practised. Some have argued that the Highway Code or <abbr title="Road Rules">RR</abbr> should be modified to accommodate AVs or that some <abbr title="Road Rules">RR</abbr> need not apply to AVs as they will be demonstrably safer. We do not take this view, and believe that AVs should comply with existing <abbr title="Road Rules">RR</abbr> so that they can integrate effectively with conventional vehicles and to avoid any sudden (and potentially hazardous) changes in behaviour when switching between self-driving and human-driven modes. However, we recognise that <abbr title="Road Rules">RR</abbr> will evolve over time, and this needs to be done while being mindful of the capabilities and limitations&nbsp; of AVs and of societal attitudes to AVs, including changes in views as such vehicles become more widespread. We therefore recommend that <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> has a role to advise on <abbr title="Road Rules">RR</abbr> and see this as consistent with the Law Commissions’ report.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>3. The authorisation authority, in concert with the in-use regulator, shall develop and publish guidance on <abbr title="Road Rules">RR</abbr> in the context of self-driving vehicles, with input from the <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> Road Rules Subcommittee, to inform the development of SEOCs that:<br><br>a) give complete coverage of situations that an <abbr title="Automated Vehicle">AV</abbr> could reasonably be anticipated to encounter in the <abbr title="Operational Design Domain">ODD</abbr>;<br>b) reflect rules of behaviour that are ethical and broadly acceptable across different types of <abbr title="Automated Vehicle">AV</abbr>; and<br>c) identify precedence between the rules.</td>
      <td>Authorisation authority</td>
    </tr>
  </tbody>
</table>

<h4>Safe and Ethical Operating Concept (<abbr title="Safe and Ethical Operational Concept">SEOC</abbr>)</h4>

<p>It is necessary to understand how the <abbr title="Automated Vehicle">AV</abbr> will behave safely and ethically. Current road rules are defined based on the presence of a human driver. Several of the Highway Code rules for drivers include phrases such as ‘when it is safe to do so’, and ethical considerations, e.g. with respect to vulnerable road users, are also left to the discretion of the driver. Thus, for AVs, just complying with the <abbr title="Road Rules">RR</abbr> is not sufficient, and it is necessary to ‘encode’ aspects of safe and ethical behaviour beyond the <abbr title="Road Rules">RR</abbr>. It is common engineering practice to define a Concept of Operations (<abbr title="Concept of Operations">CONOPS</abbr>) for a system and we build on this practice by introducing a Safe and Ethical Operating Concept (<abbr title="Safe and Ethical Operational Concept">SEOC</abbr>) which sets out constraints that will govern the behaviour of the <abbr title="Automated Vehicle">AV</abbr>. The <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> will address, for example, issues of handover to drivers for AVs with a <abbr title="User-in-Charge">UiC</abbr> feature on exiting an <abbr title="Operational Design Domain">ODD</abbr>, and how unavoidable emergency situations will be dealt with, including priority given to vulnerable road users. The <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> will build on and help interpret the relevant <abbr title="Road Rules">RR</abbr>, for example providing the context for interpreting rules, such as for crossing double white lines, that say they may be ‘broken’ when it is safe to do so. The intent is that the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> can be communicated to the public and interested stakeholder groups so they can gain an understanding of how the <abbr title="Automated Vehicle">AV</abbr> is intended to achieve safe and ethical behaviour.</p>

<div class="call-to-action">
<p><strong>What is a SEOC?</strong></p>

<p>A Safe and Ethical Operating Concept (SEOC) would be a set of constraints on vehicle behaviour, including motion, signalling to other road users, and actions to preserve their own safety. The SEOC would be defined as a set of Self-Driving Constraints (SDCs) and precedence between these constraints, as they can conflict in certain circumstances.</p>

<p>In <a class="govuk-link" href="#Annex-A">Annex A</a>, we have identified some example SDCs, some clear precedence rules, and some situation-dependent precedences so the concept is clear.&nbsp; For ease of understanding, these focus on motion rather than signalling. These are intended to be illustrative and an ASDE’s SEOC would need to be thought through from their perspective on safe and ethical behaviour for the capability of their AV and the intended ODD.</p>
</div>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>4. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall define a <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, including Self-Driving Constraints (SDCs) (see <a class="govuk-link" href="#Annex-A">Annex A</a> for more detail), for inclusion within its <abbr title="Safety Case Report">SCR</abbr> submitted as part of authorisation, for the behaviour of the <abbr title="Automated Vehicle">AV</abbr> in its <abbr title="Operational Design Domain">ODD</abbr>, that:<br><br>a) complies with road rules (<abbr title="Road Rules">RR</abbr>);<br>b) complies with any applicable regulations for automated driving system (<abbr title="Automated Driving System(s)">ADS</abbr>);<br>c) minimises occurrence of ‘at-fault’ collisions in its defined <abbr title="Operational Design Domain">ODD</abbr>;<br>d) mitigates risk of ‘non-fault’ collisions in its defined <abbr title="Operational Design Domain">ODD</abbr>;<br>e) manages entry to and exit from the <abbr title="Operational Design Domain">ODD</abbr>, ensuring a transition to safe control of the <abbr title="Automated Vehicle">AV</abbr> by the <abbr title="User-in-Charge">UiC</abbr> where there is one, or a safe transition to a minimal risk condition (<abbr title="Minimal Risk Condition">MRC</abbr>) on exiting the deployment domain;<br>f) does not unfairly discriminate against road users or otherwise unfairly treat vulnerable road users;<br>g) does not require other road users to violate applicable rules or SDCs;<br>h) defines the priority of rules and SDCs where they can conflict in particular circumstances;<br>i) does not cause individuals in the vicinity of the <abbr title="Automated Vehicle">AV</abbr> unjustified concern about their safety;<sup role="doc-noteref"><a class="govuk-link" href="#fn:14" rel="footnote">[footnote 14]</a></sup><br>appropriately balances the need to make progress with the need to ensure safety.<sup role="doc-noteref"><a class="govuk-link" href="#fn:15" rel="footnote">[footnote 15]</a></sup>
</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>5. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall demonstrate to the authorisation authority that they have designed the <abbr title="Automated Vehicle">AV</abbr> to be consistent with the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, and provide supporting arguments and links to evidence in a <abbr title="Safety Case Report">SCR</abbr> to gain authorisation for self-driving. The <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> shall be made publicly available once authorisation is granted.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>6. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall monitor the operation of the <abbr title="Automated Vehicle">AV</abbr> to identify situations where it fails to implement the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, inform the in-use regulator of ‘notifiable events’ and take action to resolve deviations from the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> that are not notifiable. Government will need to consider how this interacts with <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s and what their obligations in relation to the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> will be.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, with oversight from the In-use regulator</td>
    </tr>
  </tbody>
</table>

<h4>Safety Management Systems (<abbr title="Safety Management System">SMS</abbr>), Safety Cases and Safety Case Reports</h4>

<p>Safety Management Systems (<abbr title="Safety Management System">SMS</abbr>), Safety Cases and Safety Case Reports (SCRs) are key tools in ensuring and assuring safety. A Safety Case is a structured argument, supported by evidence, that a system is acceptably safe for a given application, in a specified environment (e.g. an <abbr title="Operational Design Domain">ODD</abbr>). Safety Cases are very large, so it is common to present the argument and evidence summaries in an <abbr title="Safety Case Report">SCR</abbr>, e.g. in support of regulatory approval.&nbsp; Safety Cases and SCRs are well understood and are already part of the automotive industry practice (e.g. as required by ISO 26262). Our usage here is consistent with that standard, except that we would also expect to see ethical issues addressed in the <abbr title="Safety Case Report">SCR</abbr> and the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> to be both prominent and publicly available. The <abbr title="Safety Management System">SMS</abbr> is a set of processes and procedures on how safety will be managed by an organisation including, but not limited to, how an <abbr title="Safety Case Report">SCR</abbr> will be produced for an <abbr title="Automated Vehicle">AV</abbr>. For an Authorised Self-Driving Entity (<abbr title="Authorised Self-Driving Entity">ASDE</abbr>), the <abbr title="Safety Management System">SMS</abbr> will define organisational structures, processes for handling ethical concerns, ways of responding to instructions from regulators and informing owners/users of issues they need to be aware of, and so on. For a No-User-in-Charge (<abbr title="No User-in-Charge">NUiC</abbr>) Operator the <abbr title="Safety Management System">SMS</abbr> will perform a similar role in setting out how safety is managed in the organisation but will be different in scope as it will need to include operator training and competence, maintenance procedures, emergency response, e.g. recovering a broken-down vehicle and providing a means of completing unfinished journeys, where appropriate. In <a class="govuk-link" href="#Annex-A">Annex A</a>, we have outlined what, at a minimum, the contents of the <abbr title="Safety Management System">SMS</abbr> should be, both for ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s.<sup role="doc-noteref"><a class="govuk-link" href="#fn:16" rel="footnote">[footnote 16]</a></sup></p>

<p>Although there are many more details, the <abbr title="Operational Design Domain">ODD</abbr>, <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, <abbr title="Safety Management System">SMS</abbr> and <abbr title="Safety Case Report">SCR</abbr> provide the bases on which the safety assurance framework is built. Although the onus in the framework is on the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and the <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, it is intended that the regulatory authorities will gather and analyse data so it is possible to make judgements that the introduction of AVs provides a significant net reduction in safety risks, over time.</p>

<p>It is important that the Safety Case and <abbr title="Safety Case Report">SCR</abbr> are kept ‘in step’ with the evolving system design. However, it would be both onerous and ultimately unproductive to update the <abbr title="Safety Case Report">SCR</abbr> for every change, thus guidance is needed on when the <abbr title="Safety Case Report">SCR</abbr> needs to be updated and re-submitted to the regulator.</p>

<p>As a rule of thumb, we would expect that the following changes would be considered sufficiently significant to require the production and issuing of a revised <abbr title="Safety Case Report">SCR</abbr>:</p>

<ul>
  <li>
    <p>Change to priorities between rules in the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> which might change the balance of risks between classes of road user</p>
  </li>
  <li>
    <p>Extending capability of a particular Automated Driving System (<abbr title="Automated Driving System(s)">ADS</abbr>)</p>
  </li>
</ul>

<p>The following changes would not be considered sufficiently significant to require the production and issuing of a revised <abbr title="Safety Case Report">SCR</abbr>:</p>

<ul>
  <li>
    <p>Perfective changes, e.g. change in trajectory generation for path planning that reduces energy use</p>
  </li>
  <li>
    <p>Changes to internal labels for object classes used by the perception system, without changing the object classes themselves</p>
  </li>
</ul>

<p>The <abbr title="Safety Management System">SMS</abbr> too will evolve, but this will reflect changes in processes, e.g. new training schemes for staff at a <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, not changes to the <abbr title="Automated Vehicle">AV</abbr> itself. Current <abbr title="United Nations Economic Commission for Europe">UNECE</abbr> regulations typically require review or audit of similar processes, e.g. for managing software updates, every three years. We make no specific recommendations on frequency of audit or update, but suggest that this is an issue which should be kept under review by regulators.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>7. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall comply with instructions from the in-use regulator or authorisation authority, e.g. to limit the <abbr title="Automated Vehicle">AV</abbr> deployment domain or modify the vehicle design, to ensure continued safety of operation.<sup role="doc-noteref"><a class="govuk-link" href="#fn:17" rel="footnote">[footnote 17]</a></sup>
</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>
</td>
    </tr>
    <tr>
      <td>8. ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall keep their <abbr title="Safety Case Report">SCR</abbr> up to date and produce it to the authorisation authority when required to gain approval for changes to the vehicle prior to deploying the changes as part of the vehicle’s re-authorisation.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>9. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall operate a safety management system (<abbr title="Safety Management System">SMS</abbr>) for the <abbr title="Automated Vehicle">AV</abbr> governing how they manage safety through the <abbr title="Automated Vehicle">AV</abbr> lifecycle, and provide periodic independent <abbr title="Safety Management System">SMS</abbr> audit reports to the in-use regulator.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, with oversight from the Authorisation authority and In-use regulator</td>
    </tr>
    <tr>
      <td>10. The authorisation authority should assess <abbr title="Safety Management System">SMS</abbr> and safety culture within ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s as part of the authorisation and licensing decisions respectively, and approve deployments where they meet applicable criteria.</td>
      <td>Authorisation authority</td>
    </tr>
    <tr>
      <td>11. For authorisation purposes, the authorisation authority shall assess the safety of <abbr title="Automated Vehicle">AV</abbr> deployments based on:<br><br>a) the <abbr title="Safety Case Report">SCR</abbr><br>b) independent <abbr title="Safety Management System">SMS</abbr> audit reports<br>c) notifiable events (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 20 - data gathering on safety)<br><br>The in-use regulator should assess a), b), and c) on an ongoing basis.</td>
      <td>Authorisation authority and In-use regulator</td>
    </tr>
    <tr>
      <td>12. The authorisation authority shall define ‘notifiable events’ in terms of deviation from the <abbr title="Authorised Self-Driving Entity">ASDE</abbr>’s <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>.<sup role="doc-noteref"><a class="govuk-link" href="#fn:18" rel="footnote">[footnote 18]</a></sup> It will, at a minimum, include traffic infractions as defined by the Law Commissions; an incident that had it been performed by a human driver would have attracted criminal or civil penalties (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 20 - data gathering on safety).</td>
      <td>Authorisation authority</td>
    </tr>
    <tr>
      <td>13. The authorisation authority shall define a scheme for determining what changes to <abbr title="Automated Vehicle">AV</abbr> performance are significant enough to require re-authorisation prior to ASDEs supplying updates to deployed AVs.</td>
      <td>Authorisation authority</td>
    </tr>
  </tbody>
</table>

<h4>Clarity around responsibility and accountability during handover with the <abbr title="User-in-Charge">UiC</abbr>
</h4>

<p>The <abbr title="Automated Vehicle">AV</abbr> shall be designed to enable the <abbr title="User-in-Charge">UiC</abbr> to take back control of the vehicle in a safe manner, e.g. by being given sufficient time to retain situational awareness, noting that the <abbr title="User-in-Charge">UiC</abbr> should respond to the transition demand but that the <abbr title="Automated Vehicle">AV</abbr> should continue to provide safe operation, should the <abbr title="User-in-Charge">UiC</abbr> fail to do so (See Rec. 14). This is important because it will ensure that responsibility and accountability falls in the appropriate place so that, for example, the <abbr title="Automated Vehicle">AV</abbr> rescinds control to the <abbr title="User-in-Charge">UiC</abbr> in a way that they can reasonably take responsibility and control of the vehicle. This may mean that the <abbr title="Automated Vehicle">AV</abbr> has to be designed to undertake a Minimum Risk Manoeuvre (<abbr title="Minimum Risk Manoeuvre">MRM</abbr>) if the <abbr title="User-in-Charge">UiC</abbr> doesn’t respond to a transition demand.<sup role="doc-noteref"><a class="govuk-link" href="#fn:19" rel="footnote">[footnote 19]</a></sup> This is in order to ensure that the vehicle enters a Minimum Risk Condition (<abbr title="Minimal Risk Condition">MRC</abbr>) and that appropriate recovery action can be taken. For example, on a motorway, the <abbr title="Minimum Risk Manoeuvre">MRM</abbr> might involve moving to the leftmost lane and to continue driving at a speed consistent with the surrounding traffic, before entering an Emergency Refuge Area (<abbr title="Emergency Refuge Area">ERA</abbr>) and coming to a stop - which is the <abbr title="Minimal Risk Condition">MRC</abbr>. It will take significant research and development efforts to ensure there are the human-machine interfaces in place to get these handovers right, and there may be lessons to be learned from other sectors, such as aviation, that have also grappled with handovers between automated systems and human pilots. Ensuring these handovers between the AVs and UiCs work effectively will be crucial for overall safety and trust in AVs as they are deployed more widely.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>14. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall design the <abbr title="Automated Vehicle">AV</abbr> so that transfers of authority for control of the <abbr title="Dynamic Driving Task">DDT</abbr> from the <abbr title="Automated Vehicle">AV</abbr> to the <abbr title="User-in-Charge">UiC</abbr> shall ensure safety, including providing the <abbr title="User-in-Charge">UiC</abbr> with sufficient time and information to achieve situational awareness before they engage in the <abbr title="Dynamic Driving Task">DDT</abbr>.<br><br>The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall have responsibility and accountability for behaviour of the <abbr title="Automated Vehicle">AV</abbr> both within and outside the <abbr title="Operational Design Domain">ODD</abbr> unless it is confirmed that the <abbr title="User-in-Charge">UiC</abbr> has authority for control of the <abbr title="Dynamic Driving Task">DDT</abbr>.<sup role="doc-noteref"><a class="govuk-link" href="#fn:20" rel="footnote">[footnote 20]</a></sup>
</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
  </tbody>
</table>

<h2>
<span class="number">2. </span> Data privacy</h2>

<h3>Introduction</h3>

<p>AVs necessarily collect and process large volumes of data about their surroundings. Many of the privacy and data protection challenges raised by AVs and the services they may enable are therefore similar to other technologies that process large amounts of data about their environments, such as smart speakers, video doorbell cameras and wearable fitness trackers. There are two key characteristics of AVs that suggest particular attention should be paid to the privacy implications of these systems. Firstly, AVs may lead to widespread collection and processing of personal data in order to achieve core functionality such as detecting other road users in situations where explicit consent is not feasible. Secondly, they require regulatory authorisation for deployment (as discussed in the safety section above) that may be perceived as regulatory endorsement (implicitly or explicitly) about this personal data processing, including how they strike the right balance between what is necessary for safe driving, and sufficient protection of personal data. These challenges merit careful consideration given the potential future scale of <abbr title="Automated Vehicle">AV</abbr> use in public spaces.</p>

<h3>Personal data of <abbr title="Automated Vehicle">AV</abbr> occupants</h3>

<p>AVs are likely to process several categories of personal data on-board the vehicle, such as time-stamped location data of the vehicle (which carries a high degree of identifiability), ‘health and wellbeing’ data on the driver (e.g. whether they are awake and alert for the purposes of handing over vehicle control) and personal data collected by non-driving infotainment systems (e.g. choices made on in-vehicle app stores).</p>

<p>In the UK, personal data processing is addressed by Data Protection law, including UK <abbr title="General Data Protection Regulation">GDPR</abbr>, the Data Protection Act 2018, and the Privacy and Electronic Communications Regulation (<abbr title="Privacy and Electronic Communications Regulations">PECR</abbr>) 2003. Data Protection law requires controllers to have a lawful basis for that processing, which is often consent in the context of goods and services. There are also specific requirements for consent when processing location data<sup role="doc-noteref"><a class="govuk-link" href="#fn:21" rel="footnote">[footnote 21]</a></sup> under the <abbr title="Privacy and Electronic Communications Regulations">PECR</abbr>, where all users (i.e. both UiCs and passengers) must give their <a class="govuk-link" href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/consent/what-is-valid-consent/#:~:text=%E2%80%9Cany%20freely%20given%2C%20specific%2C,relating%20to%20him%20or%20her%E2%80%9D." rel="external">valid consent</a> for this processing, unless the data is processed anonymously. It will fall within the duty of the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> to provide suitable, clearly worded and easily comprehensible information to owners, UiCs and registered keepers. Where this processing is of sensitive personal data, ASDEs will need to ensure they comply with the requirements of seeking explicit consent. We note that the Law Commissions recommend that the Government establishes a duty on <abbr title="Automated Vehicle">AV</abbr> data controllers to share relevant data with insurers to provide a legal basis for doing so. Regulators should guard against companies using privacy as an inappropriate reason not to share safety-critical data.</p>

<p>Our interviews with subject matter experts highlighted open questions regarding the intervals for when consent may need to be reviewed - for example, whether the user will need to provide consent every time the vehicle is activated, as there may be new passengers on board who have not previously provided valid consent. This will depend in part on the categories of personal data collected. In particular, there are open questions regarding fleet ownership models using vehicles fitted with a <abbr title="No User-in-Charge">NUiC</abbr> self-driving feature, and whether the occupants or the <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> will be responsible for providing consent in these situations. We recommend that these areas of ambiguity are clarified via joint guidance issued by the <abbr title="Information Commissioner’s Office">ICO</abbr> and <abbr title="Automated Vehicle">AV</abbr> regulator(s).</p>

<p>As per Data Protection regulatory requirements, any personal data processed by AVs should not be stored for longer than is strictly necessary. For incident investigation, insurance, and civil enforcement purposes, it will be necessary to store <abbr title="Automated Vehicle">AV</abbr> location data for a period of time (e.g. for cross-referencing the time and location of reported incidents). However, it would not be acceptable to store such data indefinitely, and future guidance will need to explicitly clarify the retention and deletion schedules required for <abbr title="Automated Vehicle">AV</abbr> location data. We note that the Law Commissions recommended that location data be stored for 39 months for insurance purposes. We think this is a good guide for parties beyond insurers (e.g. incident investigation and civil enforcement) as similar evidential considerations apply, although they will need to periodically review these to ensure they are appropriate.</p>

<h3>Personal data of other road users</h3>

<p><abbr title="Automated Vehicle">AV</abbr> sensors may also collect personal data from individuals outside the vehicle (for example, of pedestrians and other road users), most notably facial images collected from video feeds. Again, this issue is not unique to AVs, as many conventional vehicles now have dash cams installed that collect the facial images of pedestrians. Although AVs may collect more detailed data from multiple sensors, the legal compliance considerations remain the same, and such collection will likely be necessary for the safe operation of the vehicle, or in the interests of public safety to meet these obligations. If processing this personal data is not necessary, ‘data protection by design and by default’ measures may need to be used (see below). ASDEs will also need to consider how to enable individuals external to the vehicle to assert their data protection rights (in line with <abbr title="Information Commissioner’s Office">ICO</abbr> guidance).</p>

<h3>Biometric data</h3>

<div class="call-to-action">
<p><strong>Biometric data</strong></p>

<p>As defined in UK GDPR, <a class="govuk-link" href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/special-category-data/what-is-special-category-data/#scd4" rel="external">biometric data</a> is ‘personal data resulting from specific technical processing relating to the physical, physiological or behavioural characteristics of a natural person, which allow or confirm the unique identification of that natural person, such as facial images or dactyloscopic [fingerprint] data’.</p>
</div>

<p>Some companies are exploring the use of biometric data of road users outside of the vehicle. One application of this would be to identify the intentions of other road users, for example, by assessing eye contact with the vehicle (‘gaze detection’). If there are instances in which the collection of biometric data could be demonstrated to be necessary for the safe operation of the vehicle, then they may be lawful under the <a class="govuk-link" href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/lawful-basis-for-processing/legitimate-interests/" rel="external">‘legitimate interests’ basis of UK <abbr title="General Data Protection Regulation">GDPR</abbr></a>, although this is something of a grey area and would be subject to undertaking a legitimate interests assessment. To provide clarity for companies exploring the use of this technology, the <abbr title="Information Commissioner’s Office">ICO</abbr> and <abbr title="Automated Vehicle">AV</abbr> regulator(s) should clearly set out the circumstances (if any) in which the processing of personal data of individuals outside of the vehicle (such as facial images of pedestrians) would be considered lawful and proportionate under Article 6 of UK <abbr title="General Data Protection Regulation">GDPR</abbr>. Biometric data is also likely to be special category data and therefore processing will also need to satisfy Article 9 where this is the case.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>15. The <abbr title="Automated Vehicle">AV</abbr> regulator(s) should issue guidance for ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s clarifying how Data Protection obligations<sup role="doc-noteref"><a class="govuk-link" href="#fn:23" rel="footnote">[footnote 23]</a></sup> apply to AVs, in consultation with the Information Commissioner’s Office. Issues that could be covered include:<br><br>a) The requirement to conduct a Data Protection Impact Assessment (<abbr title="Data Protection Impact Assessment">DPIA</abbr>), and to make this document publicly available alongside the vehicle’s safety case report at authorisation<sup role="doc-noteref"><a class="govuk-link" href="#fn:24" rel="footnote">[footnote 24]</a></sup>;<br>b) Clarification that an <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and/or <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s should prepare suitable DPIAs and make available for authorisation and licensing decisions;<br>c) A self-assessment checklist to establish whether the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> / <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> is acting as a controller, processor, or joint controller; <br>d) Any requirements to secure valid consent from the <abbr title="User-in-Charge">UiC</abbr> or passengers for processing personal data within the vehicle (such as what kinds of data collection would constitute ‘location data’ and ‘cookies or similar’ under <abbr title="Privacy and Electronic Communications Regulations">PECR</abbr>) and where additional consent may be required, such as when there are new passengers in the vehicle; <br>e) Proposed retention and deletion schedules for personal data collected by AVs, particularly location data;<br>f) What would be considered necessary and legitimate purposes for processing and sharing personal data (e.g. safety improvements, insurance claims etc.);<br>g) Circumstances under which processing of personal data of other road users outside the vehicle (such as facial images of pedestrians) is likely to be considered lawful and proportionate under Article 6 <abbr title="General Data Protection Regulation">GDPR</abbr> (e.g. vital interests, or legitimate interests)<sup role="doc-noteref"><a class="govuk-link" href="#fn:25" rel="footnote">[footnote 25]</a></sup>;<br>h) Circumstances under which processing of special category personal data (e.g. biometric data of the <abbr title="User-in-Charge">UiC</abbr>) is likely to be considered lawful and proportionate under Article 9 <abbr title="General Data Protection Regulation">GDPR</abbr> (e.g. explicit consent, or substantial public interest)<sup role="doc-noteref"><a class="govuk-link" href="#fn:26" rel="footnote">[footnote 26]</a></sup>; <br>i) The testing of AI systems for AVs against the requirement ‘to design the <abbr title="Automated Vehicle">AV</abbr> so that it is possible to construct an explanation&nbsp; of the key decisions made by the <abbr title="Automated Vehicle">AV</abbr> leading up to the notifiable event, however caused’. See Rec. 29;<br>j) Which <abbr title="Automated Driving System(s)">ADS</abbr> features (if any) could be considered ‘a decision based solely on automated processing, including profiling, which produces legal effects concerning [the data subject] or similarly significantly affects [the data subject]’, for the purposes of Article 22 <abbr title="General Data Protection Regulation">GDPR</abbr>.</td>
      <td>
<abbr title="Information Commissioner’s Office">ICO</abbr>; Authorisation authority; In-use regulator</td>
    </tr>
  </tbody>
</table>

<h3>Data protection by design and by default and data minimisation</h3>

<div class="call-to-action">
<p><strong>Data protection by design</strong></p>

<p>As <a class="govuk-link" href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/accountability-and-governance/data-protection-by-design-and-default/#dpd3" rel="external">defined by the ICO</a>, ‘data protection by design is ultimately an approach that ensures you consider privacy and data protection issues at the design phase of any system, service, product or process and then throughout the lifecycle’.</p>

<p><strong>Data minimisation</strong></p>

<p>Under the <a class="govuk-link" href="https://www.legislation.gov.uk/eur/2016/679/article/5" rel="external">data minimisation principle</a> of UK GDPR, [Personal data shall be] ‘adequate, relevant and limited to what is necessary in relation to the purposes for which they are processed’.</p>
</div>

<p>One way in which AVs could implement a ‘data protection by design and by default’&nbsp; approach would be to anonymise personal data at the source, where identification is not clearly necessary for any given purpose. This is likely to be possible in an <abbr title="Automated Vehicle">AV</abbr> context because many of the types of data needed (such as video data) could potentially include personal data, but would not need to use personal data (i.e. it is not necessary for individuals to be identifiable from the data) for the purposes it was being collected for. Anonymisation would therefore be one way to minimise personal data risk in this context. For example, AVs may unavoidably collect facial image data (e.g. via video of their surroundings), which could be considered ‘special category data’ under UK <abbr title="General Data Protection Regulation">GDPR</abbr>, but is not required for safely avoiding obstacles.</p>

<p>Our in-depth consultation with manufacturers and technical experts revealed that it is very likely that all facial image data could reasonably be anonymised at the point of collection, without any adverse impact on the functioning of the vehicle. This would eliminate the need for the vehicle to process special category data of pedestrians without their consent. For manufacturers that pursue camera-only <abbr title="Automated Vehicle">AV</abbr> designs (not incorporating Lidar), it is <a class="govuk-link" href="https://techcrunch.com/2020/10/19/pimloc-gets-1-8m-for-its-ai-based-visual-search-and-redaction-tool/?guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAND8sOzngN1jk-75fLV_87LaEoT7Dup_aq_A89pB0mMO9IByK6qYyMed_Ql0B4QTiUgHdyx9cvMfa9OwhLuuBsr0XyJhqw0ElVGJClvdbdbtM2XbeNDXx9-nJzgZXq-IKdJAZZiJTp0zpIpOQHBuVHtJvtpEHvZcoBRH0e8zOVFD&amp;guccounter=2" rel="external">technically straightforward</a> to detect faces and apply anonymisation techniques to them, to ensure that individuals’ privacy is protected. ASDEs will need to ensure that such techniques fully anonymise faces, otherwise they may be considered ‘pseudonymised’ and therefore still subject to UK <abbr title="General Data Protection Regulation">GDPR</abbr> as personal data. This challenge does not arise with Lidar and radar sensor fusion devices as they do not record image data that would include facial images.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>16. ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s shall ensure that ‘data protection by design and by default’ measures are incorporated throughout the <abbr title="Automated Vehicle">AV</abbr> development process. This should include:<br><br>a) Ensuring any personal data collected by AVs or for training <abbr title="Automated Vehicle">AV</abbr> systems is strictly limited to what is necessary for the purpose for which it is processed<sup role="doc-noteref"><a class="govuk-link" href="#fn:27" rel="footnote">[footnote 27]</a></sup>; <br>b) Ensuring any personal data that is not necessary to perform the legitimate purposes established by Rec. 15(f) is anonymised at the point of collection or creation (for instance by blurring or pixelating facial image data of pedestrians);<br>c) Ensuring any personal data is only stored for as long as is strictly necessary, and is not transferred from the vehicle except for specific, clearly defined purposes, with reference to the legitimate purposes established by Rec. 15(f);<br>d) Ensuring that any sharing of personal data that is required for one of the legitimate purposes established by Rec. 15(f) is done in a way that protects individuals privacy, for instance through the use of differential privacy techniques.</td>
      <td>Authorisation authority</td>
    </tr>
  </tbody>
</table>

<h3>AVs as surveillance cameras</h3>

<p>The cameras on AVs have the capacity to function much like surveillance cameras in the sense that they can collect, store and transmit video data of environments, including other road users in public and private spaces.</p>

<p>Given this capability, our recommended approach is that ASDEs should comply with the <a class="govuk-link" href="https://www.gov.uk/government/publications/update-to-surveillance-camera-code">existing legal frameworks</a>: the Protection of Freedoms Act 2012 and Surveillance Camera Code of Practice. Compliance with the Code is mandatory for certain public authorities such as police forces and local authorities, but it is optional for private companies. However, private companies can apply to the Surveillance Camera Commissioner for third party certification, demonstrating their compliance with the Code and thereby providing assurance that they are using surveillance camera systems in a proportionate and legitimate way.</p>

<p>Some AVs use video cameras that, while their primary purpose is safe operation, can also function as surveillance cameras by collecting, storing and transmitting video of their environments (in a non-targeted way). There is some <a class="govuk-link" href="https://www.thetimes.co.uk/article/detective-tesla-videos-itself-being-keyed-cpfq2xgqf" rel="external">evidence</a> that this is already happening in both public and private places. Unlike dash cams, these are now core capabilities of an <abbr title="Automated Vehicle">AV</abbr> that would be regulated in the future by <abbr title="Department for Transport">DfT</abbr> agencies. In effect, this is potentially approving a surveillance capability, and <abbr title="Department for Transport">DfT</abbr> should draw on the existing governance frameworks for surveillance cameras.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>17. Where ASDEs are collecting camera data of other road users, they should ensure adherence to the <a class="govuk-link" href="https://www.gov.uk/government/publications/update-to-surveillance-camera-code">12 guiding principles</a> in the Surveillance Camera Code of Practice<sup role="doc-noteref"><a class="govuk-link" href="#fn:28" rel="footnote">[footnote 28]</a></sup>, and consider applying for certification under the Biometrics and Surveillance Camera Commissioner’s <a class="govuk-link" href="https://www.gov.uk/government/publications/surveillance-camera-code-of-practice-third-party-certification-scheme#:~:text=Guidance-,Surveillance%20camera%20code%20of%20practice%3A%20third%20party%20certification%20scheme,surveillance%20camera%20code%20of%20practice.">third party certification scheme</a>.<br><br>The authorisation authority should review adherence to the 12 guiding principles in the Surveillance Camera Code of Practice as part of the authorisation decision.</td>
      <td>Authorisation authority; Surveillance Camera Commissioner</td>
    </tr>
    <tr>
      <td>18. As per the Surveillance Camera Code, any <abbr title="Automated Vehicle">AV</abbr> cameras (either within or outside the vehicle) should be clearly labelled. If AVs are collecting camera data of other road users, this should be clearly labelled on the outside of vehicles.</td>
      <td>Authorisation authority; Surveillance Camera Commissioner</td>
    </tr>
  </tbody>
</table>

<h3>Access to <abbr title="Automated Vehicle">AV</abbr> data by police and other authorities</h3>

<p>The Police and Criminal Evidence Act (PACE) 1984 (s.20) grants the police powers to seize any information stored in electronic form, from any premises (including vehicles), if there are reasonable grounds for believing that a criminal offence has been committed. This provision would apply to AVs just as it applies to all other electronic devices. We also recognise that government is seeking new powers for data access in civil offence cases.</p>

<p>As ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s provide a service or system that involves facilitating the transmission of communications, they may function as ‘telecommunications operators’ for the purposes of the Investigatory Powers Act (IPA) 2016. As ASDEs may be obliged to comply with the IPA,&nbsp; it will be important to clarify and communicate any obligations to them, especially distinguishing between the categories of <abbr title="Automated Vehicle">AV</abbr> data that could satisfy definitions in the IPA (including for example, definitions of ‘communications data’ and ‘the content of a communication’ as <a class="govuk-link" href="https://www.legislation.gov.uk/ukpga/2016/25/section/261/enacted" rel="external">set out</a> in s.261 IPA).</p>

<p>These considerations are separate to access to data for the purposes of determining the circumstances of traffic infractions, which, in and of themselves, would not constitute a criminal offence.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>19. The Home Office should issue guidance clarifying how the Police and Criminal Evidence Act 1984 applies to <abbr title="Automated Vehicle">AV</abbr> data and specifically the grounds under which it could be considered evidence in relation to an offence.<br><br>The Home Office should issue guidance clarifying how the Investigatory Powers Act 2016 applies to ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s.</td>
      <td>Home Office</td>
    </tr>
  </tbody>
</table>

<h2>
<span class="number">3. </span> Fairness</h2>

<h3>Introduction</h3>

<p>AVs will have implications for the distribution of risks and benefits across groups. Access to the technology will be uneven. The factors that determine who benefits from AVs will include questions of economic development and transport planning that are outside the scope of this report. However, AVs as data-driven technologies have the potential for various forms of algorithmic bias, which may be hard to predict in advance of deployment at scale.</p>

<p>This bias may result in unfair outcomes for particular groups, which may give rise to legally-defined discrimination. Where AVs categorise vulnerable road users (for example, children, adults, wheelchair users), there is a risk of discrimination that could include protected characteristics. As with any algorithmic system, there are risks of bias and error that can be mitigated by diversifying training datasets and by appropriate choice of ML models and hyperparameters. Nonetheless, some systemic injustices may only become apparent once systems are operational. The uncertainties here point to a need for effective collection and sharing of data on how AVs affect different groups.</p>

<h3>Bias in training data</h3>

<p>Issues of algorithmic bias have emerged as important and problematic across a range of data-driven technologies. Given the types of data required to perform the <abbr title="Automated Vehicle">AV</abbr>’s functionality (such as detecting types of road users and their movement), there is reason to believe that these issues, particularly when it comes to protected characteristics such as race, may not be as great with AVs as with, for example, <a class="govuk-link" href="https://www.gov.uk/government/publications/cdei-publishes-briefing-paper-on-facial-recognition-technology">facial recognition technologies</a>. However, the possibility of systemic biases should not be dismissed. Researchers involved in <abbr title="Automated Vehicle">AV</abbr> testing and development have already spotted potential data gaps caused by a concentration of testing and data collection in some areas.<sup role="doc-noteref"><a class="govuk-link" href="#fn:29" rel="footnote">[footnote 29]</a></sup> People and objects that are seen less often, such as wheelchairs and wheelchair users, may be underrepresented in training data. Algorithmic bias could also occur with respect to in-vehicle technologies, for example in ‘attention detection’ technologies that use biometric data to judge whether a user in charge is tired or distracted.</p>

<p>Advanced sensing technologies such as gaze detection and intent prediction may, in the future, demand data at a granularity that has implications for bias. Safety cases may, in the future, benefit from identifying, for example, young and old people. Following recent changes to the UK Highway Code, an ethical focus on AVs offering additional protection for vulnerable road users would be justified, which may require more attention to classification of types of road user.<sup role="doc-noteref"><a class="govuk-link" href="#fn:30" rel="footnote">[footnote 30]</a></sup> The need for AVs to classify road users in terms of whether they are, for example, cyclists, pedestrians, or horse riders and make predictions accordingly, creates a risk if road users are hard to classify.<sup role="doc-noteref"><a class="govuk-link" href="#fn:31" rel="footnote">[footnote 31]</a></sup></p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>20. To minimise the risk of algorithmic bias, ASDEs’ safety cases and impact assessments<sup role="doc-noteref"><a class="govuk-link" href="#fn:32" rel="footnote">[footnote 32]</a></sup> should report on the fit between their training data and their ODDs. Substantially altered ODDs should require new reports on training data.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, with oversight from the Authorisation authority</td>
    </tr>
    <tr>
      <td>21. Where training data distinguishes between categories of road users, e.g. between children and adults for reasons of safety, this should be acknowledged as part of the safety case and reported to the authorisation authority. Steps should be taken to anticipate and minimise unfair consequences resulting from data bias, including discrimination.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, with oversight from the Authorisation authority</td>
    </tr>
  </tbody>
</table>

<h3>Differentiated treatment between different types of road user</h3>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>22. Where systems distinguish between groups while driving, justified on the grounds of safety, e.g. the identification of children, wheelchair users or other vulnerable road users, ASDEs should have a duty to report in order to allow independent scrutiny (including, but not limited to, reporting this in the safety case).<sup role="doc-noteref"><a class="govuk-link" href="#fn:33" rel="footnote">[footnote 33]</a></sup>
</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, with oversight from the Authorisation authority and In-use regulator</td>
    </tr>
  </tbody>
</table>

<h3>Risk distribution</h3>

<p>AVs will change the balance as well as the magnitude of risk, although the distribution of risk may be unpredictable. Even if AVs enable large improvements in overall safety, some groups may see substantial safety improvements while others see none or even face new hazards. As with other issues involving the rules of road use, perceptions of risk are likely to be important. It will be important to understand whether vulnerable road users feel more or less vulnerable around AVs. Vulnerable road users, who have recently been granted revised attention by the updated Highway Code<sup role="doc-noteref"><a class="govuk-link" href="#fn:34" rel="footnote">[footnote 34]</a></sup>, are likely to have particular interests in changes of rules of the road that may be made to accommodate AVs. There is a need for meaningful data on how AVs affect different groups. Some of this may be possible through independent scrutiny of risks and risk perceptions around AVs, but it will also require access to ASDEs’ own data on collisions and near misses. ASDEs will need to consider the types of data it is appropriate to collect for understanding impacts on different groups and how data is stored, in line with data protection requirements. Assessing outcomes of collisions or near misses for discrimination could be a lawful purpose for processing data such as a pedestrian’s detected gender - but would have to take into account ‘data protection by design and by default’ considerations set out above.</p>

<p>While our recommendation on mitigating bias in training data (Rec. 21) will help to give confidence that training data used is representative of the <abbr title="Operational Design Domain">ODD</abbr>, it will also be important to ensure that the reality of the deployment domain continues to reflect the <abbr title="Operational Design Domain">ODD</abbr>. Ongoing reporting and independent scrutiny of risks and biases that might emerge as AVs are deployed will be an important way to address this.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>23. ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s should facilitate independent scrutiny of emerging risks and biases (in addition to those raised by notifiable events) so that the distribution of risks can be assessed.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, with oversight from the in-use regulator and Authorisation authority</td>
    </tr>
    <tr>
      <td>24. The in-use regulator, advised by <abbr title="Committee on AV Ethics and Safety">CAVES</abbr>, should collect data on fairness and safety outcomes in order to allow feedback to operators and collective learning. In the event that serious problems are identified and no other means prove effective in mitigation, the regulator should be empowered to impose sanctions, up to and including de-authorisation and product recall (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 20 - data gathering on safety).<br><br>The in-use regulator should also compile evidence for where an amendment to the regulatory framework may be necessary (e.g. updates to the <abbr title="Road Rules">RR</abbr>) to ensure that AVs are acceptably safe, with continual improvements in safety (see also Rec. 8).</td>
      <td>In-use regulator</td>
    </tr>
  </tbody>
</table>

<h3>Fair treatment and access</h3>

<p>Some aspects of fairness might be designed into <abbr title="Automated Vehicle">AV</abbr> systems from the start so that they are more inclusive. For example, there could be new vehicle designs that are more accessible to disabled people. Other questions of accessibility may become clear as systems are tested and deployed, which will demand careful oversight. The safe operation of AVs may make demands on other road users, who could hypothetically be asked to change their behaviour or carry devices to make them more easily detectable. Our recommendation is that it should be the <abbr title="Authorised Self-Driving Entity">ASDE</abbr>’s responsibility to ensure the safety of&nbsp; vulnerable road users, and vulnerable road users should never be required to wear or carry devices that would make them more visible to AVs. However, we also note that there may be additional safety benefits to such devices, which should be recognised by ASDEs.</p>

<p>AVs could also have fairness implications resulting from the infrastructures that support them. The Law Commissions were clear that ‘one of the UK Government’s principles for introducing AVs on GB roads is that they should be able to cope with existing infrastructure’.<sup role="doc-noteref"><a class="govuk-link" href="#fn:36" rel="footnote">[footnote 36]</a></sup> However, their report acknowledges that changes to infrastructure may become an important part of ASDEs’ safety cases in the near future. AVs may suit some types of roads more than others, they may depend upon Vehicle-to-infrastructure (<abbr title="Vehicle-to-Infrastructure">V2I</abbr>) connectivity, and demands for their safe operation may create pressure to segregate <abbr title="Automated Vehicle">AV</abbr> spaces or ‘<abbr title="Automated Vehicle">AV</abbr>-only’ lanes.</p>

<p>Some infrastructure changes may be paid for by ASDEs. However, if investments in <abbr title="Automated Vehicle">AV</abbr>-friendly infrastructure are costly and taxpayer-funded but seen as benefiting a minority of people who travel in AVs, this would change the balance of costs and benefits, jeopardising public trust. <abbr title="Automated Vehicle">AV</abbr> developers are currently incentivised to downplay the need for changes to infrastructure, as part of asserting the capabilities of their systems. A thorough review of short-term <abbr title="Automated Vehicle">AV</abbr> infrastructure needs and long-term infrastructure possibilities would allow planners and local authorities to make better-informed decisions.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>25. <abbr title="Automated Vehicle">AV</abbr> regulators should assess the potential risks of discrimination, and the adequacy of accessibility features in their authorisation and licensing decisions, in line with their Public Sector Equality Duty (cf.&nbsp; <abbr title="Law Commission(s)">LC</abbr> Rec. 63 - accessibility advisory panel).</td>
      <td>Authorisation authority and licensing authority</td>
    </tr>
    <tr>
      <td>26. ASDEs should not, as part of their <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, require vulnerable road users to carry or wear anything to make them more easily detectable to AVs. Should vulnerable road users decide to use such devices, however, ASDEs should not ignore their potential additional safety benefits.<sup role="doc-noteref"><a class="govuk-link" href="#fn:37" rel="footnote">[footnote 37]</a></sup>
</td>
      <td>Authorisation authority and In-use regulator</td>
    </tr>
    <tr>
      <td>27. If infrastructure upgrades are required that contribute to <abbr title="Automated Vehicle">AV</abbr> safety, their costs and benefits for other road users should be fully understood and carefully balanced.</td>
      <td>Local authorities and other infrastructure bodies; National Infrastructure Commission</td>
    </tr>
  </tbody>
</table>

<h2>
<span class="number">4. </span> Explainability</h2>

<h3>Introduction</h3>

<p>Self-driving vehicles are sometimes referred to as ‘autonomous’ vehicles, but it is important to remember that they lack moral autonomy, so cannot be held accountable for their actions. For this reason, the UK Government avoids describing them as ‘autonomous’ and instead uses the term ‘self-driving’. The term ‘self-driving’ also aids public understanding and will become a protected term for the purpose of marketing products to the public. Since a self-driving vehicle lacks agency, any action it performs must be traced back to its designers and operators. The Law Commissions have concluded that it is not reasonable to hold an individual programmer responsible for the actions of the vehicle. Instead, the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> as an organisation bears responsibility. This raises a fundamental need for an appropriate degree of explainability for the vehicle’s ‘decisions’. We have seen in the investigation of high-profile self-driving vehicle crashes that perception and classification of some objects might be poor and that complete post hoc explanations might be difficult.<sup role="doc-noteref"><a class="govuk-link" href="#fn:38" rel="footnote">[footnote 38]</a></sup> This is a complicated area, and newly emerging. We recommend that <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> consider this issue in order to give guidance to government on regulating this area (see Recs. 45 and 46).</p>

<p>Explainability (being able to understand why <abbr title="Automated Vehicle">AV</abbr> systems do what they do, both in real-time and in hindsight) enables improvements in safety and accountability, and provides evidence with which to evaluate the safety and fairness of systems.<sup role="doc-noteref"><a class="govuk-link" href="#fn:39" rel="footnote">[footnote 39]</a></sup> It allows regulators to understand the behaviour of AVs and to hold ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s to account. Some machine learning based systems are challenging to explain, but improving the explainability of AI systems is an active research field and a lot of progress has been made in this area. Some opacity may be expected depending on the AI system used, but what matters is that there is sufficient explainability for accountability. Technology companies and regulators need to be able to understand a system’s decisions so that they and others can learn from collisions and near misses. Accordingly, the use of deep learning for safety critical systems represents a substantial governance challenge. There are emerging efforts to build standards for transparency of ML systems.<sup role="doc-noteref"><a class="govuk-link" href="#fn:40" rel="footnote">[footnote 40]</a></sup> We recognise there will be further effort required to ensure meaningful explainability and technical feasibility.</p>

<p>Standardising the disclosure of data is also a clear priority. The ethical black box follows the example of ‘black box’ flight recorders on aircraft, devices that are mandated by international regulators with the data they produce shared immediately with investigators. The intent is that it should be possible to generate explanations for notifiable events, not just for collisions, to facilitate learning as systems grow in maturity. The additional task of explainability during a system’s normal operation to aid research and development has been <a class="govuk-link" href="https://www.bsigroup.com/en-GB/CAV/cav-resources/safety-benchmarking-report/" rel="external">labelled</a> ‘digital commentary driving’ by the British Standards Institution (BSI. This process would provide assurance that systems’ safety-critical sensors and decision making systems are doing what is expected of them, mitigating the possibility of surprises.</p>

<p>The potential hazards of AVs as robots operating in open-ended, uncertain environments, raise the stakes for the interpretability of AI. With other technologies that make use of machine learning systems, performance has been prioritised over interpretability. Growing interest in explainable AI is starting to redress this balance, but there may be some uses of machine learning in AVs, such as computer vision, that remain incompletely interpretable. It may be impossible to know with certainty why an <abbr title="Automated Vehicle">AV</abbr> image recognition system classified an object or a person according to a particular category. Other parts of <abbr title="Automated Vehicle">AV</abbr> systems, such as those that determine the speed and direction of the vehicle, are in many cases rules-based and therefore more easily explainable.</p>

<p>Techniques for ensuring explainability will differ across <abbr title="Automated Vehicle">AV</abbr> systems. An <abbr title="Authorised Self-Driving Entity">ASDE</abbr> may need to review logs from a particular event or replay logs through a simulator. Generating explanations for ML-based systems remains an active research area and it is likely that capabilities will advance significantly in the coming years. The recommendations have been framed to be as independent as possible of particular explainable AI methods, and to put the onus on the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> to generate explanations, as and when required.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>28. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> should design the <abbr title="Automated Vehicle">AV</abbr> so that it is possible to construct an explanation of the key decisions made by the <abbr title="Automated Vehicle">AV</abbr> when it is undertaking the Dynamic Driving Task (<abbr title="Dynamic Driving Task">DDT</abbr>) for a bounded test scenario. These explanations should be made available as required under the duty of disclosure including, as a minimum:<br><br>a) to the authorisation authority as part of the <abbr title="Safety Case Report">SCR</abbr>;<br>b) to the <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> where appropriate.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the appropriate regulator</td>
    </tr>
    <tr>
      <td>29. For collisions, near misses and other notifiable events, the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> should design the <abbr title="Automated Vehicle">AV</abbr> so that it is possible to construct an explanation of the key decisions made by the <abbr title="Automated Vehicle">AV</abbr> leading up to the event, however caused. This explanation should be sufficient to identify and rectify causes of undesirable behaviours, and the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> should make the explanation available to:<br><br>a) a collision investigation unit for the incident being investigated;<br>b) the in-use regulator when investigating a notifiable event to potentially apply a sanction;<br>c) other parties with a legitimate need for the information agreed in advance as part of authorisation (cf. <abbr title="Law Commission(s)">LC</abbr> Recs. 21, 22, 29 on incident investigation; cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 74 on data disclosure).</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority; also In-use regulator and collision investigation unit</td>
    </tr>
  </tbody>
</table>

<h2>
<span class="number">5. </span> Data sharing</h2>

<h3>Introduction</h3>

<p>There are many advanced technologies whose inner workings remain largely opaque to their users and the general public. However, it would be a mistake to presume that there is no public interest in questions of explainability. Expert witnesses and regulators able to translate features for the public will be important intermediaries. We have seen that when prominent crashes have been investigated by the National Transportation Safety Board in the US, the availability and interpretability of data have become important points of contention. A balance will need to be struck between trade secrets and data sharing, particularly when data is safety-critical. <abbr title="United Nations Economic Commission for Europe">UNECE</abbr> standards for a Data Storage System for Automated Driving (<abbr title="Data Storage System for Automated Driving">DSSAD</abbr>) and an Event Data Recorder (<abbr title="Event Data Recorder">EDR</abbr>) can help to enable sharing of some of the data relating to safety-critical functions, such as establishing who was in control of a vehicle during an incident. However, as a data rich and data-driven technology, there is also potential for data sharing to enable safety improvements across the <abbr title="Automated Vehicle">AV</abbr> sector.</p>

<p>We note that there are already obligations under vehicle type approval to share data with regulators and third parties, and some similar requirements will be necessary to facilitate the sharing of data with the authorisation and licensing authorities. Beyond these obligations, the wider goal of improving the safety and effectiveness of AVs will require additional data-sharing.</p>

<p>Data-sharing mandates may require standardised formats for data storage and definitions of notifiable events, which currently vary widely between companies.</p>

<h3>Safety cultures</h3>

<p>The Law Commissions have discussed the aim of establishing a ‘no-blame safety culture’, which would allow learning between competitors. Similar approaches have led to improvements in safety in medicine and air travel, where learning is prioritised over legal liability in incident investigations. In the airline industry, for example, the US National Transportation Safety Board has sought to encourage the idea that ‘anybody’s accident is everybody’s accident’. Until recently, it was possible to assert that airlines and aircraft manufacturers did not compete on safety. Historically, this system was sustainable because of a tight relationship between regulators and industry. The recent crashes of Boeing 737 Max aircraft reveal that such a model can lead to complacency, regulatory capture and serious harm.<sup role="doc-noteref"><a class="govuk-link" href="#fn:41" rel="footnote">[footnote 41]</a></sup></p>

<p>However, there may be benefits to competition based on safety while the technology is new. <abbr title="New Car Assessment Programmes">NCAP</abbr> and EuroNCAP, the New Car Assessment Programmes, do not only test for regulatory compliance; they also incentivise safety innovation above and beyond the minimum through the use of star ratings.<sup role="doc-noteref"><a class="govuk-link" href="#fn:42" rel="footnote">[footnote 42]</a></sup> These positive effects of competition should be noted, but we should also recognise that this competition has often benefited the safety of drivers and passengers rather than other road users. In the US, for example, road use has, on average, become increasingly safe for drivers but more dangerous for pedestrians since 2000.<sup role="doc-noteref"><a class="govuk-link" href="#fn:43" rel="footnote">[footnote 43]</a></sup> We think that a balanced approach that involves aspects of a ‘no blame’ or ‘safety first’ culture&nbsp; - for example, the sharing of safety-relevant data (see Rec. 32), alongside some degree of competition on safety - is optimal.</p>

<h3>Novel data sharing approaches</h3>

<p>Regulators and the <abbr title="Automated Vehicle">AV</abbr> sector should explore the ways in which mechanisms that facilitate responsible sharing of commercially sensitive data, such as data intermediaries, could be used.&nbsp; An example of a data intermediary that facilitates safety improvements while ensuring the protection of commercially sensitive data in the aircraft industry is included below.</p>

<div class="call-to-action">
<p><strong>Case study: Advanced Product Concept Analysis Environment (APROCONE)</strong></p>

<p>APROCONE is an industrial data platform that facilitates collaborative product design in the airline industry. It involves a range of public and private organisations including Airbus, Rolls-Royce, academic partners, and supply chain companies in the aircraft industry.</p>

<p>The purpose of APROCONE is to improve collaborative product design for aircraft, while protecting participants’ intellectual property through a digital platform that allows the secure exchange and sharing of product data. The industrial data platform operates between consortium partners who are able to control their intellectual property, allowing other parties access to minimally required information to support their own designs. Partners can choose to add or remove partners and use their existing analysis tools, with the platform performing the required actions that ensure interoperability between partners, overcoming barriers to efficient and cost effective data sharing.</p>

<p>The data sharing facilitated by APROCONE has enabled an innovative approach to initial aircraft and engine sizing that is at least ten times faster and could deliver significant fuel burn savings. The platform has led to manufacturing cost savings and has enhanced design processes by making valuable data available earlier in the design lifecycle.</p>

<p>For full case study, see Centre for Data Ethics and Innovation’s <a class="govuk-link" href="https://www.gov.uk/government/publications/unlocking-the-value-of-data-exploring-the-role-of-data-intermediaries/unlocking-the-value-of-data-exploring-the-role-of-data-intermediaries">Unlocking the value of data: Exploring the role of data intermediaries</a>.</p>
</div>

<h3>Privacy-enhancing technologies (PETS)</h3>

<p>One example of a privacy-enhancing technology (PET) that could be useful in this context is federated analytics. Federated analytics <a class="govuk-link" href="https://cdeiuk.github.io/pets-adoption-guide/what-are-pets" rel="external">refers</a> to ‘a paradigm for executing a computer program against decentralised data’. Federated learning, which is a subset of federated analytics, refers to approaches which train machine learning models on distributed data sets. In the case of self-driving vehicles, it might be useful to explore how these types of techniques could be applied to minimise the amount of data that is uploaded to a centralised server, since it would instead be stored locally in the vehicle itself.</p>

<div class="call-to-action">
<p><strong>Case study: <a class="govuk-link" href="https://cdeiuk.github.io/pets-adoption-guide/repository" rel="external">GBoard</a></strong></p>

<p>GBoard is a keyboard app for Android and iOS devices. It features next-word prediction, driven by a machine learning model. GBoard utilises federated learning where each mobile device downloads an initial model from a central server, which is further trained on the device using user data local to the device. The weights of the resulting model are periodically communicated back to the central server using a secure aggregation protocol (a form of multi-party computation), which aggregates the weights received from all mobile devices into a new common model that reflects data from each individual user, without sharing any of the underlying data. Devices download this new model, and the cycle repeats, such that the model is <a class="govuk-link" href="https://ai.googleblog.com/2017/04/federated-learning-collaborative.html" rel="external">continuously trained</a> without collecting user data centrally.</p>
</div>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>30. In consultation with the authorisation authority, the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall publish a summary of the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, which will be made publicly and freely available upon authorisation of the vehicle for self-driving.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>31. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> should communicate safety-relevant data with other organisations in the <abbr title="Automated Vehicle">AV</abbr> ecosystem when requested, including other ASDEs, the in-use regulator, the authorisation authority and the collision investigation unit, using agreed data formats, where this contributes to road safety. Data formats should be decided by the authorisation authority and in-use regulator, in consultation with the <abbr title="Information Commissioner’s Office">ICO</abbr>.<sup role="doc-noteref"><a class="govuk-link" href="#fn:44" rel="footnote">[footnote 44]</a></sup><br><br>a) The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> should share core safety-relevant data as stipulated by the in-use regulator and collision investigation unit; (note that there will be some aspects of safety-relevant data that the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> will be legally required to share for law enforcement purposes.<sup role="doc-noteref"><a class="govuk-link" href="#fn:45" rel="footnote">[footnote 45]</a></sup>)<br>b) The in-use regulator and collision investigation unit should consult on the agreed scope and format of the core safety-relevant data they will require from ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s;<br>c) The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> should be encouraged to share data with interested parties, using standards and formats developed via consensus;<br>d) Regulators and the <abbr title="Automated Vehicle">AV</abbr> sector should explore the ways in which mechanisms that facilitate responsible sharing of commercially sensitive data, such as data intermediaries, could be used;<br>e) ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s should explore the use of privacy-enhancing technologies such as <a class="govuk-link" href="https://cdeiuk.github.io/pets-adoption-guide/what-are-pets" rel="external">federated learning techniques</a>, to minimise the volume of personal data that is uploaded to a centralised server.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, with oversight from the In-use regulator</td>
    </tr>
    <tr>
      <td>32. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall provide summarised safety performance data to relevant bodies including the in-use regulator to enable the safe, ethical and effective operation of the <abbr title="Automated Vehicle">AV</abbr> marketplace (cf. <abbr title="Law Commission(s)">LC</abbr> Recs. 20, 74).</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>33. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall support reasonable access to all relevant proprietary information by a road collision investigation unit and other authorised bodies to enable collision and incident analysis and support the authorities in producing lessons learnt for dissemination to other ASDEs.<sup role="doc-noteref"><a class="govuk-link" href="#fn:46" rel="footnote">[footnote 46]</a></sup>
</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, with oversight from the In-use regulator</td>
    </tr>
    <tr>
      <td>34. The in-use regulator shall define formats for safety-relevant data to enable sharing between relevant organisations, including ASDEs, the authorisation authority and the collision investigation unit, to ensure consistency and equity in regulation. This could be achieved via the guidance the Commissions recommend they publish on data sharing.</td>
      <td>In-use regulator</td>
    </tr>
  </tbody>
</table>

<h2>
<span class="number">6. </span> Public trust</h2>

<h3>Introduction</h3>

<p>Whereas some technologies are developed behind closed doors, important aspects of the development of AVs are taking place in public. Much of the testing and assurance of this technology needs to happen on public roads, which involves complicated relationships with other road users, citizens, local authorities and transport planners. If the purported benefits of AVs are to be realised, the technology will need to be trustworthy and public hopes and fears will need to be well understood. As with other complex sociotechnical systems like air travel, people will decide whether to place their trust not in the technology per se but in the systems that govern the technology and assure its safety and benefits. <a class="govuk-link" href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/951094/cav-public-acceptability-dialogue-engagement.pdf" rel="external">Public dialogue exercises</a> and surveys have revealed a mix of excitement and concern about the technology among the British public.</p>

<p>A survey of 4,860 members of the British public conducted as part of the Driverless Futures? project provides some insight into early public views<sup role="doc-noteref"><a class="govuk-link" href="#fn:47" rel="footnote">[footnote 47]</a></sup>:</p>

<ul>
  <li>
    <p>Levels of comfort with the idea of using self-driving vehicles or sharing the roads with them have remained similar since 2015. A small majority of respondents would be uncomfortable using self-driving vehicles (58%) or sharing the road with them (55%);</p>
  </li>
  <li>
    <p>Respondents demanded transparency: not only that vehicles driving themselves must be identifiable (86% agreeing), 91% agreed that ‘the companies behind [self-driving vehicles] must be able to explain the actions taken by their vehicles, while 68% preferred the statement that self-driving vehicles ‘should be required to make public the full details of how their AI systems work’ to the suggestion that they should be able to ‘keep private the details’ (preferred by 12%). 81% agreed that ‘there should be international standards regulating [self-driving vehicle] technology’ (3% disagreeing);</p>
  </li>
  <li>
    <p>86% of respondents agreed or strongly agreed that ‘it must be clear when a vehicle is driving itself’;</p>
  </li>
  <li>
    <p>In the event of a collision, 92% agreed or strongly agreed with the statement ‘all data must be made available to investigators’.</p>
  </li>
</ul>

<p>Building public awareness and understanding of self-driving vehicles will be one important element of facilitating public trust. Another important element will be the opportunity for the public to engage in genuine dialogue about this technology. The fact that both the technology itself and the structures that will govern it are still in relatively early stages of development presents an opportunity for an open public conversation on these issues.</p>

<h3>Public information</h3>

<p>There is currently public confusion, exacerbated by some claims from industry, about the capabilities and limits of <abbr title="Automated Vehicle">AV</abbr> systems.<sup role="doc-noteref"><a class="govuk-link" href="#fn:48" rel="footnote">[footnote 48]</a></sup> All of the issues above, including safety, fairness, privacy and transparency, raise the question of presenting accessible information about the functioning and performance of AVs to the public. The Law Commissions have made recommendations for legislation that clarifies terminology for AVs. Definitions of, for example, ‘self-driving’ also demand clarity on the conditions under which a vehicle can be said to perform those functions. This means clear communication of a vehicle’s Operational Design Domain (<abbr title="Operational Design Domain">ODD</abbr>), defined by the BSI as the ‘Operating conditions under which a given driving automation system or feature thereof is specifically designed to function’. Companies are currently incentivised to downplay <abbr title="Operational Design Domain">ODD</abbr> definitions in public communications and overstate the capacity of their technology. When it comes to questions of liability, companies will have the opposite incentives, to claim that their ODDs are narrow. If the technology is going to be trustworthy, technology developers need to be clearer about all aspects of the <abbr title="Operational Design Domain">ODD</abbr>, including locations, weather conditions, road types, infrastructure requirements and other road users’ behaviour.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>35. The rules on the use of terminology such as ‘self-driving’ should include requirements to inform the public about the conditions under which self-driving vehicles can operate, e.g. road types, locations, weather, other road users’ behaviour.<sup role="doc-noteref"><a class="govuk-link" href="#fn:49" rel="footnote">[footnote 49]</a></sup> <sup role="doc-noteref"><a class="govuk-link" href="#fn:50" rel="footnote">[footnote 50]</a></sup>
</td>
      <td>ASDEs, Authorisation authority and In-use regulator</td>
    </tr>
  </tbody>
</table>

<h3>Consultation and public engagement</h3>

<p>The potential implications of AVs demand wide public consultation. The testing of any technology in public raises ethical questions about safety risks, informed consent, and the ability of people, if they are regarded in some way as test subjects, to opt out if desired. Effective public engagement will be crucial to understanding and mitigating the ethical issues raised in this report. There should be ongoing dialogue with the public that informs the design and regulation of systems. Groups at risk of marginalisation, such as disabled people, should be consulted so the design and regulation of systems can be as inclusive as possible. There is a need for ongoing dialogue and social research to deepen understanding of public views on liability, labelling, the explainability of decisions made by AVs, and possible infrastructure changes as <abbr title="Automated Vehicle">AV</abbr> systems expand and develop. These are important as they can have a direct impact on safety (infrastructure), acceptability of AVs (labelling, explainability) and on accountability and the requirement to provide recompense (liability).</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>36. An accessible summary of the <abbr title="Safety Case Report">SCR</abbr> should be made public and should include clear statements of the functions and limits of an <abbr title="Automated Vehicle">AV</abbr> within an <abbr title="Operational Design Domain">ODD</abbr>.</td>
      <td>ASDEs, Authorisation authority</td>
    </tr>
    <tr>
      <td>37. The in-use regulator shall regularly publish publicly accessible reports on the achieved level of safety of AVs, which should include records of notifiable events and actions taken to improve safety of deployed AVs, including updates to the Road Rules. This should form part of its duty to publish evidence of <abbr title="Automated Vehicle">AV</abbr> safety, as recommended by the Law Commissions (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 19).</td>
      <td>In-use regulator</td>
    </tr>
    <tr>
      <td>38. Prospective ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s should engage with local communities, including local authorities, when an <abbr title="Automated Vehicle">AV</abbr> trial is planned in a particular area.<sup role="doc-noteref"><a class="govuk-link" href="#fn:51" rel="footnote">[footnote 51]</a></sup> This engagement should inform testing and/or deployment (e.g. placing conditions on times, places, public information, maximum speeds etc).<br><br>Where the vehicle is permitted to carry passengers, the service operator should consult with relevant authorities as proposed under the Law Commissions’ passenger permitting scheme.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, In-use regulator</td>
    </tr>
    <tr>
      <td>39. Serious incidents in the operation of an <abbr title="Automated Vehicle">AV</abbr> should be publicly investigated and reported. A road collision investigation unit should have a duty to report publicly on serious incidents. Evidence gathered during the investigation should be published so that others can learn lessons.<sup role="doc-noteref"><a class="govuk-link" href="#fn:52" rel="footnote">[footnote 52]</a></sup>
</td>
      <td>Road collision investigation branch</td>
    </tr>
    <tr>
      <td>40. <abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr> should commission public dialogue and social research to seek public views on:<br><br>a) Balancing the tensions between achieving a ‘safety-first culture’ and ensuring sufficient accountability for the consequences of <abbr title="Automated Vehicle">AV</abbr> behaviour;<br>b) The distribution of <abbr title="Automated Vehicle">AV</abbr> risks and benefits;<br>c) Future changes to infrastructure and rules of the road and any associated costs;<br>d) Explainability of decisions made by AVs;<br>e) Labelling of vehicles.</td>
      <td><abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr></td>
    </tr>
  </tbody>
</table>

<h3>Trials</h3>

<p>It will be particularly important for trialling organisations (or ASDEs where relevant) to engage with local communities in the vicinity of their trials in order to understand opportunities and concerns. In the absence of governance attention, trials of technologies could become de facto deployments. Safety cases that are currently built around the presence of a safety driver (who is understood to have full responsibility) will look very different from safety cases for self-driving systems. Public trials of the technology are opportunities for learning beyond the data collection carried out by the company running the test. Other parties should be encouraged and empowered to engage with and learn from the experiences of AVs on public roads. Local authorities will have interests in the future viability of <abbr title="Automated Vehicle">AV</abbr> services that might emerge from trials happening in their area, but they may lack the resources to engage with trialling organisations in the co-design of trials or in making sense of trial data.</p>

<p>As trials of the technology are in many cases happening in public, there may be a slippery slope from trials to de facto deployments of the technology as numbers of vehicles scale up and ODDs expand. Large-scale, highly concentrated deployments, measured by number of vehicles within a particular area, for example, may have different ethical implications from smaller deployments. The line between testing and deployment may be hard to draw. Systems that are deployed may (and in many cases should) be used to gather ongoing data to improve safety, service design etc.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>41. Where AVs are being trialled, the safety driver should not be removed unless the vehicle is authorised<sup role="doc-noteref"><a class="govuk-link" href="#fn:53" rel="footnote">[footnote 53]</a></sup>, and AVs should only carry passengers where the appropriate passenger licence has been issued.<br><br><abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr> should support local authorities to monitor trials in their area (e.g. to identify significant increases in the number of vehicles involved in a trial) and to make passenger licencing decisions, for example via guidance.</td>
      <td>
<abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr>, in-use regulator and Authorisation authority</td>
    </tr>
    <tr>
      <td>42. Where an <abbr title="Authorised Self-Driving Entity">ASDE</abbr> is given a limited authorisation to trial an <abbr title="Automated Driving System(s)">ADS</abbr> feature, the vehicle must be re-authorised should the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> wish to deploy the feature in a wider context.</td>
      <td>Authorisation authority and In-use regulator</td>
    </tr>
  </tbody>
</table>

<h3>Labelling</h3>

<p>The labelling of vehicles is ethically complex. Self-driving vehicles should be considered a new class of road user when operating in mixed traffic. They will not always behave in the same way as human drivers do (recognising that there is a wide range of ‘normal’ driving behaviour) and while there may be some external signs of novelty (e.g. large Lidar sensors on a vehicle’s roof), people may not know what these mean or if a vehicle is being driven by a human or by software. Sensors are likely to become smaller over time and in some cases would be essentially invisible, making some AVs indistinguishable from conventional cars. The novelty of AVs creates an argument based on the principle of human autonomy that people have a right to know what sort of agents they are sharing the road with. With some of the low-speed crashes in which human drivers have been blamed for collisions with some types of self-driving vehicles, we can assume that uncertainty about the often ultra-cautious manoeuvres of those vehicles was a contributory factor.</p>

<p>One of the Engineering and Physical Sciences Research Council principles for robotics <a class="govuk-link" href="https://www.tandfonline.com/doi/full/10.1080/09540091.2016.1271400" rel="external">states</a>, ‘Robots are manufactured artefacts. They should not be designed in a deceptive way to exploit vulnerable users; instead their machine nature should be transparent’. The range of possible interactions on the road make labelling complicated in practice, but this principle represents a good starting point.</p>

<p>However, labelling could change the distribution of responsibilities in profound ways. An expectation that other road users will understand and adapt (as with emergency vehicle warning lights and sirens or L-plates for learner drivers) could be interpreted as an abdication of <abbr title="Automated Vehicle">AV</abbr> developers’ responsibility.&nbsp; Additionally, self-driving vehicle companies may be concerned that clear labelling will lead other road users to behave differently around their vehicles, affecting their data collection, or to take advantage of their vehicles’ assumed greater caution. The emergence of AVs onto roads will shift the responsibilities of all road users, as previous technologies have done. On balance, it is better that this is done in a deliberate and informed way rather than under conditions in which road users are uncertain. This should be seen as part of the debate on wider changes to rules of the road. The ethics of on-road communication with other road users should not be overlooked as systems develop. The practicalities of labelling would need careful research and discussion, but there is clear <a class="govuk-link" href="https://driverless-futures.com/2022/05/09/survey-reports/" rel="external">public support</a> for the principle; 86% of UK survey respondents agreed or strongly agreed that ‘it must be clear when a vehicle is driving itself’.</p>

<p>External Human-Machine Interfaces (e.g. lights or display panels that clarify when an <abbr title="Automated Vehicle">AV</abbr> has detected a pedestrian and deemed it safe to cross) may be deemed necessary by some ASDEs, in shared spaces or to break deadlocks at crossings. Such innovations would need to be developed with care, as they may be used as an excuse for unsafe practices by creating expectations that vulnerable road users should understand and know how to respond to signals.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>43. AVs should be clearly labelled. Where vehicles can drive themselves or be driven conventionally at different times, signals should indicate the status of operation. This external labelling should be in addition to information inside the vehicle that clearly indicates mode of operation. <abbr title="Automated Vehicle">AV</abbr> tests and deployments should be clearly publicised within and near the relevant location.</td>
      <td>ASDEs, with oversight from the authorisation authority<sup role="doc-noteref"><a class="govuk-link" href="#fn:54" rel="footnote">[footnote 54]</a></sup>
</td>
    </tr>
    <tr>
      <td>44. <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should review and advise on the practicalities of labelling and the questions of liability raised by External Human-Machine Interfaces on AVs.</td>
      <td>Committee on <abbr title="Automated Vehicle">AV</abbr> Ethics and Safety (<abbr title="Committee on AV Ethics and Safety">CAVES</abbr>)</td>
    </tr>
  </tbody>
</table>

<h2>
<span class="number">7. </span> Governance</h2>

<h3>Introduction</h3>

<p>Refining and implementing this framework will take time because the introduction of more sophisticated ADSs and AVs will take place over years and decades. Also, implementing the framework will involve judgements by individual ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s which can have an impact on the safety and wellbeing of all road users and other stakeholders. Whilst some of these are rightly the province of such organisations, there are areas where there is a need for consistent standards between ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s, both to uphold societal norms and to avoid risks that might arise due to inconsistency in behaviour between different AVs. It is not possible to be prescriptive about such issues - certainly not with sufficient foresight - hence we recommend the establishment of a joint Committee on <abbr title="Automated Vehicle">AV</abbr> Ethics and Safety (<abbr title="Committee on AV Ethics and Safety">CAVES</abbr>) to advise the relevant authorities and to seek consensus on those issues which need to be managed and agreed centrally, to support the safe and ethical introduction of AVs on UK roads.</p>

<h3>Committee on <abbr title="Automated Vehicle">AV</abbr> Ethics and Safety</h3>

<p>The purpose of the Committee should be to provide contestable advice and recommendations - as opposed to decisions - on policy and ethical issues regarding the safety of AVs. The scope of the advice and recommendations is likely to include issues relevant to policy, authorisation, and in-use regulation and therefore should be issued to the Department for Transport, including its motoring agencies. The Committee should assess the benefits of AVs alongside the risks to provide a balanced governance approach. We would expect the committee to sit within the Department for Transport and be managed by <abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr>.</p>

<p>In line with the government’s code of practice on scientific advisory committees and councils, the purpose of <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> would be ‘to access, interpret and understand the full range of relevant scientific information, and to make judgements about its relevance, potential and application’. The scientific expertise should be broad and <a class="govuk-link" href="https://www.gov.uk/government/publications/scientific-advisory-committees-code-of-practice/code-of-practice-for-scientific-advisory-committees-and-councils-copsac-2021">lay members</a> ‘may act as a critical friend, contribute experience from outside the professional membership, or provide an external non-expert perspective to the decision-making process’. We see the Food Standard Agency’s <a class="govuk-link" href="https://www.food.gov.uk/about-us/scientific-advisory-committees" rel="external">scientific advisory committees</a> (e.g. The Advisory Committee on Novel Foods and Processes) as a useful model that <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> could follow.</p>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>45. The authorisation authority and in-use regulator should establish a <strong>joint Committee on <abbr title="Automated Vehicle">AV</abbr> Ethics and Safety (<abbr title="Committee on AV Ethics and Safety">CAVES</abbr>)</strong> composed of experts and lay members with a diverse range of perspectives (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 30 - in-use regulator’s duty to consult).<br><br>a) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should report to the Secretary of State for Transport (<abbr title="Department for Transport">DfT</abbr>). Since the SoS’s powers will likely be delegated to the motoring agencies, in practice <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> will advise the motoring agencies (which are themselves part of <abbr title="Department for Transport">DfT</abbr>).<br>b) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr>’ recommendations and policy advice should be issued to <abbr title="Department for Transport">DfT</abbr> and the regulators in parallel for full visibility. Its reports and minutes should be public by default (recognising that some discussions will need to be held in private). <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should provide advice and constructive challenge to <abbr title="Department for Transport">DfT</abbr>. It should not make policy decisions or overrule the Secretary of State.<br>c) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should have a standing Road Rules Subcommittee that includes stakeholders representing different groups of road users, to provide advice on the definition of the <abbr title="Road Rules">RR</abbr>, including consistency with published specifications for Automated Driving Systems (<abbr title="Automated Driving System(s)">ADS</abbr>), especially on ethical rules and priorities.<sup role="doc-noteref"><a class="govuk-link" href="#fn:55" rel="footnote">[footnote 55]</a></sup><br>d) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should be constituted as a non-statutory, Scientific Advisory Committee, with diverse membership, including lay member representation (e.g. vulnerable road users). Expertise should include engineering, artificial intelligence, human factors, transport planning and policy, road safety, ethics and public engagement. The committee should pay particular attention to questions of accessibility, and should include a member with expertise in disability issues (See <abbr title="Law Commission(s)">LC</abbr> Rec. 63 - accessibility advisory panel).<br>e) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should draw on the views of a wide range of stakeholders and undertake stakeholder engagement to ensure that the needs of all classes of road users (including vulnerable road users) are considered in defining the <abbr title="Road Rules">RR</abbr> and in assuring the overall governance of AVs, including authorisation and temporary restrictions of <abbr title="Automated Vehicle">AV</abbr> operations.</td>
      <td>Authorisation authority; In-use Regulator.</td>
    </tr>
    <tr>
      <td>46. <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should have responsibility for assessing regulatory decisions, and should advise on complex issues related to the regulation and governance of AVs, such as labelling, differentiated treatment towards vulnerable road users, and explainability.<br><br>a) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should assess regulatory decisions, and provide <abbr title="Department for Transport">DfT</abbr> with assurance that the authorisation decision and forms of restrictions on AVs imposed by the regulators provide an appropriate alignment between innovation and safety;<br>b) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should review and advise on the practicalities of labelling and the questions of responsibility raised by External Human-Machine Interfaces on AVs;<br>c) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should review the desirability of appropriately differentiated treatment towards vulnerable road users, and what additional reporting duties may be required;<br>d) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should review the degree of explainability needed for regulatory oversight.</td>
      <td>Authorisation authority; In-use Regulator.</td>
    </tr>
  </tbody>
</table>

<h2>Next steps</h2>

<p>The recommendations in this report will support and guide the Department for Transport as they deliver ‘Connected &amp; Automated Mobility 2025: realising the benefits of self-driving vehicles’ (link), a roadmap that commits to developing a new legislative framework that builds trust in self-driving vehicles while enabling innovation.</p>

<p>After laying primary legislation before Parliament in 2022, the Department for Transport will develop and consult on secondary legislation that will set out the details of the requirements and processes of the new legislative framework for self-driving vehicles in 2023. This report will closely inform the development of that secondary legislation.</p>

<p>In particular, our recommendations will inform the design of the new safety framework for self-driving vehicles, and will shape the requirements for what constitutes a sufficient safety case by <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s. Following consultation, the Department for Transport expects to publish further guidance on this issue, closely informed by the recommendations of this report.</p>

<h2>Annex A: Safe and Ethical Operational Concept and Safety Management Systems</h2>

<h3>Safe and Ethical Operational Concept (<abbr title="Safe and Ethical Operational Concept">SEOC</abbr>)</h3>

<p>The intent of this brief note is to sketch out what (part of) a Safe and Ethical Operational Concept (<abbr title="Safe and Ethical Operational Concept">SEOC</abbr>) might look like. As identified above, the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> would be a set of constraints on vehicle behaviour, including motion, signalling to other road users, and actions to preserve their own safety.</p>

<p>The <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> would be defined as a set of&nbsp; Self-Driving Constraints (SDCs) and precedence between these constraints, as they can conflict in certain circumstances. The constraints would also cover signalling as appropriate signalling can reduce concern (and misleading signalling might increase concern). We illustrate part of a <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> that relates to motion. These are intended to be illustrative and an <abbr title="Authorised Self-Driving Entity">ASDE</abbr>’s <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> would need to be thought through from their perspective on safe and ethical behaviour, e.g. the extent to which they prioritise safety of vulnerable road users. The intent here is to identify some example SDCs, some clear precedence rules, and some situation-dependent precedences so the concept is clear.</p>

<p><strong>Table 1: Example SDCs</strong></p>

<table>
  <tbody>
    <tr>
      <td><strong>SDC</strong></td>
      <td><strong>Description</strong></td>
    </tr>
    <tr>
      <th scope="row">1</th>
      <td>Avoid collision with all other objects</td>
    </tr>
    <tr>
      <th scope="row">2</th>
      <td>Maintain safe distance to other objects (given predicted trajectories)</td>
    </tr>
    <tr>
      <th scope="row">3</th>
      <td>Remain on the road, except at an access point to the roadside (e.g. house drive, car park entrance)</td>
    </tr>
    <tr>
      <th scope="row">4</th>
      <td>Avoid movement that can cause discomfort or harm to passengers</td>
    </tr>
    <tr>
      <th scope="row">5</th>
      <td>Leave the road away from an access point where this reduces overall risk</td>
    </tr>
    <tr>
      <th scope="row">6</th>
      <td>Avoid movements that cause other vehicles to violate any other SDC</td>
    </tr>
    <tr>
      <th scope="row">7</th>
      <td>Avoid movements that cause individuals concern about their safety</td>
    </tr>
    <tr>
      <th scope="row">8</th>
      <td>Follow directions given by authorised persons</td>
    </tr>
  </tbody>
</table>

<p><strong>Table 2: Example SDC Precedences</strong></p>

<table>
  <tbody>
    <tr>
      <td><strong>SDC Precedence</strong></td>
    </tr>
    <tr>
      <td>SDC 1 takes precedence over SDC 4 (e.g. an emergency stop for an unanticipated object in a vehicle path)</td>
    </tr>
    <tr>
      <td>SDC 5 takes precedence over SDC 3 (if doing so satisfies SDC 1)</td>
    </tr>
  </tbody>
</table>

<p><strong>Table 3: Example SDC Situation Dependent Precedences</strong></p>

<table>
  <tbody>
    <tr>
      <td><strong>Initiator</strong></td>
      <td><strong>Possible Constraint Conflict</strong></td>
      <td><strong>Constraint Honoured</strong></td>
    </tr>
    <tr>
      <td>Response to Authorised Person (Constraint 8)</td>
      <td>Response leads to conflict with constraint 1<br><br>Response leads to conflict with constraint 2<br><br>Response leads to conflict with constraint 3<br><br>Response leads to conflict with constraint 7</td>
      <td>1<br><br><br>8<br><br><br>3<br><br><br>8</td>
    </tr>
  </tbody>
</table>

<p>This is intended to be simple enough to communicate the concept. Specific road rules, e.g. clauses from&nbsp; the Highway Code, would be organised under these top-level SDCs, where appropriate. It would&nbsp; be expected that the notifiable events would include items from Table 3 where active (dynamic) choices have to be made between the SDCs; they would probably also include the ‘triggering’ of the precedences from Table 2.</p>

<h3>Safety Management Systems (<abbr title="Safety Management System">SMS</abbr>)</h3>

<p><strong>For ASDEs:</strong></p>

<p>The <abbr title="Safety Management System">SMS</abbr> should include, at a minimum:</p>

<ol>
  <li>A process for safety assessment of design, verification and change relating to the vehicle, covering software, hardware, subsystems and data.</li>
  <li>Procedures and mechanisms for responding to test failures, incidents, collisions&nbsp; and hazardous failures.</li>
  <li>Processes, procedures, competencies, certifications and training for vehicle design, manufacture, maintenance and upgrade activities.</li>
  <li>Processes for responding to directives from regulators, including making design changes and communicating to users/operators of the vehicle.</li>
  <li>Processes for updating the safety documentation to allow for regular review and re-issue as appropriate.</li>
</ol>

<p><strong>For <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s:</strong></p>

<p>The <abbr title="Safety Management System">SMS</abbr> should include, at a minimum:</p>

<ol>
  <li>A process for safety assessment of changes relating to the vehicle and its safety case, deployment routes and infrastructure.</li>
  <li>Procedures and mechanisms for responding to incidents, collisions and hazardous failures.</li>
  <li>A process for management of specific restrictions, deviations and waivers covering the vehicle, infrastructure and routes, arising from the in-use regulator and other authorities.</li>
  <li>Processes, procedures, competencies, certifications and training for vehicle operation, maintenance and upgrades.</li>
  <li>Processes for updating the safety documentation to allow for regular review and re-issue as appropriate.</li>
</ol>

<h2>Annex B: List of recommendations</h2>

<h3>Road safety</h3>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>1. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall define the <abbr title="Automated Vehicle">AV</abbr> <abbr title="Operational Design Domain">ODD</abbr> to be consistent with the relevant Road Rules (<abbr title="Road Rules">RR</abbr>) and to cover all classes of road users including vulnerable road users that can reasonably be expected in the <abbr title="Operational Design Domain">ODD</abbr>.<br><br>The <abbr title="Operational Design Domain">ODD</abbr> definition should include all relevant features defined to an appropriate level of detail. The definition should cover the parameter ranges for fixed scenery elements, attributes of dynamic elements and environmental elements. It should also include all ethically salient features relating to other road users.<br><br>Further guidance will be needed from <abbr title="Department for Transport">DfT</abbr> to define these ethically salient features.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>2. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall ensure that the deployment domain is compatible with the <abbr title="Operational Design Domain">ODD</abbr> prior to operational use of the <abbr title="Automated Vehicle">AV</abbr>.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> reporting to the In-use regulator</td>
    </tr>
    <tr>
      <td>3. The authorisation authority, in concert with the in-use regulator, shall develop and publish guidance on <abbr title="Road Rules">RR</abbr> in the context of self-driving vehicles, with input from the <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> Road Rules Subcommittee, to inform the development of SEOCs that:<br><br>a) give complete coverage of situations that an <abbr title="Automated Vehicle">AV</abbr> could reasonably be anticipated to encounter in the <abbr title="Operational Design Domain">ODD</abbr>;<br>b) reflect rules of behaviour that are ethical and broadly acceptable across different types of <abbr title="Automated Vehicle">AV</abbr>; and<br>c) identify precedence between the rules.</td>
      <td>Authorisation authority</td>
    </tr>
    <tr>
      <td>4. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall define a <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, including Self-Driving Constraints (SDCs) (see <a class="govuk-link" href="#Annex-A">Annex A</a> for more detail), for inclusion within its <abbr title="Safety Case Report">SCR</abbr> submitted as part of authorisation, for the behaviour of the <abbr title="Automated Vehicle">AV</abbr> in its <abbr title="Operational Design Domain">ODD</abbr>, that:<br><br>a) complies with road rules (<abbr title="Road Rules">RR</abbr>);<br>b) complies with any applicable regulations for automated driving system (<abbr title="Automated Driving System(s)">ADS</abbr>);<br>c) minimises occurrence of ‘at-fault’ collisions in its defined <abbr title="Operational Design Domain">ODD</abbr>;<br>d) mitigates risk of ‘non-fault’ collisions in its defined <abbr title="Operational Design Domain">ODD</abbr>;<br>e) manages entry to and exit from the <abbr title="Operational Design Domain">ODD</abbr>, ensuring a transition to safe control of the <abbr title="Automated Vehicle">AV</abbr> by the <abbr title="User-in-Charge">UiC</abbr> where there is one, or a safe transition to a minimal risk condition (<abbr title="Minimal Risk Condition">MRC</abbr>) on exiting the deployment domain;<br>f) does not unfairly discriminate against road users or otherwise unfairly treat vulnerable road users;<br>g) does not require other road users to violate applicable rules or SDCs;<br>h) defines the priority of rules and SDCs where they can conflict in particular circumstances;<br>i) does not cause individuals in the vicinity of the <abbr title="Automated Vehicle">AV</abbr> unjustified concern about their safety;<br>appropriately balances the need to make progress with the need to ensure safety.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>5. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall demonstrate to the authorisation authority that they have designed the <abbr title="Automated Vehicle">AV</abbr> to be consistent with the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, and provide supporting arguments and links to evidence in a <abbr title="Safety Case Report">SCR</abbr> to gain authorisation for self-driving. The <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> shall be made publicly available once authorisation is granted.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>6. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall monitor the operation of the <abbr title="Automated Vehicle">AV</abbr> to identify situations where it fails to implement the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, inform the in-use regulator of ‘notifiable events’ and take action to resolve deviations from the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> that are not notifiable. Government will need to consider how this interacts with <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s and what their obligations in relation to the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr> will be.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, with oversight from the In-use regulator</td>
    </tr>
    <tr>
      <td>7. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall comply with instructions from the in-use regulator or authorisation authority, e.g. to limit the <abbr title="Automated Vehicle">AV</abbr> deployment domain or modify the vehicle design, to ensure continued safety of operation.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>
</td>
    </tr>
    <tr>
      <td>8. ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall keep their <abbr title="Safety Case Report">SCR</abbr> up to date and produce it to the authorisation authority when required to gain approval for changes to the vehicle prior to deploying the changes as part of the vehicle’s re-authorisation.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>9. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall operate a safety management system (<abbr title="Safety Management System">SMS</abbr>) for the <abbr title="Automated Vehicle">AV</abbr> governing how they manage safety through the <abbr title="Automated Vehicle">AV</abbr> lifecycle, and provide periodic independent <abbr title="Safety Management System">SMS</abbr> audit reports to the in-use regulator.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, with oversight from the Authorisation authority and In-use regulator</td>
    </tr>
    <tr>
      <td>10. The authorisation authority should assess <abbr title="Safety Management System">SMS</abbr> and safety culture within ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s as part of the authorisation and licensing decisions respectively, and approve deployments where they meet applicable criteria.</td>
      <td>Authorisation authority</td>
    </tr>
    <tr>
      <td>11. For authorisation purposes, the authorisation authority shall assess the safety of <abbr title="Automated Vehicle">AV</abbr> deployments based on:<br><br>a) the <abbr title="Safety Case Report">SCR</abbr><br>b) independent <abbr title="Safety Management System">SMS</abbr> audit reports<br>c) notifiable events (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 20 - data gathering on safety)<br><br>The in-use regulator should assess a), b), and c) on an ongoing basis.</td>
      <td>Authorisation authority and In-use regulator</td>
    </tr>
    <tr>
      <td>12. The authorisation authority shall define ‘notifiable events’ in terms of deviation from the <abbr title="Authorised Self-Driving Entity">ASDE</abbr>’s <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>. It will, at a minimum, include traffic infractions as defined by the Law Commissions; an incident that had it been performed by a human driver would have attracted criminal or civil penalties (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 20 - data gathering on safety).</td>
      <td>Authorisation authority</td>
    </tr>
    <tr>
      <td>13. The authorisation authority shall define a scheme for determining what changes to <abbr title="Automated Vehicle">AV</abbr> performance are significant enough to require re-authorisation prior to ASDEs supplying updates to deployed AVs.</td>
      <td>Authorisation authority</td>
    </tr>
    <tr>
      <td>14. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall design the <abbr title="Automated Vehicle">AV</abbr> so that transfers of authority for control of the <abbr title="Dynamic Driving Task">DDT</abbr> from the <abbr title="Automated Vehicle">AV</abbr> to the <abbr title="User-in-Charge">UiC</abbr> shall ensure safety, including providing the <abbr title="User-in-Charge">UiC</abbr> with sufficient time and information to achieve situational awareness before they engage in the <abbr title="Dynamic Driving Task">DDT</abbr>.<br><br>The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall have responsibility and accountability for behaviour of the <abbr title="Automated Vehicle">AV</abbr> both within and outside the <abbr title="Operational Design Domain">ODD</abbr> unless it is confirmed that the <abbr title="User-in-Charge">UiC</abbr> has authority for control of the <abbr title="Dynamic Driving Task">DDT</abbr>.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
  </tbody>
</table>

<h3>Data privacy</h3>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>15. The <abbr title="Automated Vehicle">AV</abbr> regulator(s) should issue guidance for ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s clarifying how Data Protection obligations apply to AVs, in consultation with the Information Commissioner’s Office. Issues that could be covered include:<br><br>a) The requirement to conduct a Data Protection Impact Assessment (<abbr title="Data Protection Impact Assessment">DPIA</abbr>), and to make this document publicly available alongside the vehicle’s safety case report at authorisation;<br>b) Clarification that an <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and/or <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s should prepare suitable DPIAs and make available for authorisation and licensing decisions;<br>c) A self-assessment checklist to establish whether the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> / <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> is acting as a controller, processor, or joint controller; <br>d) Any requirements to secure valid consent from the <abbr title="User-in-Charge">UiC</abbr> or passengers for processing personal data within the vehicle (such as what kinds of data collection would constitute ‘location data’ and ‘cookies or similar’ under <abbr title="Privacy and Electronic Communications Regulations">PECR</abbr>) and where additional consent may be required, such as when there are new passengers in the vehicle; <br>e) Proposed retention and deletion schedules for personal data collected by AVs, particularly location data;<br>f) What would be considered necessary and legitimate purposes for processing and sharing personal data (e.g. safety improvements, insurance claims etc.);<br>g) Circumstances under which processing of personal data of other road users outside the vehicle (such as facial images of pedestrians) is likely to be considered lawful and proportionate under Article 6 <abbr title="General Data Protection Regulation">GDPR</abbr> (e.g. vital interests, or legitimate interests);<br>h) Circumstances under which processing of special category personal data (e.g. biometric data of the <abbr title="User-in-Charge">UiC</abbr>) is likely to be considered lawful and proportionate under Article 9 <abbr title="General Data Protection Regulation">GDPR</abbr> (e.g. explicit consent, or substantial public interest); <br>i) The testing of AI systems for AVs against the requirement ‘to design the <abbr title="Automated Vehicle">AV</abbr> so that it is possible to construct an explanation&nbsp; of the key decisions made by the <abbr title="Automated Vehicle">AV</abbr> leading up to the notifiable event, however caused’. See Rec. 29;<br>j) Which <abbr title="Automated Driving System(s)">ADS</abbr> features (if any) could be considered ‘a decision based solely on automated processing, including profiling, which produces legal effects concerning [the data subject] or similarly significantly affects [the data subject]’, for the purposes of Article 22 <abbr title="General Data Protection Regulation">GDPR</abbr>.</td>
      <td>
<abbr title="Information Commissioner’s Office">ICO</abbr>; Authorisation authority; In-use regulator</td>
    </tr>
    <tr>
      <td>16. ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s shall ensure that ‘data protection by design and by default’ measures are incorporated throughout the <abbr title="Automated Vehicle">AV</abbr> development process. This should include:<br><br>a) Ensuring any personal data collected by AVs or for training <abbr title="Automated Vehicle">AV</abbr> systems is strictly limited to what is necessary for the purpose for which it is processed; <br>b) Ensuring any personal data that is not necessary to perform the legitimate purposes established by Rec. 15(f) is anonymised at the point of collection or creation (for instance by blurring or pixelating facial image data of pedestrians);<br>c) Ensuring any personal data is only stored for as long as is strictly necessary, and is not transferred from the vehicle except for specific, clearly defined purposes, with reference to the legitimate purposes established by Rec. 15(f);<br>d) Ensuring that any sharing of personal data that is required for one of the legitimate purposes established by Rec. 15(f) is done in a way that protects individuals privacy, for instance through the use of differential privacy techniques.</td>
      <td>Authorisation authority</td>
    </tr>
    <tr>
      <td>17. Where ASDEs are collecting camera data of other road users, they should ensure adherence to the <a class="govuk-link" href="https://www.gov.uk/government/publications/update-to-surveillance-camera-code">12 guiding principles</a> in the Surveillance Camera Code of Practice, and consider applying for certification under the Biometrics and Surveillance Camera Commissioner’s <a class="govuk-link" href="https://www.gov.uk/government/publications/surveillance-camera-code-of-practice-third-party-certification-scheme#:~:text=Guidance-,Surveillance%20camera%20code%20of%20practice%3A%20third%20party%20certification%20scheme,surveillance%20camera%20code%20of%20practice.">third party certification scheme</a>.<br><br>The authorisation authority should review adherence to the 12 guiding principles in the Surveillance Camera Code of Practice as part of the authorisation decision.</td>
      <td>Authorisation authority; Surveillance Camera Commissioner</td>
    </tr>
    <tr>
      <td>18. As per the Surveillance Camera Code, any <abbr title="Automated Vehicle">AV</abbr> cameras (either within or outside the vehicle) should be clearly labelled. If AVs are collecting camera data of other road users, this should be clearly labelled on the outside of vehicles.</td>
      <td>Authorisation authority; Surveillance Camera Commissioner</td>
    </tr>
    <tr>
      <td>19. The Home Office should issue guidance clarifying how the Police and Criminal Evidence Act 1984 applies to <abbr title="Automated Vehicle">AV</abbr> data and specifically the grounds under which it could be considered evidence in relation to an offence.<br><br>The Home Office should issue guidance clarifying how the Investigatory Powers Act 2016 applies to ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s.</td>
      <td>Home Office</td>
    </tr>
  </tbody>
</table>

<h3>Fairness</h3>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>20. To minimise the risk of algorithmic bias, ASDEs’ safety cases and impact assessments should report on the fit between their training data and their ODDs. Substantially altered ODDs should require new reports on training data.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, with oversight from the Authorisation authority</td>
    </tr>
    <tr>
      <td>21. Where training data distinguishes between categories of road users, e.g. between children and adults for reasons of safety, this should be acknowledged as part of the safety case and reported to the authorisation authority. Steps should be taken to anticipate and minimise unfair consequences resulting from data bias, including discrimination.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, with oversight from the Authorisation authority</td>
    </tr>
    <tr>
      <td>22. Where systems distinguish between groups while driving, justified on the grounds of safety, e.g. the identification of children, wheelchair users or other vulnerable road users, ASDEs should have a duty to report in order to allow independent scrutiny (including, but not limited to, reporting this in the safety case).</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, with oversight from the Authorisation authority and In-use regulator</td>
    </tr>
    <tr>
      <td>23. ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s should facilitate independent scrutiny of emerging risks and biases (in addition to those raised by notifiable events) so that the distribution of risks can be assessed.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, with oversight from the in-use regulator and Authorisation authority</td>
    </tr>
    <tr>
      <td>24. The in-use regulator, advised by <abbr title="Committee on AV Ethics and Safety">CAVES</abbr>, should collect data on fairness and safety outcomes in order to allow feedback to operators and collective learning. In the event that serious problems are identified and no other means prove effective in mitigation, the regulator should be empowered to impose sanctions, up to and including de-authorisation and product recall (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 20 - data gathering on safety).<br><br>The in-use regulator should also compile evidence for where an amendment to the regulatory framework may be necessary (e.g. updates to the <abbr title="Road Rules">RR</abbr>) to ensure that AVs are acceptably safe, with continual improvements in safety (see also Rec. 8).</td>
      <td>In-use regulator</td>
    </tr>
    <tr>
      <td>25. <abbr title="Automated Vehicle">AV</abbr> regulators should assess the potential risks of discrimination, and the adequacy of accessibility features in their authorisation and licensing decisions, in line with their Public Sector Equality Duty (cf.&nbsp; <abbr title="Law Commission(s)">LC</abbr> Rec. 63 - accessibility advisory panel).</td>
      <td>Authorisation authority and licensing authority</td>
    </tr>
    <tr>
      <td>26. ASDEs should not, as part of their <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, require vulnerable road users to carry or wear anything to make them more easily detectable to AVs. Should vulnerable road users decide to use such devices, however, ASDEs should not ignore their potential additional safety benefits.</td>
      <td>Authorisation authority and In-use regulator</td>
    </tr>
    <tr>
      <td>27. If infrastructure upgrades are required that contribute to <abbr title="Automated Vehicle">AV</abbr> safety, their costs and benefits for other road users should be fully understood and carefully balanced.</td>
      <td>Local authorities and other infrastructure bodies; National Infrastructure Commission</td>
    </tr>
  </tbody>
</table>

<h3>Explainability</h3>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>28. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> should design the <abbr title="Automated Vehicle">AV</abbr> so that it is possible to construct an explanation of the key decisions made by the <abbr title="Automated Vehicle">AV</abbr> when it is undertaking the Dynamic Driving Task (<abbr title="Dynamic Driving Task">DDT</abbr>) for a bounded test scenario. These explanations should be made available as required under the duty of disclosure including, as a minimum:<br><br>a) to the authorisation authority as part of the <abbr title="Safety Case Report">SCR</abbr>;<br>b) to the <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> where appropriate.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the appropriate regulator</td>
    </tr>
    <tr>
      <td>29. For collisions, near misses and other notifiable events, the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> should design the <abbr title="Automated Vehicle">AV</abbr> so that it is possible to construct an explanation of the key decisions made by the <abbr title="Automated Vehicle">AV</abbr> leading up to the event, however caused. This explanation should be sufficient to identify and rectify causes of undesirable behaviours, and the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> should make the explanation available to:<br><br>a) a collision investigation unit for the incident being investigated;<br>b) the in-use regulator when investigating a notifiable event to potentially apply a sanction;<br>c) other parties with a legitimate need for the information agreed in advance as part of authorisation (cf. <abbr title="Law Commission(s)">LC</abbr> Recs. 21, 22, 29 on incident investigation; cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 74 on data disclosure).</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority; also In-use regulator and collision investigation unit</td>
    </tr>
  </tbody>
</table>

<h3>Data sharing</h3>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>30. In consultation with the authorisation authority, the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> shall publish a summary of the <abbr title="Safe and Ethical Operational Concept">SEOC</abbr>, which will be made publicly and freely available upon authorisation of the vehicle for self-driving.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>31. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> should communicate safety-relevant data with other organisations in the <abbr title="Automated Vehicle">AV</abbr> ecosystem when requested, including other ASDEs, the in-use regulator, the authorisation authority and the collision investigation unit, using agreed data formats, where this contributes to road safety. Data formats should be decided by the authorisation authority and in-use regulator, in consultation with the <abbr title="Information Commissioner’s Office">ICO</abbr>.<br><br>a) The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> should share core safety-relevant data as stipulated by the in-use regulator and collision investigation unit; (note that there will be some aspects of safety-relevant data that the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> will be legally required to share for law enforcement purposes.)<br>b) The in-use regulator and collision investigation unit should consult on the agreed scope and format of the core safety-relevant data they will require from ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s;<br>c) The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> should be encouraged to share data with interested parties, using standards and formats developed via consensus;<br>d) Regulators and the <abbr title="Automated Vehicle">AV</abbr> sector should explore the ways in which mechanisms that facilitate responsible sharing of commercially sensitive data, such as data intermediaries, could be used;<br>e) ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s should explore the use of privacy-enhancing technologies such as <a class="govuk-link" href="https://cdeiuk.github.io/pets-adoption-guide/what-are-pets" rel="external">federated learning techniques</a>, to minimise the volume of personal data that is uploaded to a centralised server.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, with oversight from the In-use regulator</td>
    </tr>
    <tr>
      <td>32. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall provide summarised safety performance data to relevant bodies including the in-use regulator to enable the safe, ethical and effective operation of the <abbr title="Automated Vehicle">AV</abbr> marketplace (cf. <abbr title="Law Commission(s)">LC</abbr> Recs. 20, 74).</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, reporting to the Authorisation authority</td>
    </tr>
    <tr>
      <td>33. The <abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr> shall support reasonable access to all relevant proprietary information by a road collision investigation unit and other authorised bodies to enable collision and incident analysis and support the authorities in producing lessons learnt for dissemination to other ASDEs.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr> and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, with oversight from the In-use regulator</td>
    </tr>
    <tr>
      <td>34. The in-use regulator shall define formats for safety-relevant data to enable sharing between relevant organisations, including ASDEs, the authorisation authority and the collision investigation unit, to ensure consistency and equity in regulation. This could be achieved via the guidance the Commissions recommend they publish on data sharing.</td>
      <td>In-use regulator</td>
    </tr>
  </tbody>
</table>

<h3>Public trust</h3>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>35. The rules on the use of terminology such as ‘self-driving’ should include requirements to inform the public about the conditions under which self-driving vehicles can operate, e.g. road types, locations, weather, other road users’ behaviour.</td>
      <td>ASDEs, Authorisation authority and In-use regulator</td>
    </tr>
    <tr>
      <td>36. An accessible summary of the <abbr title="Safety Case Report">SCR</abbr> should be made public and should include clear statements of the functions and limits of an <abbr title="Automated Vehicle">AV</abbr> within an <abbr title="Operational Design Domain">ODD</abbr>.</td>
      <td>ASDEs, Authorisation authority</td>
    </tr>
    <tr>
      <td>37. The in-use regulator shall regularly publish publicly accessible reports on the achieved level of safety of AVs, which should include records of notifiable events and actions taken to improve safety of deployed AVs, including updates to the Road Rules. This should form part of its duty to publish evidence of <abbr title="Automated Vehicle">AV</abbr> safety, as recommended by the Law Commissions (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 19).</td>
      <td>In-use regulator</td>
    </tr>
    <tr>
      <td>38. Prospective ASDEs and <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>s should engage with local communities, including local authorities, when an <abbr title="Automated Vehicle">AV</abbr> trial is planned in a particular area. This engagement should inform testing and/or deployment (e.g. placing conditions on times, places, public information, maximum speeds etc).<br><br>Where the vehicle is permitted to carry passengers, the service operator should consult with relevant authorities as proposed under the Law Commissions’ passenger permitting scheme.</td>
      <td>
<abbr title="Authorised Self-Driving Entity">ASDE</abbr>, <abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>, In-use regulator</td>
    </tr>
    <tr>
      <td>39. Serious incidents in the operation of an <abbr title="Automated Vehicle">AV</abbr> should be publicly investigated and reported. A road collision investigation unit should have a duty to report publicly on serious incidents. Evidence gathered during the investigation should be published so that others can learn lessons.</td>
      <td>Road collision investigation branch</td>
    </tr>
    <tr>
      <td>40. <abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr> should commission public dialogue and social research to seek public views on:<br><br>a) Balancing the tensions between achieving a ‘safety-first culture’ and ensuring sufficient accountability for the consequences of <abbr title="Automated Vehicle">AV</abbr> behaviour;<br>b) The distribution of <abbr title="Automated Vehicle">AV</abbr> risks and benefits;<br>c) Future changes to infrastructure and rules of the road and any associated costs;<br>d) Explainability of decisions made by AVs;<br>e) Labelling of vehicles.</td>
      <td><abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr></td>
    </tr>
    <tr>
      <td>41. Where AVs are being trialled, the safety driver should not be removed unless the vehicle is authorised, and AVs should only carry passengers where the appropriate passenger licence has been issued.<br><br><abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr> should support local authorities to monitor trials in their area (e.g. to identify significant increases in the number of vehicles involved in a trial) and to make passenger licencing decisions, for example via guidance.</td>
      <td>
<abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr>, in-use regulator and Authorisation authority</td>
    </tr>
    <tr>
      <td>42. Where an <abbr title="Authorised Self-Driving Entity">ASDE</abbr> is given a limited authorisation to trial an <abbr title="Automated Driving System(s)">ADS</abbr> feature, the vehicle must be re-authorised should the <abbr title="Authorised Self-Driving Entity">ASDE</abbr> wish to deploy the feature in a wider context.</td>
      <td>Authorisation authority and In-use regulator</td>
    </tr>
    <tr>
      <td>43. AVs should be clearly labelled. Where vehicles can drive themselves or be driven conventionally at different times, signals should indicate the status of operation. This external labelling should be in addition to information inside the vehicle that clearly indicates mode of operation. <abbr title="Automated Vehicle">AV</abbr> tests and deployments should be clearly publicised within and near the relevant location.</td>
      <td>ASDEs, with oversight from the authorisation authority</td>
    </tr>
    <tr>
      <td>44. <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should review and advise on the practicalities of labelling and the questions of liability raised by External Human-Machine Interfaces on AVs.</td>
      <td>Committee on <abbr title="Automated Vehicle">AV</abbr> Ethics and Safety (<abbr title="Committee on AV Ethics and Safety">CAVES</abbr>)</td>
    </tr>
  </tbody>
</table>

<h3>Governance</h3>

<table>
  <tbody>
    <tr>
      <td><strong>Recommendation</strong></td>
      <td><strong>Implementer</strong></td>
    </tr>
    <tr>
      <td>45. The authorisation authority and in-use regulator should establish a <strong>joint Committee on <abbr title="Automated Vehicle">AV</abbr> Ethics and Safety (<abbr title="Committee on AV Ethics and Safety">CAVES</abbr>)</strong> composed of experts and lay members with a diverse range of perspectives (cf. <abbr title="Law Commission(s)">LC</abbr> Rec. 30 - in-use regulator’s duty to consult).<br><br>a) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should report to the Secretary of State for Transport (<abbr title="Department for Transport">DfT</abbr>). Since the SoS’s powers will likely be delegated to the motoring agencies, in practice <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> will advise the motoring agencies (which are themselves part of <abbr title="Department for Transport">DfT</abbr>).<br>b) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr>’ recommendations and policy advice should be issued to <abbr title="Department for Transport">DfT</abbr> and the regulators in parallel for full visibility. Its reports and minutes should be public by default (recognising that some discussions will need to be held in private). <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should provide advice and constructive challenge to <abbr title="Department for Transport">DfT</abbr>. It should not make policy decisions or overrule the Secretary of State.<br>c) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should have a standing Road Rules Subcommittee that includes stakeholders representing different groups of road users, to provide advice on the definition of the <abbr title="Road Rules">RR</abbr>, including consistency with published specifications for Automated Driving Systems (<abbr title="Automated Driving System(s)">ADS</abbr>), especially on ethical rules and priorities.<br>d) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should be constituted as a non-statutory, Scientific Advisory Committee, with diverse membership, including lay member representation (e.g. vulnerable road users). Expertise should include engineering, artificial intelligence, human factors, transport planning and policy, road safety, ethics and public engagement. The committee should pay particular attention to questions of accessibility, and should include a member with expertise in disability issues (See <abbr title="Law Commission(s)">LC</abbr> Rec. 63 - accessibility advisory panel).<br>e) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should draw on the views of a wide range of stakeholders and undertake stakeholder engagement to ensure that the needs of all classes of road users (including vulnerable road users) are considered in defining the <abbr title="Road Rules">RR</abbr> and in assuring the overall governance of AVs, including authorisation and temporary restrictions of <abbr title="Automated Vehicle">AV</abbr> operations.</td>
      <td>Authorisation authority; In-use Regulator.</td>
    </tr>
    <tr>
      <td>46. <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should have responsibility for assessing regulatory decisions, and should advise on complex issues related to the regulation and governance of AVs, such as labelling, differentiated treatment towards vulnerable road users, and explainability.<br><br>a) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should assess regulatory decisions, and provide <abbr title="Department for Transport">DfT</abbr> with assurance that the authorisation decision and forms of restrictions on AVs imposed by the regulators provide an appropriate alignment between innovation and safety;<br>b) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should review and advise on the practicalities of labelling and the questions of responsibility raised by External Human-Machine Interfaces on AVs;<br>c) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should review the desirability of appropriately differentiated treatment towards vulnerable road users, and what additional reporting duties may be required;<br>d) <abbr title="Committee on AV Ethics and Safety">CAVES</abbr> should review the degree of explainability needed for regulatory oversight.</td>
      <td>Authorisation authority; In-use Regulator.</td>
    </tr>
  </tbody>
</table>

<h2>List of Abbreviations</h2>

<p><abbr title="Automated Driving System(s)">ADS</abbr>: Automated Driving System(s)</p>

<p><abbr title="Authorised Self-Driving Entity">ASDE</abbr>: Authorised Self-Driving Entity</p>

<p><abbr title="Automated Vehicle">AV</abbr>: Automated Vehicle (in this report we use the abbreviation ‘<abbr title="Automated Vehicle">AV</abbr>’ to refer to self-driving vehicles)</p>

<p><abbr title="Committee on AV Ethics and Safety">CAVES</abbr>: Committee on <abbr title="Automated Vehicle">AV</abbr> Ethics and Safety</p>

<p><abbr title="Centre for Connected and Autonomous Vehicles">CCAV</abbr>: Centre for Connected and Autonomous Vehicles</p>

<p><abbr title="Concept of Operations">CONOPS</abbr>: Concept of Operations</p>

<p><abbr title="Dynamic Driving Task">DDT</abbr>: Dynamic Driving Task</p>

<p><abbr title="Department for Transport">DfT</abbr>: Department for Transport</p>

<p><abbr title="Data Protection Impact Assessment">DPIA</abbr>: Data Protection Impact Assessment</p>

<p><abbr title="Data Storage System for Automated Driving">DSSAD</abbr>: Data Storage System for Automated Driving</p>

<p><abbr title="Driver and Vehicle Standards Agency">DVSA</abbr>: Driver and Vehicle Standards Agency</p>

<p><abbr title="Event Data Recorder">EDR</abbr>: Event Data Recorder</p>

<p><abbr title="Emergency Refuge Area">ERA</abbr>: Emergency Refuge Area</p>

<p><abbr title="General Data Protection Regulation">GDPR</abbr>: General Data Protection Regulation</p>

<p><abbr title="Information Commissioner’s Office">ICO</abbr>: Information Commissioner’s Office</p>

<p><abbr title="Law Commission(s)">LC</abbr>: Law Commission(s) (here refers to the Law Commission of England and Wales and the Scottish Law Commission who are joint authors of the proposals on the regulation of Automated Vehicles)</p>

<p><abbr title="Minimal Risk Condition">MRC</abbr>: Minimal Risk Condition</p>

<p><abbr title="Minimum Risk Manoeuvre">MRM</abbr>: Minimum Risk Manoeuvre</p>

<p><abbr title="New Car Assessment Programmes">NCAP</abbr>: New Car Assessment Programmes</p>

<p><abbr title="No User-in-Charge">NUiC</abbr>: No User-in-Charge</p>

<p><abbr title="No User-in-Charge vehicle Operator">NUiC Operator</abbr>: No User-in-Charge vehicle Operator</p>

<p><abbr title="Operational Design Domain">ODD</abbr>: Operational Design Domain</p>

<p><abbr title="Privacy and Electronic Communications Regulations">PECR</abbr>: Privacy and Electronic Communications Regulations</p>

<p><abbr title="Privacy-Enhancing Technologies">PETs</abbr>: Privacy-Enhancing Technologies</p>

<p><abbr title="Road Rules">RR</abbr>: Road Rules</p>

<p><abbr title="Safety Case Report">SCR</abbr>: Safety Case Report</p>

<p><abbr title="Self-Driving Vehicle">SDV</abbr>: Self-Driving Vehicle</p>

<p><abbr title="Safe and Ethical Operational Concept">SEOC</abbr>: Safe and Ethical Operational Concept</p>

<p><abbr title="Safety Management System">SMS</abbr>: Safety Management System</p>

<p><abbr title="User-in-Charge">UiC</abbr>: User-in-Charge</p>

<p><abbr title="United Nations Economic Commission for Europe">UNECE</abbr>: United Nations Economic Commission for Europe</p>

<p><abbr title="Vehicle Certification Agency">VCA</abbr>: Vehicle Certification Agency</p>

<p><abbr title="Vehicle Safety Case Report">VSCR</abbr>: Vehicle Safety Case Report</p>

<p><abbr title="Vehicle-to-Infrastructure">V2I</abbr>: Vehicle-to-Infrastructure</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li role="doc-endnote">
  <p>
    Law Commission of England and Wales and the Scottish Law Commission. <a class="govuk-link" href="https://s3-eu-west-2.amazonaws.com/lawcom-prod-storage-11jsxou24uy7q/uploads/2022/01/Automated-vehicles-joint-report-cvr-03-02-22.pdf" rel="external">Automated Vehicles: joint report</a>, January 2022. p.XVII<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:1" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Law Commission of England and Wales and the Scottish Law Commission. <a class="govuk-link" href="https://s3-eu-west-2.amazonaws.com/lawcom-prod-storage-11jsxou24uy7q/uploads/2022/01/Automated-vehicles-joint-report-cvr-03-02-22.pdf" rel="external">Automated Vehicles: joint report</a>, January 2022. p.XVII<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:2" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Law Commission of England and Wales and the Scottish Law Commission. <a class="govuk-link" href="https://s3-eu-west-2.amazonaws.com/lawcom-prod-storage-11jsxou24uy7q/uploads/2022/01/Automated-vehicles-joint-report-cvr-03-02-22.pdf" rel="external">Automated Vehicles: joint report</a>, January 2022. p.XVIII<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:3" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    See Article 5(1)(c) of <a class="govuk-link" href="https://www.legislation.gov.uk/eur/2016/679/article/5" rel="external">UK GDPR</a><a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:4" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Law Commission of England and Wales and the Scottish Law Commission. <a class="govuk-link" href="https://s3-eu-west-2.amazonaws.com/lawcom-prod-storage-11jsxou24uy7q/uploads/2022/01/Automated-vehicles-joint-report-cvr-03-02-22.pdf" rel="external">Automated Vehicles: joint report</a>, January 2022. p.XVIII<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:5" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    See Law Commission of England and Wales and the Scottish Law Commission. <a class="govuk-link" href="https://s3-eu-west-2.amazonaws.com/lawcom-prod-storage-11jsxou24uy7q/uploads/2022/01/Automated-vehicles-joint-report-cvr-03-02-22.pdf" rel="external">Automated Vehicles: joint report</a>, January 2022. p.XIX<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:6" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    See Article 4(1) of <a class="govuk-link" href="https://www.legislation.gov.uk/eur/2016/679/article/4" rel="external">UK GDPR</a><a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:7" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Law Commission of England and Wales and the Scottish Law Commission. <a class="govuk-link" href="https://s3-eu-west-2.amazonaws.com/lawcom-prod-storage-11jsxou24uy7q/uploads/2022/01/Automated-vehicles-joint-report-cvr-03-02-22.pdf" rel="external">Automated Vehicles: joint report</a>, January 2022. p.XXI<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:8" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    See Rule 204, <a class="govuk-link" href="https://www.gov.uk/guidance/the-highway-code/road-users-requiring-extra-care-204-to-225">The Highway Code</a>, Updated 2022. Note that vulnerable road users are referred to as ‘road users requiring extra care’ in the Highway Code.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:9" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This supplements LC Rec. 30 - in-use regulator’s duty to engage with those with an interest in the safety of automated vehicles<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:10" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Slovic, Paul. <a class="govuk-link" href="https://www.science.org/doi/10.1126/science.3563507" rel="external">Perception of risk</a>, Science, 236(4799), 280–285, 1987.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:11" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Liu, Peng., et al. <a class="govuk-link" href="https://doi.org/%2010.1111/risa.13116" rel="external">How safe is safe enough for self-driving vehicles?</a>, Risk Analysis, 39(2), 315–325, 2019. Note that this was a small public survey.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:12" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Stilgoe, Jack. <a class="govuk-link" href="https://link.springer.com/article/10.1007/s10676-021-09602-1" rel="external">How can we know a self-driving car is safe?</a>, Ethics and Information Technology, 23(4), 635-647, 2021.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:13" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    We propose that this be defined in terms of behaviours such as: keeping a safe distance from the individual or infrastructure, decelerating well in advance of stopping (as opposed to an emergency brake), mounting the pavement slowly if it is necessary and permissible to do so.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:14" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    cf. LC Recs. 6 and 7 - safety standard; cf. LC Rec. 15 - safety case and EIA; cf. LC Rec. 20 - data gathering on safety<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:15" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note that we expect DfT to publish good practice on how the SMS contents should be defined in due course.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:16" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This implements and strengthens the LC Rec. 13 to ‘cooperate’ with the in-use regulator; it requires the ASDE and NUiC Operator to comply with any changes in operation required by the in-use regulator - for example, to change a valet parking system or to avoid routes with level crossings.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:17" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This is intended, with the authority as having control, to be flexible. However, it would include things like records of when rules are broken/priorities are applied as these will indicate points where there are decisions that are potentially ethically significant.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:18" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    And minimum risk manoeuvre (MRM) should lead to a minimum risk condition (MRC); the combination is often referred to as MRX.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:19" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This is in line with LC Rec. 49, and the discussion of inability to respond to a transition demand due to medical emergencies, but goes further in making clear that responsibility for behaviours of the AV remains with the ASDE unless the handover to the UiC is confirmed.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:20" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    ‘Location data’ under the PECR has a specific meaning, and does not include general use of network-agnostic location services such as GPS signals (although more general GDPR requirements still apply). How location data is collected and processed will affect their data protection obligations, and this is an important area for greater regulatory clarity.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:21" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    For example, as covered in guidance on surveillance systems: Information Commissioner’s Office, <a class="govuk-link" href="https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/guidance-on-video-surveillance/" rel="external">Guidance on Video Surveillance</a>.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:22" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note that the UK government is consulting on reforms to the data protection regime: See Department for Digital, Culture, Media and Sport, <a class="govuk-link" href="https://www.gov.uk/government/consultations/data-a-new-direction">Data: a new direction</a>, September 2021.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:23" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note that there is no explicit obligation in UK GDPR requiring the publication of DPIAs, but we consider it would be appropriate here.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:24" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    It may not be practical for such a list to be exhaustive but would assist organisations in undertaking DPIAs, which will be needed to assess what is necessary, proportionate and appropriate in each given circumstance.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:25" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    As above, it may not be practical for such a list to be exhaustive but would assist organisations in undertaking DPIAs, which will be needed to assess what is necessary, proportionate and appropriate in each given circumstance.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:26" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    The ‘necessary purposes’ here could include, for example: responding fairly to the needs of other road users, safe operation of the vehicle and incident investigation.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:27" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note that the Surveillance Camera Code of Practice also includes transparency requirements as set out in UK GDPR.&nbsp; See Information Commissioner’s Office, Guide to the General Data Protection Regulation, <a class="govuk-link" href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/individual-rights/right-to-be-informed/" rel="external">‘Right to be informed’</a>.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:28" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    One example from Philip Koopman is of a AV system that failed to identify people in high-visibility clothing because it was unused to construction zones, which had been avoided in testing, see IEEE Computer Society, Roundtable discussion on <a class="govuk-link" href="http://users.ece.cmu.edu/~koopman/pubs/koopman21_Ethics_Safety_AVs_IEEE_Roundtable.pdf" rel="external">‘Ethics, Safety, and Autonomous Vehicles’</a>, 2021.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:29" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    A recent European Commission report on the ethics of AVs argued for appropriately differentiated treatment towards vulnerable road users. See European Commission, <a class="govuk-link" href="https://op.europa.eu/en/publication-detail/-/publication/89624e2c-f98c-11ea-b44f-01aa75ed71a1/language-en/format-PDF/source-search" rel="external">Ethics of Connected and Automated Vehicles</a>, 2020.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:30" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    It is notable, for example, that Uber ATG’s fatal collision in Arizona in March 2018 was in part due to a classification problem caused by a pedestrian, outside a pedestrian crossing, pushing a bicycle across a road. See National Transportation Safety Board, <a class="govuk-link" href="https://www.ntsb.gov/investigations/accidentreports/reports/har1903.pdf" rel="external">Collision Between Vehicle Controlled by Developmental Automated Driving System and Pedestrian</a>, Accident Report NTSB/HAR-19/03, 2019.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:31" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note that these impact assessments should consider impacts on relevant protected characteristics as set out in equality law, but the assessments should also cover impacts on vulnerable road users.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:32" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note that in recommendation 49 on CAVES, we recommend that CAVES should review the desirability of appropriately differentiated treatment towards vulnerable road users, and what additional reporting duties may be required.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:33" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    See Rule 204, <a class="govuk-link" href="https://www.gov.uk/guidance/the-highway-code/road-users-requiring-extra-care-204-to-225">The Highway Code</a>, Updated 2022.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:34" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    The case for independent scrutiny to evaluate AI systems is in: Falco, Gregory., et al. <a class="govuk-link" href="https://www.nature.com/articles/s42256-021-00370-7" rel="external">Governing AI safety through independent audits</a>. Nature Machine Intelligence 3, 566–571, 2021.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:35" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    LC paragraph 3.44<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:36" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This follows a recommendation from the European Commission expert group report on the ethics of connected and automated vehicles. See European Commission, <a class="govuk-link" href="https://op.europa.eu/en/publication-detail/-/publication/89624e2c-f98c-11ea-b44f-01aa75ed71a1/language-en/format-PDF/source-search" rel="external">Ethics of Connected and Automated Vehicles</a>, 2020.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:37" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Macrae, Carl. <a class="govuk-link" href="https://onlinelibrary.wiley.com/doi/10.1111/risa.13850" rel="external">Learning from the failure of autonomous and intelligent systems: accidents, safety, and sociotechnical sources of risk</a>. Risk analysis, 2021.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:38" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note that another aspect of explainability is that of explaining what is likely to happen in the future. This is covered in Rec. 5 which requires ASDEs to define a SEOC that would set out how the AV is intended to achieve safe and ethical behaviour.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:39" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    See for example the forthcoming IEEE standard on transparency (Winfield, Alan FT, Serena Booth, Louise A. Dennis, Takashi Egawa, Helen Hastie, Naomi Jacobs, Roderick I. Muttram et al. <a class="govuk-link" href="https://www.frontiersin.org/articles/10.3389/frobt.2021.665729/full" rel="external">IEEE P7001: a proposed standard on transparency</a>, Frontiers in Robotics and AI, Volume 8, 225. 2021) and <a class="govuk-link" href="https://standardsdevelopment.bsigroup.com/projects/9020-04875#/section" rel="external">ISO/IEC NP TS 6254</a><a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:40" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Herkert, Joseph, et al. <a class="govuk-link" href="https://link.springer.com/article/10.1007/s11948-020-00252-y" rel="external">The Boeing 737 MAX: Lessons for engineering ethics</a>. Science and engineering ethics, 26(6), 2957-2974. 2020.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:41" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Any framework for certification should acknowledge the possibility of incentives towards cheating, as revealed by the VW ‘dieselgate’ controversy.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:42" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Tyndall, Justin. <a class="govuk-link" href="https://www.sciencedirect.com/science/article/abs/pii/S2212012221000241" rel="external">Pedestrian deaths and large vehicles</a>. Economics of Transportation, 26, 100219. 2021.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:43" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note: this recommendation is broader than the requirements set out in LC Recs. 20 and 57.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:44" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    See for example, LC Rec. 74, which establishes a legal basis for data disclosure on AV data controllers.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:45" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note that this aligns with the Law Commissions’ recommendation that the ASDE must cooperate with an investigation unit as much as the regulator.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:46" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Tennant, Chris et al. <a class="govuk-link" href="https://driverless-futures.com/2022/05/09/survey-reports/" rel="external">Driverless Futures? A Survey of the British Public</a>, (2022). Driverless Futures? was a three-year social science project (2019-2022) funded by the Economic and Social Research Council, with researchers from University College London, UWE Bristol and City, University of London. See also Department for Transport, <a class="govuk-link" href="https://www.gov.uk/government/publications/transport-and-transport-technology-public-attitudes-tracker">Transport and transport technology: public attitudes tracker</a>, 2021 (seven iterations since 2018).<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:47" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    A recent US survey from J.D. Power found that 19% of people thought fully self-driving vehicles were already available to buy. When prompted for more information, ‘Tesla’ was the most commonly used word by survey respondents. See J.D. Power, MIT Advanced Vehicle Technology Consortium, Partners for Automated Vehicle Education (PAVE), <a class="govuk-link" href="https://www.jdpower.com/business/press-releases/2021-mobility-confidence-index-mci-study" rel="external">Mobility Confidence Index Study</a>, 2021.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:48" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This expands on LC Rec. 23 - info to owners and UIC and LC Rec. 34 - criminal offence on terminology<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:49" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This could be addressed by the Government led AV-DRiVE group.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:50" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This supplements LC Rec. 30 - in-use regulator’s duty to engage with those with an interest in the safety of automated vehicles<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:51" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Note: Recommendation 33 states that the ASDE and NUiC Operator shall support reasonable access to all relevant proprietary information by a road collision investigation unit and other authorised bodies to enable collision and incident analysis and support the authorities in producing lessons learnt for dissemination to other ASDEs.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:52" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Prior to the commencement of the future framework, listing under AEVA 2018 would be the appropriate alternative.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:53" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    Where AVs are being trialled only, and have not been authorised, trialling organisations should implement this.<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:54" role="doc-backlink">↩</a>
  </p>
</li>
<li role="doc-endnote">
  <p>
    This would implement the Law Commissions’ recommendation for a ‘Road Rules Forum’ (LC Rec. 31).<a aria-label="go to where this is referenced" class="govuk-link" href="#fnref:55" role="doc-backlink">↩</a>
  </p>
</li>
  </ol>
</div>

</div>


</div>
</div>
    </div>
  </div>

  <div class="govuk-grid-row">
    <a class="govuk-link app-c-back-to-top dont-print" href="#contents">
    <svg class="app-c-back-to-top__icon" focusable="false" height="17" viewBox="0 0 13 17" width="13" xmlns="http://www.w3.org/2000/svg">
      <path d="M6.5 0L0 6.5 1.4 8l4-4v12.7h2V4l4.3 4L13 6.4z" fill="currentColor"></path>
    </svg>
    Back to top
</a>

  </div>
</div>

    </main>